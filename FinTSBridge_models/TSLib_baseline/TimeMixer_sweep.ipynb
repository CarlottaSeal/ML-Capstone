{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9160efb",
   "metadata": {},
   "source": [
    "\n",
    "# TimeMixer Hyperparameter Sweep (Metrics-Only)\n",
    "\n",
    "This notebook runs your `Exp_Long_Term_Forecast` experiments across a grid of hyperparameters, collects **MSE, MAE, msIC, msIR**, and saves results to a CSV.\n",
    "\n",
    "**Privacy note:** After each test run, the notebook **deletes** `./test_results/<setting>/` and `./results/<setting>/` to avoid storing predictions or large artifacts. Only aggregated metrics and the final CSV are kept.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6973f1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will write CSV to: ./sweeps/sweep_results_1759258031.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "\n",
    "# Import your project modules (assumes you're running from repo root)\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "\n",
    "# ========== CONFIGS ==========\n",
    "MODEL_NAME = \"TimeMixer\"\n",
    "ROOT_PATH = \"./dataset/FBD/\"\n",
    "\n",
    "# Recreate your shellscript's dataset-specific choices\n",
    "DATASETS = {\n",
    "    \"OPTION\": {\"data_path\": \"OPTION.csv\", \"target\": \"t\", \"channel_num\": 22},\n",
    "    \"BTCF\":   {\"data_path\": \"BTCF.csv\",   \"target\": \"taker_buy_volume_spot\", \"channel_num\": 12},\n",
    "    # Add GSMI here if needed:\n",
    "    # \"GSMI\": {\"data_path\": \"GSMI.csv\", \"target\": \"volume.SZSE\", \"channel_num\": 100},\n",
    "}\n",
    "\n",
    "# Hyperparameter grid to sweep\n",
    "grid = {\n",
    "    \"pred_len\": [5, 21, 63, 126],\n",
    "    \"seq_len\": [512],\n",
    "    \"e_layers\": [2],\n",
    "    \"down_sampling_layers\": [3],\n",
    "    \"down_sampling_window\": [2],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"d_model\": [16],\n",
    "    \"d_ff\": [32],\n",
    "    \"train_epochs\": [10],\n",
    "    \"patience\": [10],\n",
    "    \"batch_size\": [128],\n",
    "    \"data\": [\"OPTION\", \"BTCF\"],\n",
    "}\n",
    "\n",
    "# Output\n",
    "RESULTS_DIR = \"./sweeps\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "CSV_PATH = os.path.join(RESULTS_DIR, f\"sweep_results_{int(time.time())}.csv\")\n",
    "print(\"Will write CSV to:\", CSV_PATH)\n",
    "\n",
    "def combos(g):\n",
    "    keys = list(g.keys())\n",
    "    vals = [g[k] for k in keys]\n",
    "    for prod in itertools.product(*vals):\n",
    "        yield dict(zip(keys, prod))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb6234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_args(params, ds_cfg):\n",
    "    \"\"\"Match run.py argument names as closely as possible.\"\"\"\n",
    "    args = Namespace(\n",
    "        # basic\n",
    "        task_name=\"long_term_forecast\",\n",
    "        is_training=1,\n",
    "        model_id=f\"{params['data']}_{params['seq_len']}_{params['pred_len']}\" ,\n",
    "        model=MODEL_NAME,\n",
    "\n",
    "        # data loader\n",
    "        data=\"custom\",\n",
    "        root_path=ROOT_PATH,\n",
    "        data_path=ds_cfg[\"data_path\"],\n",
    "        features=\"M\",\n",
    "        target=ds_cfg[\"target\"],\n",
    "        freq=\"h\",\n",
    "        checkpoints=\"./checkpoints/\",\n",
    "\n",
    "        # forecasting task\n",
    "        seq_len=params[\"seq_len\"],\n",
    "        label_len=0,\n",
    "        pred_len=params[\"pred_len\"],\n",
    "        seasonal_patterns=\"Monthly\",\n",
    "        inverse=False,\n",
    "\n",
    "        # model define (only the ones we care about for this sweep)\n",
    "        enc_in=ds_cfg[\"channel_num\"],\n",
    "        dec_in=ds_cfg[\"channel_num\"],\n",
    "        c_out=ds_cfg[\"channel_num\"],\n",
    "        d_model=params[\"d_model\"],\n",
    "        n_heads=8,\n",
    "        e_layers=params[\"e_layers\"],\n",
    "        d_layers=1,\n",
    "        d_ff=params[\"d_ff\"],\n",
    "        moving_avg=25,\n",
    "        factor=1,\n",
    "        distil=True,\n",
    "        dropout=0.1,\n",
    "        embed=\"timeF\",\n",
    "        activation=\"gelu\",\n",
    "        channel_independence=1,\n",
    "        decomp_method=\"moving_avg\",\n",
    "        use_norm=1,\n",
    "        down_sampling_layers=params[\"down_sampling_layers\"],\n",
    "        down_sampling_window=params[\"down_sampling_window\"],\n",
    "        down_sampling_method=\"avg\",\n",
    "        seg_len=48,\n",
    "\n",
    "        # optimization\n",
    "        num_workers=10,\n",
    "        itr=1,\n",
    "        train_epochs=params[\"train_epochs\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        patience=params[\"patience\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        des=\"Exp\",\n",
    "        loss=\"MSE\",\n",
    "        lradj=\"type1\",\n",
    "        use_amp=False,\n",
    "\n",
    "        # GPU\n",
    "        use_gpu=torch.cuda.is_available(),\n",
    "        gpu=0,\n",
    "        gpu_type=\"cuda\",\n",
    "        use_multi_gpu=False,\n",
    "        devices=\"0\",\n",
    "\n",
    "        # others\n",
    "        p_hidden_dims=[128,128],\n",
    "        p_hidden_layers=2,\n",
    "        use_dtw=False,\n",
    "        augmentation_ratio=0,\n",
    "        seed=2,\n",
    "        jitter=False, scaling=False, permutation=False, randompermutation=False,\n",
    "        magwarp=False, timewarp=False, windowslice=False, windowwarp=False,\n",
    "        rotation=False, spawner=False, dtwwarp=False, shapedtwwarp=False,\n",
    "        wdba=False, discdtw=False, discsdtw=False,\n",
    "        extra_tag=\"\",\n",
    "        patch_len=16,\n",
    "    )\n",
    "    # Device\n",
    "    args.device = torch.device(\"cuda:0\" if args.use_gpu else \"cpu\")\n",
    "    return args\n",
    "\n",
    "def safe_cleanup(setting):\n",
    "    \"\"\"Delete heavy artifacts saved by test() to keep only aggregated metrics.\"\"\"\n",
    "    # These are created in Exp_Long_Term_Forecast.test\n",
    "    paths = [f\"./test_results/{setting}\", f\"./results/{setting}\"]\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "\n",
      "=== RUNNING: OPTION_TimeMixer_ftM_sl512_pl5_dm16_el2_df32_dsl3_dsw2_lr0.01_bs128 ===\n",
      "\n",
      "train 25685\n",
      "val 3740\n",
      "test 7482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m exp = Exp_Long_Term_Forecast(args)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== RUNNING:\u001b[39m\u001b[33m\"\u001b[39m, setting, \u001b[33m\"\u001b[39m\u001b[33m===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m mse, mae, msIC, msIR = exp.test(setting)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Clean up heavy artifacts\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/FinTSBridge/FinTSBridge_models/TSLib_baseline/exp/exp_long_term_forecasting.py:115\u001b[39m, in \u001b[36mExp_Long_Term_Forecast.train\u001b[39m\u001b[34m(self, setting)\u001b[39m\n\u001b[32m    113\u001b[39m iter_count += \u001b[32m1\u001b[39m\n\u001b[32m    114\u001b[39m model_optim.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m batch_x = \u001b[43mbatch_x\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m batch_y = batch_y.float().to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    117\u001b[39m batch_x_mark = batch_x_mark.float().to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "all_rows = []\n",
    "\n",
    "for params in combos(grid):\n",
    "    ds_name = params[\"data\"]\n",
    "    ds_cfg = DATASETS[ds_name]\n",
    "\n",
    "    # Construct a 'setting' string consistent with your run.py scheme (shorter but unique)\n",
    "    setting = f\"{params['data']}_{MODEL_NAME}_ftM_sl{params['seq_len']}_pl{params['pred_len']}_dm{params['d_model']}_el{params['e_layers']}_df{params['d_ff']}_dsl{params['down_sampling_layers']}_dsw{params['down_sampling_window']}_lr{params['learning_rate']}_bs{params['batch_size']}\"\n",
    "\n",
    "    args = build_args(params, ds_cfg)\n",
    "    exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "    print(\"\\n=== RUNNING:\", setting, \"===\\n\")\n",
    "    exp.train(setting)\n",
    "    mse, mae, msIC, msIR = exp.test(setting)\n",
    "\n",
    "    # Clean up heavy artifacts\n",
    "    safe_cleanup(setting)\n",
    "\n",
    "    # Record a single row of metrics + params\n",
    "    row = {\n",
    "        \"setting\": setting,\n",
    "        \"data\": params[\"data\"],\n",
    "        \"pred_len\": params[\"pred_len\"],\n",
    "        \"seq_len\": params[\"seq_len\"],\n",
    "        \"e_layers\": params[\"e_layers\"],\n",
    "        \"down_sampling_layers\": params[\"down_sampling_layers\"],\n",
    "        \"down_sampling_window\": params[\"down_sampling_window\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"d_model\": params[\"d_model\"],\n",
    "        \"d_ff\": params[\"d_ff\"],\n",
    "        \"train_epochs\": params[\"train_epochs\"],\n",
    "        \"patience\": params[\"patience\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"msIC\": msIC,\n",
    "        \"msIR\": msIR,\n",
    "    }\n",
    "    all_rows.append(row)\n",
    "\n",
    "# Build DataFrame and save\n",
    "df = pd.DataFrame(all_rows)\n",
    "df.sort_values(by=[\"data\",\"pred_len\",\"d_model\",\"e_layers\"], inplace=True)\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9e4ee",
   "metadata": {},
   "source": [
    "\n",
    "### Optional: Resume/Skip Logic\n",
    "If you want to resume a long sweep and **skip** already-finished settings, wrap the loop with a check against an existing CSV. Happy to add that if you need it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
