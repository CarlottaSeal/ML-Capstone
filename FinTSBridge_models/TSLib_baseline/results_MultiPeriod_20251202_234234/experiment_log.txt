==============================================================
MULTI-PERIOD COMPARISON EXPERIMENT
Started: Tue Dec  2 11:42:34 PM UTC 2025
==============================================================

[STEP 1] Preparing period-specific datasets...
Datasets prepared.

==============================================================
PERIOD: RECENT10
Data: WTI-log-2015.csv | SeqLen: 256 | D_Model: 64
==============================================================

[RECENT10] Model: Naive
  Training Naive...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Naive_pl5  Model:              Naive               

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       1                   Batch Size:         32                  
  Patience:           7                   Learning Rate:      0.0002              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.14348053932189941
Epoch: 1, Steps: 52 | Train Loss: 2.0054335 Vali Loss: 0.6885593 Test Loss: 0.4192746
Validation loss decreased (inf --> 0.688559).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.4201, mae:0.4940, msIC:0.0166, msIR:0.0342
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.04693317413330078
Epoch: 1, Steps: 52 | Train Loss: 2.0065825 Vali Loss: 0.7099130 Test Loss: 0.4192775
Validation loss decreased (inf --> 0.709913).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.4201, mae:0.4940, msIC:-0.0099, msIR:-0.0196
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.04679512977600098
Epoch: 1, Steps: 52 | Train Loss: 2.0033098 Vali Loss: 0.6810109 Test Loss: 0.4192828
Validation loss decreased (inf --> 0.681011).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_RECENT10_Naive_pl5_Naive_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.4201, mae:0.4940, msIC:-0.0324, msIR:-0.0663
Total Evaluation 

MSE:0.4201Â±0.0000
MAE:0.4940Â±0.0000
msIC:-0.0086Â±0.0200
msIR:-0.0172Â±0.0411
  Evaluating Naive results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: DLinear
  Training DLinear...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_DLinear_pl5Model:              DLinear             

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.001               
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.14608025550842285
Epoch: 1, Steps: 52 | Train Loss: 1.0324515 Vali Loss: 0.3371214 Test Loss: 0.2075360
Validation loss decreased (inf --> 0.337121).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.07011055946350098
Epoch: 2, Steps: 52 | Train Loss: 0.9756733 Vali Loss: 0.3520299 Test Loss: 0.2109922
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.07078123092651367
Epoch: 3, Steps: 52 | Train Loss: 0.9231179 Vali Loss: 0.3588254 Test Loss: 0.2125056
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.08805990219116211
Epoch: 4, Steps: 52 | Train Loss: 0.9074756 Vali Loss: 0.3690688 Test Loss: 0.2134101
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.07624983787536621
Epoch: 5, Steps: 52 | Train Loss: 0.8995379 Vali Loss: 0.3586277 Test Loss: 0.2137769
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.07634735107421875
Epoch: 6, Steps: 52 | Train Loss: 0.9026596 Vali Loss: 0.3684167 Test Loss: 0.2140322
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.08052945137023926
Epoch: 7, Steps: 52 | Train Loss: 0.8982541 Vali Loss: 0.3701066 Test Loss: 0.2141536
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.07664823532104492
Epoch: 8, Steps: 52 | Train Loss: 0.8961631 Vali Loss: 0.3690762 Test Loss: 0.2141986
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.07962799072265625
Epoch: 9, Steps: 52 | Train Loss: 0.8921313 Vali Loss: 0.3684651 Test Loss: 0.2142206
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.08542609214782715
Epoch: 10, Steps: 52 | Train Loss: 0.9033987 Vali Loss: 0.3683907 Test Loss: 0.2142355
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.0862419605255127
Epoch: 11, Steps: 52 | Train Loss: 0.8949980 Vali Loss: 0.3733994 Test Loss: 0.2142425
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.07795071601867676
Epoch: 12, Steps: 52 | Train Loss: 0.8936223 Vali Loss: 0.3672739 Test Loss: 0.2142457
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.05477619171142578
Epoch: 13, Steps: 52 | Train Loss: 0.8935817 Vali Loss: 0.3698165 Test Loss: 0.2142476
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.06985616683959961
Epoch: 14, Steps: 52 | Train Loss: 0.8934089 Vali Loss: 0.3666110 Test Loss: 0.2142484
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.0783531665802002
Epoch: 15, Steps: 52 | Train Loss: 0.8952668 Vali Loss: 0.3797022 Test Loss: 0.2142489
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.07002925872802734
Epoch: 16, Steps: 52 | Train Loss: 0.8953146 Vali Loss: 0.3684849 Test Loss: 0.2142491
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2079, mae:0.3467, msIC:0.0005, msIR:0.0011
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.09124612808227539
Epoch: 1, Steps: 52 | Train Loss: 1.0327877 Vali Loss: 0.3447053 Test Loss: 0.2080959
Validation loss decreased (inf --> 0.344705).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.09718680381774902
Epoch: 2, Steps: 52 | Train Loss: 0.9647090 Vali Loss: 0.3500503 Test Loss: 0.2118379
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.09649014472961426
Epoch: 3, Steps: 52 | Train Loss: 0.9287809 Vali Loss: 0.3635114 Test Loss: 0.2133270
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.09642767906188965
Epoch: 4, Steps: 52 | Train Loss: 0.9097052 Vali Loss: 0.3652869 Test Loss: 0.2141606
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.09650444984436035
Epoch: 5, Steps: 52 | Train Loss: 0.9136485 Vali Loss: 0.3793703 Test Loss: 0.2145553
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.09638094902038574
Epoch: 6, Steps: 52 | Train Loss: 0.8991422 Vali Loss: 0.3656915 Test Loss: 0.2147770
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.09652447700500488
Epoch: 7, Steps: 52 | Train Loss: 0.9389358 Vali Loss: 0.3745767 Test Loss: 0.2148460
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.09628129005432129
Epoch: 8, Steps: 52 | Train Loss: 0.8999493 Vali Loss: 0.3756926 Test Loss: 0.2149161
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.09635567665100098
Epoch: 9, Steps: 52 | Train Loss: 0.8932028 Vali Loss: 0.3781756 Test Loss: 0.2149383
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.08858823776245117
Epoch: 10, Steps: 52 | Train Loss: 0.8950138 Vali Loss: 0.3715190 Test Loss: 0.2149514
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.04508852958679199
Epoch: 11, Steps: 52 | Train Loss: 0.8982190 Vali Loss: 0.3785391 Test Loss: 0.2149571
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.04449772834777832
Epoch: 12, Steps: 52 | Train Loss: 0.9023936 Vali Loss: 0.3790542 Test Loss: 0.2149608
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.04304361343383789
Epoch: 13, Steps: 52 | Train Loss: 0.8976642 Vali Loss: 0.3659724 Test Loss: 0.2149624
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.04361748695373535
Epoch: 14, Steps: 52 | Train Loss: 0.8990572 Vali Loss: 0.3698193 Test Loss: 0.2149630
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.042986154556274414
Epoch: 15, Steps: 52 | Train Loss: 0.9056317 Vali Loss: 0.3664660 Test Loss: 0.2149633
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.07660579681396484
Epoch: 16, Steps: 52 | Train Loss: 0.8931504 Vali Loss: 0.3704364 Test Loss: 0.2149636
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2084, mae:0.3468, msIC:-0.0020, msIR:-0.0040
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.06978821754455566
Epoch: 1, Steps: 52 | Train Loss: 1.0317816 Vali Loss: 0.3387540 Test Loss: 0.2058286
Validation loss decreased (inf --> 0.338754).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.08220386505126953
Epoch: 2, Steps: 52 | Train Loss: 0.9681186 Vali Loss: 0.3504649 Test Loss: 0.2100866
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.07926273345947266
Epoch: 3, Steps: 52 | Train Loss: 0.9335570 Vali Loss: 0.3592604 Test Loss: 0.2119707
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.0769648551940918
Epoch: 4, Steps: 52 | Train Loss: 0.9068885 Vali Loss: 0.3663409 Test Loss: 0.2129543
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.07291769981384277
Epoch: 5, Steps: 52 | Train Loss: 0.9049700 Vali Loss: 0.3627251 Test Loss: 0.2133975
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.07240486145019531
Epoch: 6, Steps: 52 | Train Loss: 0.8966715 Vali Loss: 0.3688638 Test Loss: 0.2136173
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.07875275611877441
Epoch: 7, Steps: 52 | Train Loss: 0.8975392 Vali Loss: 0.3649258 Test Loss: 0.2137185
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.06844711303710938
Epoch: 8, Steps: 52 | Train Loss: 0.8925212 Vali Loss: 0.3679181 Test Loss: 0.2137838
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.08109498023986816
Epoch: 9, Steps: 52 | Train Loss: 0.8961387 Vali Loss: 0.3674125 Test Loss: 0.2138114
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.06650757789611816
Epoch: 10, Steps: 52 | Train Loss: 0.9135031 Vali Loss: 0.3660969 Test Loss: 0.2138234
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.07956576347351074
Epoch: 11, Steps: 52 | Train Loss: 0.8921084 Vali Loss: 0.3733146 Test Loss: 0.2138311
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.08055520057678223
Epoch: 12, Steps: 52 | Train Loss: 0.8930591 Vali Loss: 0.3725765 Test Loss: 0.2138337
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.06003069877624512
Epoch: 13, Steps: 52 | Train Loss: 0.9014516 Vali Loss: 0.3689874 Test Loss: 0.2138357
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.07869172096252441
Epoch: 14, Steps: 52 | Train Loss: 0.8935485 Vali Loss: 0.3699940 Test Loss: 0.2138367
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.0768594741821289
Epoch: 15, Steps: 52 | Train Loss: 0.8948413 Vali Loss: 0.3681001 Test Loss: 0.2138371
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.06717586517333984
Epoch: 16, Steps: 52 | Train Loss: 0.9013867 Vali Loss: 0.3675324 Test Loss: 0.2138373
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_DLinear_pl5_DLinear_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2062, mae:0.3457, msIC:-0.0015, msIR:-0.0029
Total Evaluation 

MSE:0.2075Â±0.0010
MAE:0.3464Â±0.0005
msIC:-0.0010Â±0.0011
msIR:-0.0019Â±0.0022
  Evaluating DLinear results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: PatchTST
  Training PatchTST...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_PatchTST_pl5Model:              PatchTST            

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.38214993476867676
Epoch: 1, Steps: 52 | Train Loss: 1.4383606 Vali Loss: 0.4481985 Test Loss: 0.2318293
Validation loss decreased (inf --> 0.448199).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.16082501411437988
Epoch: 2, Steps: 52 | Train Loss: 1.2660533 Vali Loss: 0.4008232 Test Loss: 0.2204839
Validation loss decreased (0.448199 --> 0.400823).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.20763874053955078
Epoch: 3, Steps: 52 | Train Loss: 1.1521114 Vali Loss: 0.3808943 Test Loss: 0.2149085
Validation loss decreased (0.400823 --> 0.380894).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.2875337600708008
Epoch: 4, Steps: 52 | Train Loss: 1.1318364 Vali Loss: 0.3736845 Test Loss: 0.2156310
Validation loss decreased (0.380894 --> 0.373684).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2638850212097168
Epoch: 5, Steps: 52 | Train Loss: 1.0874662 Vali Loss: 0.3688015 Test Loss: 0.2133300
Validation loss decreased (0.373684 --> 0.368801).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.27457523345947266
Epoch: 6, Steps: 52 | Train Loss: 1.1123366 Vali Loss: 0.3688650 Test Loss: 0.2125746
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2546505928039551
Epoch: 7, Steps: 52 | Train Loss: 1.0777465 Vali Loss: 0.3648105 Test Loss: 0.2115327
Validation loss decreased (0.368801 --> 0.364810).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.20430612564086914
Epoch: 8, Steps: 52 | Train Loss: 1.1220810 Vali Loss: 0.3652387 Test Loss: 0.2114636
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.21109867095947266
Epoch: 9, Steps: 52 | Train Loss: 1.0757181 Vali Loss: 0.3696288 Test Loss: 0.2113563
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.21144318580627441
Epoch: 10, Steps: 52 | Train Loss: 1.0694184 Vali Loss: 0.3720731 Test Loss: 0.2113851
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.24248194694519043
Epoch: 11, Steps: 52 | Train Loss: 1.0621082 Vali Loss: 0.3590128 Test Loss: 0.2113628
Validation loss decreased (0.364810 --> 0.359013).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.1764357089996338
Epoch: 12, Steps: 52 | Train Loss: 1.0661786 Vali Loss: 0.3649925 Test Loss: 0.2114011
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.14897823333740234
Epoch: 13, Steps: 52 | Train Loss: 1.0854947 Vali Loss: 0.3677849 Test Loss: 0.2113984
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.13830995559692383
Epoch: 14, Steps: 52 | Train Loss: 1.0690836 Vali Loss: 0.3668224 Test Loss: 0.2114016
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.13630199432373047
Epoch: 15, Steps: 52 | Train Loss: 1.0917321 Vali Loss: 0.3642671 Test Loss: 0.2113707
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.1832425594329834
Epoch: 16, Steps: 52 | Train Loss: 1.0804454 Vali Loss: 0.3650074 Test Loss: 0.2114203
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.19366240501403809
Epoch: 17, Steps: 52 | Train Loss: 1.0737101 Vali Loss: 0.3619832 Test Loss: 0.2114126
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13744616508483887
Epoch: 18, Steps: 52 | Train Loss: 1.0966782 Vali Loss: 0.3641634 Test Loss: 0.2113127
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.24988412857055664
Epoch: 19, Steps: 52 | Train Loss: 1.0873823 Vali Loss: 0.3679489 Test Loss: 0.2114231
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13306641578674316
Epoch: 20, Steps: 52 | Train Loss: 1.0776191 Vali Loss: 0.3640001 Test Loss: 0.2114689
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.13364052772521973
Epoch: 21, Steps: 52 | Train Loss: 1.0876713 Vali Loss: 0.3719347 Test Loss: 0.2114546
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.13308429718017578
Epoch: 22, Steps: 52 | Train Loss: 1.0844790 Vali Loss: 0.3691889 Test Loss: 0.2114104
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13284945487976074
Epoch: 23, Steps: 52 | Train Loss: 1.0747542 Vali Loss: 0.3622130 Test Loss: 0.2113276
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.1343834400177002
Epoch: 24, Steps: 52 | Train Loss: 1.0861234 Vali Loss: 0.3694568 Test Loss: 0.2113805
EarlyStopping counter: 13 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.13285136222839355
Epoch: 25, Steps: 52 | Train Loss: 1.0877465 Vali Loss: 0.3702859 Test Loss: 0.2113935
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13283896446228027
Epoch: 26, Steps: 52 | Train Loss: 1.0779655 Vali Loss: 0.3690809 Test Loss: 0.2114570
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2117, mae:0.3503, msIC:0.0414, msIR:0.0831
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.163238525390625
Epoch: 1, Steps: 52 | Train Loss: 1.4031306 Vali Loss: 0.4306782 Test Loss: 0.2352189
Validation loss decreased (inf --> 0.430678).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.27257680892944336
Epoch: 2, Steps: 52 | Train Loss: 1.2555481 Vali Loss: 0.4373082 Test Loss: 0.2339857
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.15385866165161133
Epoch: 3, Steps: 52 | Train Loss: 1.1779161 Vali Loss: 0.4239169 Test Loss: 0.2298801
Validation loss decreased (0.430678 --> 0.423917).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.1762540340423584
Epoch: 4, Steps: 52 | Train Loss: 1.1615920 Vali Loss: 0.4129444 Test Loss: 0.2264488
Validation loss decreased (0.423917 --> 0.412944).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.18370866775512695
Epoch: 5, Steps: 52 | Train Loss: 1.1081960 Vali Loss: 0.4130866 Test Loss: 0.2254993
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.18617486953735352
Epoch: 6, Steps: 52 | Train Loss: 1.1097169 Vali Loss: 0.4134482 Test Loss: 0.2257696
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.1377098560333252
Epoch: 7, Steps: 52 | Train Loss: 1.0853389 Vali Loss: 0.4117500 Test Loss: 0.2257140
Validation loss decreased (0.412944 --> 0.411750).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.16275334358215332
Epoch: 8, Steps: 52 | Train Loss: 1.1174670 Vali Loss: 0.4079814 Test Loss: 0.2257741
Validation loss decreased (0.411750 --> 0.407981).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.19799256324768066
Epoch: 9, Steps: 52 | Train Loss: 1.1110594 Vali Loss: 0.4182269 Test Loss: 0.2255831
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.1806049346923828
Epoch: 10, Steps: 52 | Train Loss: 1.1083551 Vali Loss: 0.4059560 Test Loss: 0.2255070
Validation loss decreased (0.407981 --> 0.405956).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.25710487365722656
Epoch: 11, Steps: 52 | Train Loss: 1.1058559 Vali Loss: 0.4070916 Test Loss: 0.2255165
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.1374356746673584
Epoch: 12, Steps: 52 | Train Loss: 1.1024066 Vali Loss: 0.3994129 Test Loss: 0.2254349
Validation loss decreased (0.405956 --> 0.399413).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.1961381435394287
Epoch: 13, Steps: 52 | Train Loss: 1.1133038 Vali Loss: 0.4129728 Test Loss: 0.2254709
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.19340062141418457
Epoch: 14, Steps: 52 | Train Loss: 1.1199164 Vali Loss: 0.4088355 Test Loss: 0.2254660
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.14428091049194336
Epoch: 15, Steps: 52 | Train Loss: 1.1282580 Vali Loss: 0.4043055 Test Loss: 0.2254952
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.13579797744750977
Epoch: 16, Steps: 52 | Train Loss: 1.1219183 Vali Loss: 0.4096584 Test Loss: 0.2254775
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.13605594635009766
Epoch: 17, Steps: 52 | Train Loss: 1.1299236 Vali Loss: 0.3989798 Test Loss: 0.2254580
Validation loss decreased (0.399413 --> 0.398980).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.16312432289123535
Epoch: 18, Steps: 52 | Train Loss: 1.1158667 Vali Loss: 0.4132467 Test Loss: 0.2254793
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.1357100009918213
Epoch: 19, Steps: 52 | Train Loss: 1.1007871 Vali Loss: 0.4037571 Test Loss: 0.2254992
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13587522506713867
Epoch: 20, Steps: 52 | Train Loss: 1.1385406 Vali Loss: 0.4002924 Test Loss: 0.2253994
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.13637995719909668
Epoch: 21, Steps: 52 | Train Loss: 1.1307663 Vali Loss: 0.4117462 Test Loss: 0.2254032
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.136152982711792
Epoch: 22, Steps: 52 | Train Loss: 1.1032015 Vali Loss: 0.4127377 Test Loss: 0.2254275
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13608741760253906
Epoch: 23, Steps: 52 | Train Loss: 1.1224952 Vali Loss: 0.4042190 Test Loss: 0.2254328
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.24721765518188477
Epoch: 24, Steps: 52 | Train Loss: 1.0833877 Vali Loss: 0.4082009 Test Loss: 0.2254623
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.1923201084136963
Epoch: 25, Steps: 52 | Train Loss: 1.1171836 Vali Loss: 0.4116510 Test Loss: 0.2254432
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13705921173095703
Epoch: 26, Steps: 52 | Train Loss: 1.1473278 Vali Loss: 0.4017963 Test Loss: 0.2254394
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13958382606506348
Epoch: 27, Steps: 52 | Train Loss: 1.1222887 Vali Loss: 0.4169164 Test Loss: 0.2254648
EarlyStopping counter: 10 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.1361832618713379
Epoch: 28, Steps: 52 | Train Loss: 1.1011258 Vali Loss: 0.4133104 Test Loss: 0.2254773
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.13727021217346191
Epoch: 29, Steps: 52 | Train Loss: 1.1010745 Vali Loss: 0.4063875 Test Loss: 0.2254771
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.13608503341674805
Epoch: 30, Steps: 52 | Train Loss: 1.1527446 Vali Loss: 0.4034438 Test Loss: 0.2254590
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.19107747077941895
Epoch: 31, Steps: 52 | Train Loss: 1.1516316 Vali Loss: 0.4161537 Test Loss: 0.2254170
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.2727773189544678
Epoch: 32, Steps: 52 | Train Loss: 1.0950610 Vali Loss: 0.4056979 Test Loss: 0.2254054
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2256, mae:0.3664, msIC:-0.0120, msIR:-0.0246
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.1491718292236328
Epoch: 1, Steps: 52 | Train Loss: 1.4117823 Vali Loss: 0.4436062 Test Loss: 0.2417076
Validation loss decreased (inf --> 0.443606).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.1482987403869629
Epoch: 2, Steps: 52 | Train Loss: 1.2724222 Vali Loss: 0.4246170 Test Loss: 0.2337262
Validation loss decreased (0.443606 --> 0.424617).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.27747321128845215
Epoch: 3, Steps: 52 | Train Loss: 1.1975559 Vali Loss: 0.4018401 Test Loss: 0.2238199
Validation loss decreased (0.424617 --> 0.401840).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.26738929748535156
Epoch: 4, Steps: 52 | Train Loss: 1.1587074 Vali Loss: 0.3964015 Test Loss: 0.2227834
Validation loss decreased (0.401840 --> 0.396402).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.14148473739624023
Epoch: 5, Steps: 52 | Train Loss: 1.1270134 Vali Loss: 0.3920912 Test Loss: 0.2223979
Validation loss decreased (0.396402 --> 0.392091).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2869710922241211
Epoch: 6, Steps: 52 | Train Loss: 1.1138367 Vali Loss: 0.3980523 Test Loss: 0.2208708
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.23109173774719238
Epoch: 7, Steps: 52 | Train Loss: 1.1040005 Vali Loss: 0.3874331 Test Loss: 0.2208052
Validation loss decreased (0.392091 --> 0.387433).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.13684630393981934
Epoch: 8, Steps: 52 | Train Loss: 1.1555218 Vali Loss: 0.3906616 Test Loss: 0.2205503
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.13250446319580078
Epoch: 9, Steps: 52 | Train Loss: 1.1357985 Vali Loss: 0.3864270 Test Loss: 0.2206029
Validation loss decreased (0.387433 --> 0.386427).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.15704560279846191
Epoch: 10, Steps: 52 | Train Loss: 1.1058715 Vali Loss: 0.3851809 Test Loss: 0.2205851
Validation loss decreased (0.386427 --> 0.385181).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.1676316261291504
Epoch: 11, Steps: 52 | Train Loss: 1.0826057 Vali Loss: 0.3876200 Test Loss: 0.2205645
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.13775873184204102
Epoch: 12, Steps: 52 | Train Loss: 1.1149135 Vali Loss: 0.3933544 Test Loss: 0.2206064
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.13533663749694824
Epoch: 13, Steps: 52 | Train Loss: 1.1207487 Vali Loss: 0.3759710 Test Loss: 0.2206047
Validation loss decreased (0.385181 --> 0.375971).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.17641067504882812
Epoch: 14, Steps: 52 | Train Loss: 1.0998586 Vali Loss: 0.3897585 Test Loss: 0.2205850
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.14989209175109863
Epoch: 15, Steps: 52 | Train Loss: 1.1183344 Vali Loss: 0.3759777 Test Loss: 0.2205367
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.16942834854125977
Epoch: 16, Steps: 52 | Train Loss: 1.0919441 Vali Loss: 0.3814207 Test Loss: 0.2205937
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.1513831615447998
Epoch: 17, Steps: 52 | Train Loss: 1.1104922 Vali Loss: 0.3832391 Test Loss: 0.2205354
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.27309465408325195
Epoch: 18, Steps: 52 | Train Loss: 1.1049667 Vali Loss: 0.3819699 Test Loss: 0.2205891
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.2748689651489258
Epoch: 19, Steps: 52 | Train Loss: 1.1080152 Vali Loss: 0.3853734 Test Loss: 0.2205407
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.2794933319091797
Epoch: 20, Steps: 52 | Train Loss: 1.1099813 Vali Loss: 0.3873047 Test Loss: 0.2205536
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.1509244441986084
Epoch: 21, Steps: 52 | Train Loss: 1.1040227 Vali Loss: 0.3831958 Test Loss: 0.2205551
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.13304758071899414
Epoch: 22, Steps: 52 | Train Loss: 1.1177104 Vali Loss: 0.3870146 Test Loss: 0.2205960
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13317131996154785
Epoch: 23, Steps: 52 | Train Loss: 1.1301132 Vali Loss: 0.3829572 Test Loss: 0.2206266
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.13351106643676758
Epoch: 24, Steps: 52 | Train Loss: 1.1099527 Vali Loss: 0.3885341 Test Loss: 0.2205241
EarlyStopping counter: 11 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.13412833213806152
Epoch: 25, Steps: 52 | Train Loss: 1.1140940 Vali Loss: 0.3867041 Test Loss: 0.2206270
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.1337904930114746
Epoch: 26, Steps: 52 | Train Loss: 1.1234439 Vali Loss: 0.3799507 Test Loss: 0.2205769
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13403940200805664
Epoch: 27, Steps: 52 | Train Loss: 1.0968351 Vali Loss: 0.3960328 Test Loss: 0.2205624
EarlyStopping counter: 14 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.1334071159362793
Epoch: 28, Steps: 52 | Train Loss: 1.0944583 Vali Loss: 0.3868455 Test Loss: 0.2205881
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_PatchTST_pl5_PatchTST_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2209, mae:0.3606, msIC:0.0093, msIR:0.0186
Total Evaluation 

MSE:0.2194Â±0.0058
MAE:0.3591Â±0.0067
msIC:0.0129Â±0.0219
msIR:0.0257Â±0.0443
  Evaluating PatchTST results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: iTransformer
  Training iTransformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_iTransformer_pl5Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.42168354988098145
Epoch: 1, Steps: 52 | Train Loss: 1.2360396 Vali Loss: 0.4282146 Test Loss: 0.2267728
Validation loss decreased (inf --> 0.428215).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.15136361122131348
Epoch: 2, Steps: 52 | Train Loss: 1.0737434 Vali Loss: 0.3898245 Test Loss: 0.2200449
Validation loss decreased (0.428215 --> 0.389825).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.1487572193145752
Epoch: 3, Steps: 52 | Train Loss: 1.0303614 Vali Loss: 0.3879201 Test Loss: 0.2156770
Validation loss decreased (0.389825 --> 0.387920).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.22602057456970215
Epoch: 4, Steps: 52 | Train Loss: 0.9941429 Vali Loss: 0.3804519 Test Loss: 0.2152998
Validation loss decreased (0.387920 --> 0.380452).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2531287670135498
Epoch: 5, Steps: 52 | Train Loss: 1.0081137 Vali Loss: 0.3788161 Test Loss: 0.2147787
Validation loss decreased (0.380452 --> 0.378816).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.19463491439819336
Epoch: 6, Steps: 52 | Train Loss: 0.9928987 Vali Loss: 0.3780961 Test Loss: 0.2148632
Validation loss decreased (0.378816 --> 0.378096).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.13480401039123535
Epoch: 7, Steps: 52 | Train Loss: 0.9863471 Vali Loss: 0.3824564 Test Loss: 0.2147646
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.13561725616455078
Epoch: 8, Steps: 52 | Train Loss: 0.9839776 Vali Loss: 0.3795234 Test Loss: 0.2147911
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.128997802734375
Epoch: 9, Steps: 52 | Train Loss: 0.9959015 Vali Loss: 0.3841481 Test Loss: 0.2147945
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.129072904586792
Epoch: 10, Steps: 52 | Train Loss: 0.9824088 Vali Loss: 0.3741249 Test Loss: 0.2147935
Validation loss decreased (0.378096 --> 0.374125).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.13469552993774414
Epoch: 11, Steps: 52 | Train Loss: 0.9857260 Vali Loss: 0.3848637 Test Loss: 0.2147974
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.13112258911132812
Epoch: 12, Steps: 52 | Train Loss: 0.9993579 Vali Loss: 0.3742559 Test Loss: 0.2147984
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.12882328033447266
Epoch: 13, Steps: 52 | Train Loss: 0.9805901 Vali Loss: 0.3773476 Test Loss: 0.2147994
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.128814697265625
Epoch: 14, Steps: 52 | Train Loss: 0.9950606 Vali Loss: 0.3709689 Test Loss: 0.2147986
Validation loss decreased (0.374125 --> 0.370969).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.12948393821716309
Epoch: 15, Steps: 52 | Train Loss: 0.9768543 Vali Loss: 0.3762034 Test Loss: 0.2147990
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.1318042278289795
Epoch: 16, Steps: 52 | Train Loss: 0.9909702 Vali Loss: 0.3806123 Test Loss: 0.2147993
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.1368110179901123
Epoch: 17, Steps: 52 | Train Loss: 0.9930900 Vali Loss: 0.3739232 Test Loss: 0.2147993
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13427114486694336
Epoch: 18, Steps: 52 | Train Loss: 1.0064108 Vali Loss: 0.3724379 Test Loss: 0.2147992
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.12937092781066895
Epoch: 19, Steps: 52 | Train Loss: 0.9883066 Vali Loss: 0.3746362 Test Loss: 0.2147992
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.12921738624572754
Epoch: 20, Steps: 52 | Train Loss: 0.9826719 Vali Loss: 0.3870709 Test Loss: 0.2147992
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.12905049324035645
Epoch: 21, Steps: 52 | Train Loss: 1.0270768 Vali Loss: 0.3734878 Test Loss: 0.2147991
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.12912344932556152
Epoch: 22, Steps: 52 | Train Loss: 0.9884604 Vali Loss: 0.3784389 Test Loss: 0.2147992
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13196086883544922
Epoch: 23, Steps: 52 | Train Loss: 0.9956193 Vali Loss: 0.3831096 Test Loss: 0.2147992
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.17023968696594238
Epoch: 24, Steps: 52 | Train Loss: 0.9860615 Vali Loss: 0.3756137 Test Loss: 0.2147992
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.2153301239013672
Epoch: 25, Steps: 52 | Train Loss: 0.9854609 Vali Loss: 0.3805977 Test Loss: 0.2147991
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.14545345306396484
Epoch: 26, Steps: 52 | Train Loss: 0.9941715 Vali Loss: 0.3804413 Test Loss: 0.2147992
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13084912300109863
Epoch: 27, Steps: 52 | Train Loss: 0.9828338 Vali Loss: 0.3766559 Test Loss: 0.2147992
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.12900948524475098
Epoch: 28, Steps: 52 | Train Loss: 0.9792767 Vali Loss: 0.3776813 Test Loss: 0.2147992
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.16239404678344727
Epoch: 29, Steps: 52 | Train Loss: 0.9865491 Vali Loss: 0.3853272 Test Loss: 0.2147992
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2151, mae:0.3529, msIC:0.0202, msIR:0.0399
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.17679524421691895
Epoch: 1, Steps: 52 | Train Loss: 1.2350417 Vali Loss: 0.4176844 Test Loss: 0.2278610
Validation loss decreased (inf --> 0.417684).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.25353121757507324
Epoch: 2, Steps: 52 | Train Loss: 1.0788108 Vali Loss: 0.3846632 Test Loss: 0.2200485
Validation loss decreased (0.417684 --> 0.384663).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2638218402862549
Epoch: 3, Steps: 52 | Train Loss: 1.0183636 Vali Loss: 0.3812454 Test Loss: 0.2194487
Validation loss decreased (0.384663 --> 0.381245).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.2642216682434082
Epoch: 4, Steps: 52 | Train Loss: 1.0197422 Vali Loss: 0.3907075 Test Loss: 0.2194615
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.26558423042297363
Epoch: 5, Steps: 52 | Train Loss: 0.9861185 Vali Loss: 0.3758188 Test Loss: 0.2187595
Validation loss decreased (0.381245 --> 0.375819).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.3251183032989502
Epoch: 6, Steps: 52 | Train Loss: 0.9801370 Vali Loss: 0.3788453 Test Loss: 0.2187910
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.20416545867919922
Epoch: 7, Steps: 52 | Train Loss: 0.9712966 Vali Loss: 0.3848096 Test Loss: 0.2186701
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.1291041374206543
Epoch: 8, Steps: 52 | Train Loss: 0.9753720 Vali Loss: 0.3793657 Test Loss: 0.2186677
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.1291522979736328
Epoch: 9, Steps: 52 | Train Loss: 0.9783857 Vali Loss: 0.3787229 Test Loss: 0.2186884
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.13225555419921875
Epoch: 10, Steps: 52 | Train Loss: 1.0624115 Vali Loss: 0.3819428 Test Loss: 0.2186875
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.13698339462280273
Epoch: 11, Steps: 52 | Train Loss: 0.9933936 Vali Loss: 0.3864671 Test Loss: 0.2186925
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.1291062831878662
Epoch: 12, Steps: 52 | Train Loss: 0.9737478 Vali Loss: 0.3772406 Test Loss: 0.2186927
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.12920117378234863
Epoch: 13, Steps: 52 | Train Loss: 1.0055485 Vali Loss: 0.3828261 Test Loss: 0.2186925
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.1290435791015625
Epoch: 14, Steps: 52 | Train Loss: 0.9799249 Vali Loss: 0.3771930 Test Loss: 0.2186927
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.12900757789611816
Epoch: 15, Steps: 52 | Train Loss: 0.9737325 Vali Loss: 0.3833067 Test Loss: 0.2186925
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.13660526275634766
Epoch: 16, Steps: 52 | Train Loss: 0.9787833 Vali Loss: 0.3797351 Test Loss: 0.2186925
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.15026021003723145
Epoch: 17, Steps: 52 | Train Loss: 1.0041405 Vali Loss: 0.3877423 Test Loss: 0.2186924
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.1718442440032959
Epoch: 18, Steps: 52 | Train Loss: 1.0274990 Vali Loss: 0.3853692 Test Loss: 0.2186925
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.1292438507080078
Epoch: 19, Steps: 52 | Train Loss: 0.9761295 Vali Loss: 0.3770608 Test Loss: 0.2186925
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.17795872688293457
Epoch: 20, Steps: 52 | Train Loss: 0.9920403 Vali Loss: 0.3757197 Test Loss: 0.2186926
Validation loss decreased (0.375819 --> 0.375720).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.13008952140808105
Epoch: 21, Steps: 52 | Train Loss: 0.9874749 Vali Loss: 0.3832797 Test Loss: 0.2186925
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.1370849609375
Epoch: 22, Steps: 52 | Train Loss: 0.9918331 Vali Loss: 0.3848848 Test Loss: 0.2186926
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.12933611869812012
Epoch: 23, Steps: 52 | Train Loss: 0.9859988 Vali Loss: 0.3841680 Test Loss: 0.2186926
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.1292736530303955
Epoch: 24, Steps: 52 | Train Loss: 0.9918007 Vali Loss: 0.3731683 Test Loss: 0.2186926
Validation loss decreased (0.375720 --> 0.373168).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.1295764446258545
Epoch: 25, Steps: 52 | Train Loss: 0.9792803 Vali Loss: 0.3789017 Test Loss: 0.2186926
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13934087753295898
Epoch: 26, Steps: 52 | Train Loss: 0.9630278 Vali Loss: 0.3770714 Test Loss: 0.2186926
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.12915563583374023
Epoch: 27, Steps: 52 | Train Loss: 0.9796022 Vali Loss: 0.3791105 Test Loss: 0.2186926
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.12912225723266602
Epoch: 28, Steps: 52 | Train Loss: 0.9719714 Vali Loss: 0.3814482 Test Loss: 0.2186926
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.12945556640625
Epoch: 29, Steps: 52 | Train Loss: 0.9807187 Vali Loss: 0.3903736 Test Loss: 0.2186926
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.22994637489318848
Epoch: 30, Steps: 52 | Train Loss: 0.9837259 Vali Loss: 0.3765622 Test Loss: 0.2186926
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.26746439933776855
Epoch: 31, Steps: 52 | Train Loss: 0.9634903 Vali Loss: 0.3719403 Test Loss: 0.2186926
Validation loss decreased (0.373168 --> 0.371940).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.1493990421295166
Epoch: 32, Steps: 52 | Train Loss: 0.9867020 Vali Loss: 0.3848615 Test Loss: 0.2186926
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.14479851722717285
Epoch: 33, Steps: 52 | Train Loss: 0.9890319 Vali Loss: 0.3775093 Test Loss: 0.2186926
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.19512724876403809
Epoch: 34, Steps: 52 | Train Loss: 0.9818839 Vali Loss: 0.3857679 Test Loss: 0.2186926
EarlyStopping counter: 3 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.26518893241882324
Epoch: 35, Steps: 52 | Train Loss: 0.9866401 Vali Loss: 0.3987312 Test Loss: 0.2186926
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.16488385200500488
Epoch: 36, Steps: 52 | Train Loss: 0.9867601 Vali Loss: 0.3851142 Test Loss: 0.2186926
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.16396832466125488
Epoch: 37, Steps: 52 | Train Loss: 0.9971558 Vali Loss: 0.3833451 Test Loss: 0.2186926
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.14609909057617188
Epoch: 38, Steps: 52 | Train Loss: 0.9657913 Vali Loss: 0.3815913 Test Loss: 0.2186926
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.25210070610046387
Epoch: 39, Steps: 52 | Train Loss: 0.9843875 Vali Loss: 0.3780253 Test Loss: 0.2186926
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.26909494400024414
Epoch: 40, Steps: 52 | Train Loss: 0.9890096 Vali Loss: 0.3824557 Test Loss: 0.2186926
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.2408914566040039
Epoch: 41, Steps: 52 | Train Loss: 1.0079239 Vali Loss: 0.3762474 Test Loss: 0.2186926
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.1358482837677002
Epoch: 42, Steps: 52 | Train Loss: 0.9859439 Vali Loss: 0.3835760 Test Loss: 0.2186926
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.15418124198913574
Epoch: 43, Steps: 52 | Train Loss: 1.0457683 Vali Loss: 0.3774435 Test Loss: 0.2186926
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.16656041145324707
Epoch: 44, Steps: 52 | Train Loss: 0.9737912 Vali Loss: 0.3935134 Test Loss: 0.2186926
EarlyStopping counter: 13 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.13111305236816406
Epoch: 45, Steps: 52 | Train Loss: 0.9819273 Vali Loss: 0.3782598 Test Loss: 0.2186926
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 0.12899446487426758
Epoch: 46, Steps: 52 | Train Loss: 0.9804596 Vali Loss: 0.3789641 Test Loss: 0.2186926
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2190, mae:0.3560, msIC:0.0130, msIR:0.0261
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.18354177474975586
Epoch: 1, Steps: 52 | Train Loss: 1.2161418 Vali Loss: 0.4265808 Test Loss: 0.2280957
Validation loss decreased (inf --> 0.426581).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.26923561096191406
Epoch: 2, Steps: 52 | Train Loss: 1.0833501 Vali Loss: 0.3991874 Test Loss: 0.2196210
Validation loss decreased (0.426581 --> 0.399187).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.13039088249206543
Epoch: 3, Steps: 52 | Train Loss: 1.0021687 Vali Loss: 0.4061075 Test Loss: 0.2192428
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.1282052993774414
Epoch: 4, Steps: 52 | Train Loss: 0.9951300 Vali Loss: 0.3962141 Test Loss: 0.2180248
Validation loss decreased (0.399187 --> 0.396214).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.14356184005737305
Epoch: 5, Steps: 52 | Train Loss: 0.9936707 Vali Loss: 0.4034610 Test Loss: 0.2180828
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.16150784492492676
Epoch: 6, Steps: 52 | Train Loss: 1.0015085 Vali Loss: 0.4000922 Test Loss: 0.2179329
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2617373466491699
Epoch: 7, Steps: 52 | Train Loss: 0.9785109 Vali Loss: 0.4078624 Test Loss: 0.2179708
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.1782393455505371
Epoch: 8, Steps: 52 | Train Loss: 1.0427106 Vali Loss: 0.3912669 Test Loss: 0.2179791
Validation loss decreased (0.396214 --> 0.391267).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.13951373100280762
Epoch: 9, Steps: 52 | Train Loss: 0.9758840 Vali Loss: 0.3997063 Test Loss: 0.2179500
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.14793848991394043
Epoch: 10, Steps: 52 | Train Loss: 0.9716659 Vali Loss: 0.4056736 Test Loss: 0.2179393
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.2625279426574707
Epoch: 11, Steps: 52 | Train Loss: 0.9788348 Vali Loss: 0.3963439 Test Loss: 0.2179305
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.19684362411499023
Epoch: 12, Steps: 52 | Train Loss: 0.9713662 Vali Loss: 0.3920918 Test Loss: 0.2179302
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.14475536346435547
Epoch: 13, Steps: 52 | Train Loss: 0.9738866 Vali Loss: 0.3973131 Test Loss: 0.2179280
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.151597261428833
Epoch: 14, Steps: 52 | Train Loss: 0.9773550 Vali Loss: 0.3955394 Test Loss: 0.2179269
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.22697019577026367
Epoch: 15, Steps: 52 | Train Loss: 0.9747328 Vali Loss: 0.3926178 Test Loss: 0.2179271
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.24857711791992188
Epoch: 16, Steps: 52 | Train Loss: 0.9893929 Vali Loss: 0.3895904 Test Loss: 0.2179273
Validation loss decreased (0.391267 --> 0.389590).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.13631916046142578
Epoch: 17, Steps: 52 | Train Loss: 0.9947786 Vali Loss: 0.3973760 Test Loss: 0.2179273
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.1291515827178955
Epoch: 18, Steps: 52 | Train Loss: 0.9695255 Vali Loss: 0.3887294 Test Loss: 0.2179272
Validation loss decreased (0.389590 --> 0.388729).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.1629493236541748
Epoch: 19, Steps: 52 | Train Loss: 0.9927755 Vali Loss: 0.3947921 Test Loss: 0.2179273
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13816356658935547
Epoch: 20, Steps: 52 | Train Loss: 0.9724693 Vali Loss: 0.3882059 Test Loss: 0.2179273
Validation loss decreased (0.388729 --> 0.388206).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.17013907432556152
Epoch: 21, Steps: 52 | Train Loss: 0.9673094 Vali Loss: 0.3960737 Test Loss: 0.2179273
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.22433876991271973
Epoch: 22, Steps: 52 | Train Loss: 0.9711506 Vali Loss: 0.3943813 Test Loss: 0.2179273
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.26880455017089844
Epoch: 23, Steps: 52 | Train Loss: 0.9787391 Vali Loss: 0.4020194 Test Loss: 0.2179273
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.1899251937866211
Epoch: 24, Steps: 52 | Train Loss: 0.9799165 Vali Loss: 0.3942065 Test Loss: 0.2179273
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.14548873901367188
Epoch: 25, Steps: 52 | Train Loss: 0.9730202 Vali Loss: 0.3918290 Test Loss: 0.2179273
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.23415255546569824
Epoch: 26, Steps: 52 | Train Loss: 0.9692203 Vali Loss: 0.3990365 Test Loss: 0.2179273
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.26642870903015137
Epoch: 27, Steps: 52 | Train Loss: 0.9770691 Vali Loss: 0.3943730 Test Loss: 0.2179273
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.23612642288208008
Epoch: 28, Steps: 52 | Train Loss: 0.9746834 Vali Loss: 0.3904425 Test Loss: 0.2179273
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.13406634330749512
Epoch: 29, Steps: 52 | Train Loss: 1.0047517 Vali Loss: 0.3985068 Test Loss: 0.2179273
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.12915611267089844
Epoch: 30, Steps: 52 | Train Loss: 0.9800135 Vali Loss: 0.3980331 Test Loss: 0.2179273
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.14182496070861816
Epoch: 31, Steps: 52 | Train Loss: 0.9787707 Vali Loss: 0.3980149 Test Loss: 0.2179273
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.14783787727355957
Epoch: 32, Steps: 52 | Train Loss: 0.9793386 Vali Loss: 0.3972686 Test Loss: 0.2179273
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.17894196510314941
Epoch: 33, Steps: 52 | Train Loss: 0.9786833 Vali Loss: 0.3987052 Test Loss: 0.2179273
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.13143467903137207
Epoch: 34, Steps: 52 | Train Loss: 0.9646438 Vali Loss: 0.3940766 Test Loss: 0.2179273
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.14235281944274902
Epoch: 35, Steps: 52 | Train Loss: 1.0016467 Vali Loss: 0.3978274 Test Loss: 0.2179273
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_iTransformer_pl5_iTransformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2182, mae:0.3555, msIC:0.0101, msIR:0.0199
Total Evaluation 

MSE:0.2174Â±0.0017
MAE:0.3548Â±0.0014
msIC:0.0144Â±0.0042
msIR:0.0286Â±0.0084
  Evaluating iTransformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: TimeMixer
  Training TimeMixer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_TimeMixer_pl5Model:              TimeMixer           

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          0                   
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            16                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       50                  Batch Size:         64                  
  Patience:           10                  Learning Rate:      0.01                
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.44347333908081055
Epoch: 1, Steps: 26 | Train Loss: 1.4589889 Vali Loss: 0.4097530 Test Loss: 0.2125570
Validation loss decreased (inf --> 0.409753).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.23590922355651855
Epoch: 2, Steps: 26 | Train Loss: 1.0994881 Vali Loss: 0.3863368 Test Loss: 0.2093403
Validation loss decreased (0.409753 --> 0.386337).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.2317047119140625
Epoch: 3, Steps: 26 | Train Loss: 1.0438460 Vali Loss: 0.3650939 Test Loss: 0.2045916
Validation loss decreased (0.386337 --> 0.365094).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.22983860969543457
Epoch: 4, Steps: 26 | Train Loss: 1.0153734 Vali Loss: 0.3465145 Test Loss: 0.2031818
Validation loss decreased (0.365094 --> 0.346515).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.2343130111694336
Epoch: 5, Steps: 26 | Train Loss: 0.9977756 Vali Loss: 0.3479637 Test Loss: 0.2033760
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.21517229080200195
Epoch: 6, Steps: 26 | Train Loss: 0.9883668 Vali Loss: 0.3585300 Test Loss: 0.2035270
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.2238926887512207
Epoch: 7, Steps: 26 | Train Loss: 0.9874544 Vali Loss: 0.3497068 Test Loss: 0.2035013
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.21679997444152832
Epoch: 8, Steps: 26 | Train Loss: 1.0024797 Vali Loss: 0.3518080 Test Loss: 0.2035850
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.2177290916442871
Epoch: 9, Steps: 26 | Train Loss: 0.9959234 Vali Loss: 0.3521259 Test Loss: 0.2036470
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.2171332836151123
Epoch: 10, Steps: 26 | Train Loss: 0.9932628 Vali Loss: 0.3502204 Test Loss: 0.2036802
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.2660641670227051
Epoch: 11, Steps: 26 | Train Loss: 0.9838753 Vali Loss: 0.3595650 Test Loss: 0.2036962
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.4438645839691162
Epoch: 12, Steps: 26 | Train Loss: 0.9853096 Vali Loss: 0.3621972 Test Loss: 0.2036947
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.307159423828125
Epoch: 13, Steps: 26 | Train Loss: 0.9936010 Vali Loss: 0.3497778 Test Loss: 0.2037018
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.21529197692871094
Epoch: 14, Steps: 26 | Train Loss: 0.9873895 Vali Loss: 0.3441525 Test Loss: 0.2037047
Validation loss decreased (0.346515 --> 0.344153).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.2509765625
Epoch: 15, Steps: 26 | Train Loss: 0.9816733 Vali Loss: 0.3525074 Test Loss: 0.2037045
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.21616911888122559
Epoch: 16, Steps: 26 | Train Loss: 0.9844258 Vali Loss: 0.3424841 Test Loss: 0.2037051
Validation loss decreased (0.344153 --> 0.342484).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.2370312213897705
Epoch: 17, Steps: 26 | Train Loss: 0.9921986 Vali Loss: 0.3732756 Test Loss: 0.2037051
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.22363066673278809
Epoch: 18, Steps: 26 | Train Loss: 0.9927356 Vali Loss: 0.3606236 Test Loss: 0.2037052
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.21592140197753906
Epoch: 19, Steps: 26 | Train Loss: 0.9926564 Vali Loss: 0.3627778 Test Loss: 0.2037053
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.21599531173706055
Epoch: 20, Steps: 26 | Train Loss: 1.0236737 Vali Loss: 0.3485543 Test Loss: 0.2037053
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.21633648872375488
Epoch: 21, Steps: 26 | Train Loss: 0.9930773 Vali Loss: 0.3415384 Test Loss: 0.2037053
Validation loss decreased (0.342484 --> 0.341538).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.40269970893859863
Epoch: 22, Steps: 26 | Train Loss: 0.9984026 Vali Loss: 0.3771428 Test Loss: 0.2037053
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.21455860137939453
Epoch: 23, Steps: 26 | Train Loss: 0.9923076 Vali Loss: 0.3519381 Test Loss: 0.2037053
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.21514129638671875
Epoch: 24, Steps: 26 | Train Loss: 0.9918432 Vali Loss: 0.3703578 Test Loss: 0.2037053
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.21610212326049805
Epoch: 25, Steps: 26 | Train Loss: 0.9943892 Vali Loss: 0.3686914 Test Loss: 0.2037053
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 26 cost time: 0.21977996826171875
Epoch: 26, Steps: 26 | Train Loss: 0.9903602 Vali Loss: 0.3460609 Test Loss: 0.2037053
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 27 cost time: 0.2149674892425537
Epoch: 27, Steps: 26 | Train Loss: 0.9853154 Vali Loss: 0.3657066 Test Loss: 0.2037053
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 28 cost time: 0.21498322486877441
Epoch: 28, Steps: 26 | Train Loss: 0.9881711 Vali Loss: 0.3797330 Test Loss: 0.2037053
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 29 cost time: 0.21694135665893555
Epoch: 29, Steps: 26 | Train Loss: 0.9869921 Vali Loss: 0.3511357 Test Loss: 0.2037053
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 30 cost time: 0.21504473686218262
Epoch: 30, Steps: 26 | Train Loss: 0.9876400 Vali Loss: 0.3475262 Test Loss: 0.2037053
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 31 cost time: 0.2149200439453125
Epoch: 31, Steps: 26 | Train Loss: 0.9858625 Vali Loss: 0.3575426 Test Loss: 0.2037053
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2072, mae:0.3439, msIC:-0.0316, msIR:-0.0631
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.24457144737243652
Epoch: 1, Steps: 26 | Train Loss: 3.1220197 Vali Loss: 121.3932877 Test Loss: 37.1738663
Validation loss decreased (inf --> 121.393288).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.31330013275146484
Epoch: 2, Steps: 26 | Train Loss: 805.4928233 Vali Loss: 19.4842434 Test Loss: 7.6399994
Validation loss decreased (121.393288 --> 19.484243).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.3826584815979004
Epoch: 3, Steps: 26 | Train Loss: 27.6310816 Vali Loss: 1.6539154 Test Loss: 0.6009333
Validation loss decreased (19.484243 --> 1.653915).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.25605201721191406
Epoch: 4, Steps: 26 | Train Loss: 2.3792016 Vali Loss: 1.0592320 Test Loss: 0.4096449
Validation loss decreased (1.653915 --> 1.059232).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.33025240898132324
Epoch: 5, Steps: 26 | Train Loss: 1.3688649 Vali Loss: 0.8444685 Test Loss: 0.3214904
Validation loss decreased (1.059232 --> 0.844468).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.2987711429595947
Epoch: 6, Steps: 26 | Train Loss: 1.3196900 Vali Loss: 0.7230375 Test Loss: 0.3074219
Validation loss decreased (0.844468 --> 0.723038).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.26377344131469727
Epoch: 7, Steps: 26 | Train Loss: 1.3438641 Vali Loss: 0.7036460 Test Loss: 0.2988147
Validation loss decreased (0.723038 --> 0.703646).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.23742389678955078
Epoch: 8, Steps: 26 | Train Loss: 1.3085888 Vali Loss: 0.7271498 Test Loss: 0.3052922
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.2595968246459961
Epoch: 9, Steps: 26 | Train Loss: 1.3020257 Vali Loss: 0.7401053 Test Loss: 0.3048660
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.22694873809814453
Epoch: 10, Steps: 26 | Train Loss: 1.2904377 Vali Loss: 0.7005487 Test Loss: 0.3016464
Validation loss decreased (0.703646 --> 0.700549).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.25925278663635254
Epoch: 11, Steps: 26 | Train Loss: 1.2898439 Vali Loss: 0.7495407 Test Loss: 0.3020239
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.2317485809326172
Epoch: 12, Steps: 26 | Train Loss: 1.2921887 Vali Loss: 0.7356622 Test Loss: 0.3021858
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.21622896194458008
Epoch: 13, Steps: 26 | Train Loss: 1.3066169 Vali Loss: 0.7499028 Test Loss: 0.3021706
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.2159438133239746
Epoch: 14, Steps: 26 | Train Loss: 1.2956278 Vali Loss: 0.7141938 Test Loss: 0.3020632
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.21567845344543457
Epoch: 15, Steps: 26 | Train Loss: 1.2854155 Vali Loss: 0.7378516 Test Loss: 0.3019739
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.2154839038848877
Epoch: 16, Steps: 26 | Train Loss: 1.2690144 Vali Loss: 0.7104813 Test Loss: 0.3019588
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.29357123374938965
Epoch: 17, Steps: 26 | Train Loss: 1.2785590 Vali Loss: 0.6992579 Test Loss: 0.3019484
Validation loss decreased (0.700549 --> 0.699258).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.39502882957458496
Epoch: 18, Steps: 26 | Train Loss: 1.3063051 Vali Loss: 0.7229663 Test Loss: 0.3019496
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.21876811981201172
Epoch: 19, Steps: 26 | Train Loss: 1.3087379 Vali Loss: 0.7408330 Test Loss: 0.3019499
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.24822664260864258
Epoch: 20, Steps: 26 | Train Loss: 1.2989543 Vali Loss: 0.7264384 Test Loss: 0.3019496
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.288205623626709
Epoch: 21, Steps: 26 | Train Loss: 1.3000761 Vali Loss: 0.7249156 Test Loss: 0.3019496
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.25336360931396484
Epoch: 22, Steps: 26 | Train Loss: 1.2867910 Vali Loss: 0.7347660 Test Loss: 0.3019496
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.23079895973205566
Epoch: 23, Steps: 26 | Train Loss: 1.3053319 Vali Loss: 0.7156093 Test Loss: 0.3019495
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.23702645301818848
Epoch: 24, Steps: 26 | Train Loss: 1.2720813 Vali Loss: 0.6992266 Test Loss: 0.3019495
Validation loss decreased (0.699258 --> 0.699227).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.28571605682373047
Epoch: 25, Steps: 26 | Train Loss: 1.3058342 Vali Loss: 0.7366105 Test Loss: 0.3019495
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 26 cost time: 0.2858607769012451
Epoch: 26, Steps: 26 | Train Loss: 1.3091617 Vali Loss: 0.7023224 Test Loss: 0.3019495
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 27 cost time: 0.31795358657836914
Epoch: 27, Steps: 26 | Train Loss: 1.3017594 Vali Loss: 0.7192770 Test Loss: 0.3019495
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 28 cost time: 0.4000978469848633
Epoch: 28, Steps: 26 | Train Loss: 1.3186634 Vali Loss: 0.7217210 Test Loss: 0.3019495
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 29 cost time: 0.3943798542022705
Epoch: 29, Steps: 26 | Train Loss: 1.3019579 Vali Loss: 0.7147251 Test Loss: 0.3019495
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 30 cost time: 0.2697763442993164
Epoch: 30, Steps: 26 | Train Loss: 1.2734706 Vali Loss: 0.7376660 Test Loss: 0.3019495
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 31 cost time: 0.22413158416748047
Epoch: 31, Steps: 26 | Train Loss: 1.2981930 Vali Loss: 0.7590545 Test Loss: 0.3019495
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 32 cost time: 0.2596914768218994
Epoch: 32, Steps: 26 | Train Loss: 1.2857487 Vali Loss: 0.7741059 Test Loss: 0.3019495
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 33 cost time: 0.2199394702911377
Epoch: 33, Steps: 26 | Train Loss: 1.2949769 Vali Loss: 0.7417389 Test Loss: 0.3019495
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 34 cost time: 0.22280406951904297
Epoch: 34, Steps: 26 | Train Loss: 1.2852884 Vali Loss: 0.7037314 Test Loss: 0.3019495
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.3081, mae:0.4303, msIC:0.0078, msIR:0.0160
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.25115203857421875
Epoch: 1, Steps: 26 | Train Loss: 1.5427761 Vali Loss: 0.4036722 Test Loss: 0.2123157
Validation loss decreased (inf --> 0.403672).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.2676708698272705
Epoch: 2, Steps: 26 | Train Loss: 1.1028356 Vali Loss: 0.3761599 Test Loss: 0.2079148
Validation loss decreased (0.403672 --> 0.376160).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.32558512687683105
Epoch: 3, Steps: 26 | Train Loss: 1.0431311 Vali Loss: 0.3723586 Test Loss: 0.2083321
Validation loss decreased (0.376160 --> 0.372359).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.3748652935028076
Epoch: 4, Steps: 26 | Train Loss: 1.0051410 Vali Loss: 0.3498240 Test Loss: 0.2084915
Validation loss decreased (0.372359 --> 0.349824).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.2494487762451172
Epoch: 5, Steps: 26 | Train Loss: 0.9820974 Vali Loss: 0.3832717 Test Loss: 0.2205441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.21622371673583984
Epoch: 6, Steps: 26 | Train Loss: 0.9570169 Vali Loss: 0.3956556 Test Loss: 0.2216570
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.21584725379943848
Epoch: 7, Steps: 26 | Train Loss: 0.9598937 Vali Loss: 0.3759426 Test Loss: 0.2226391
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.21605396270751953
Epoch: 8, Steps: 26 | Train Loss: 0.9417496 Vali Loss: 0.3962936 Test Loss: 0.2283169
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.2155606746673584
Epoch: 9, Steps: 26 | Train Loss: 0.9473462 Vali Loss: 0.3837580 Test Loss: 0.2276286
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.21568679809570312
Epoch: 10, Steps: 26 | Train Loss: 0.9372253 Vali Loss: 0.4011821 Test Loss: 0.2291749
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.2835967540740967
Epoch: 11, Steps: 26 | Train Loss: 0.9466038 Vali Loss: 0.3711848 Test Loss: 0.2279583
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.21568608283996582
Epoch: 12, Steps: 26 | Train Loss: 0.9437410 Vali Loss: 0.3687855 Test Loss: 0.2276246
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.2158522605895996
Epoch: 13, Steps: 26 | Train Loss: 0.9376121 Vali Loss: 0.3816817 Test Loss: 0.2278568
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.21557092666625977
Epoch: 14, Steps: 26 | Train Loss: 0.9336248 Vali Loss: 0.3798722 Test Loss: 0.2278555
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimeMixer_pl5_TimeMixer_custom_ftMS_sl256_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2120, mae:0.3480, msIC:-0.0254, msIR:-0.0512
Total Evaluation 

MSE:0.2424Â±0.0465
MAE:0.3741Â±0.0398
msIC:-0.0164Â±0.0173
msIR:-0.0328Â±0.0348
  Evaluating TimeMixer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: Transformer
  Training Transformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Transformer_pl5Model:              Transformer         

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.6799163818359375
Epoch: 1, Steps: 52 | Train Loss: 1.1004966 Vali Loss: 0.3523298 Test Loss: 0.2515919
Validation loss decreased (inf --> 0.352330).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.2848169803619385
Epoch: 2, Steps: 52 | Train Loss: 1.0462509 Vali Loss: 0.3324891 Test Loss: 0.2154082
Validation loss decreased (0.352330 --> 0.332489).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.4338967800140381
Epoch: 3, Steps: 52 | Train Loss: 1.0190365 Vali Loss: 0.3403512 Test Loss: 0.2207534
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.21950817108154297
Epoch: 4, Steps: 52 | Train Loss: 1.0222528 Vali Loss: 0.3336345 Test Loss: 0.2143703
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.21993517875671387
Epoch: 5, Steps: 52 | Train Loss: 1.0162674 Vali Loss: 0.3406423 Test Loss: 0.2236971
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.21650934219360352
Epoch: 6, Steps: 52 | Train Loss: 1.0111069 Vali Loss: 0.3398695 Test Loss: 0.2192006
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2164170742034912
Epoch: 7, Steps: 52 | Train Loss: 1.0185844 Vali Loss: 0.3417219 Test Loss: 0.2193944
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.21629118919372559
Epoch: 8, Steps: 52 | Train Loss: 1.0200960 Vali Loss: 0.3366821 Test Loss: 0.2190084
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.2166297435760498
Epoch: 9, Steps: 52 | Train Loss: 1.0662073 Vali Loss: 0.3433993 Test Loss: 0.2192727
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.21659326553344727
Epoch: 10, Steps: 52 | Train Loss: 1.0142988 Vali Loss: 0.3396257 Test Loss: 0.2196320
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.21814846992492676
Epoch: 11, Steps: 52 | Train Loss: 1.0125031 Vali Loss: 0.3444960 Test Loss: 0.2196096
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.21636128425598145
Epoch: 12, Steps: 52 | Train Loss: 1.0149644 Vali Loss: 0.3375817 Test Loss: 0.2196659
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.21694588661193848
Epoch: 13, Steps: 52 | Train Loss: 1.0131113 Vali Loss: 0.3390953 Test Loss: 0.2196811
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.22486305236816406
Epoch: 14, Steps: 52 | Train Loss: 1.0075657 Vali Loss: 0.3430541 Test Loss: 0.2196959
EarlyStopping counter: 12 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.4104793071746826
Epoch: 15, Steps: 52 | Train Loss: 1.0368942 Vali Loss: 0.3351427 Test Loss: 0.2197060
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.26186537742614746
Epoch: 16, Steps: 52 | Train Loss: 1.0154888 Vali Loss: 0.3349977 Test Loss: 0.2197091
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.2164287567138672
Epoch: 17, Steps: 52 | Train Loss: 1.0163880 Vali Loss: 0.3473983 Test Loss: 0.2197126
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2157, mae:0.3497, msIC:-0.0150, msIR:-0.0292
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.33828139305114746
Epoch: 1, Steps: 52 | Train Loss: 1.0973808 Vali Loss: 0.3512604 Test Loss: 0.2064678
Validation loss decreased (inf --> 0.351260).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.47571611404418945
Epoch: 2, Steps: 52 | Train Loss: 1.0563643 Vali Loss: 0.3333812 Test Loss: 0.2097706
Validation loss decreased (0.351260 --> 0.333381).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.4855349063873291
Epoch: 3, Steps: 52 | Train Loss: 1.0736195 Vali Loss: 0.3398181 Test Loss: 0.2107994
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.4161496162414551
Epoch: 4, Steps: 52 | Train Loss: 1.0434458 Vali Loss: 0.3403814 Test Loss: 0.2061419
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2304682731628418
Epoch: 5, Steps: 52 | Train Loss: 1.0130873 Vali Loss: 0.3428944 Test Loss: 0.2091516
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2554032802581787
Epoch: 6, Steps: 52 | Train Loss: 1.0168789 Vali Loss: 0.3384829 Test Loss: 0.2110979
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.292217493057251
Epoch: 7, Steps: 52 | Train Loss: 1.0151527 Vali Loss: 0.3431277 Test Loss: 0.2120870
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.22497129440307617
Epoch: 8, Steps: 52 | Train Loss: 1.0081819 Vali Loss: 0.3377777 Test Loss: 0.2120552
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.21745085716247559
Epoch: 9, Steps: 52 | Train Loss: 1.0258391 Vali Loss: 0.3405707 Test Loss: 0.2116841
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.21779751777648926
Epoch: 10, Steps: 52 | Train Loss: 1.0131832 Vali Loss: 0.3337581 Test Loss: 0.2118040
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.4009222984313965
Epoch: 11, Steps: 52 | Train Loss: 1.0181424 Vali Loss: 0.3319545 Test Loss: 0.2116876
Validation loss decreased (0.333381 --> 0.331955).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.453960657119751
Epoch: 12, Steps: 52 | Train Loss: 1.0252182 Vali Loss: 0.3402249 Test Loss: 0.2116335
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.4504265785217285
Epoch: 13, Steps: 52 | Train Loss: 1.0163231 Vali Loss: 0.3401800 Test Loss: 0.2116373
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.44846463203430176
Epoch: 14, Steps: 52 | Train Loss: 1.0270238 Vali Loss: 0.3381855 Test Loss: 0.2116107
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.4418919086456299
Epoch: 15, Steps: 52 | Train Loss: 1.0091596 Vali Loss: 0.3371564 Test Loss: 0.2116147
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.2925746440887451
Epoch: 16, Steps: 52 | Train Loss: 1.0157778 Vali Loss: 0.3379305 Test Loss: 0.2116160
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.22051668167114258
Epoch: 17, Steps: 52 | Train Loss: 1.0152302 Vali Loss: 0.3325002 Test Loss: 0.2116156
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.21756887435913086
Epoch: 18, Steps: 52 | Train Loss: 1.0169849 Vali Loss: 0.3364979 Test Loss: 0.2116151
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.2256324291229248
Epoch: 19, Steps: 52 | Train Loss: 1.0175502 Vali Loss: 0.3435921 Test Loss: 0.2116150
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.21770930290222168
Epoch: 20, Steps: 52 | Train Loss: 1.0091423 Vali Loss: 0.3418348 Test Loss: 0.2116150
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.2173314094543457
Epoch: 21, Steps: 52 | Train Loss: 1.0138081 Vali Loss: 0.3300560 Test Loss: 0.2116150
Validation loss decreased (0.331955 --> 0.330056).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.25965309143066406
Epoch: 22, Steps: 52 | Train Loss: 1.0230922 Vali Loss: 0.3372709 Test Loss: 0.2116150
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.21975469589233398
Epoch: 23, Steps: 52 | Train Loss: 1.0212826 Vali Loss: 0.3317384 Test Loss: 0.2116150
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.23356008529663086
Epoch: 24, Steps: 52 | Train Loss: 1.0155218 Vali Loss: 0.3402804 Test Loss: 0.2116150
EarlyStopping counter: 3 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.22025203704833984
Epoch: 25, Steps: 52 | Train Loss: 1.0121274 Vali Loss: 0.3403649 Test Loss: 0.2116150
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.21719121932983398
Epoch: 26, Steps: 52 | Train Loss: 1.0150289 Vali Loss: 0.3352194 Test Loss: 0.2116150
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.2176072597503662
Epoch: 27, Steps: 52 | Train Loss: 1.0209417 Vali Loss: 0.3306648 Test Loss: 0.2116150
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.23342156410217285
Epoch: 28, Steps: 52 | Train Loss: 1.0202146 Vali Loss: 0.3373274 Test Loss: 0.2116150
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.32579684257507324
Epoch: 29, Steps: 52 | Train Loss: 1.0096592 Vali Loss: 0.3413462 Test Loss: 0.2116150
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.3062326908111572
Epoch: 30, Steps: 52 | Train Loss: 1.0159889 Vali Loss: 0.3264920 Test Loss: 0.2116150
Validation loss decreased (0.330056 --> 0.326492).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.26091980934143066
Epoch: 31, Steps: 52 | Train Loss: 1.0151975 Vali Loss: 0.3358462 Test Loss: 0.2116150
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.2170734405517578
Epoch: 32, Steps: 52 | Train Loss: 1.0183474 Vali Loss: 0.3370233 Test Loss: 0.2116150
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.2525148391723633
Epoch: 33, Steps: 52 | Train Loss: 1.0796804 Vali Loss: 0.3349426 Test Loss: 0.2116150
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.42430996894836426
Epoch: 34, Steps: 52 | Train Loss: 1.0166825 Vali Loss: 0.3384320 Test Loss: 0.2116150
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.4396669864654541
Epoch: 35, Steps: 52 | Train Loss: 1.0278364 Vali Loss: 0.3326326 Test Loss: 0.2116150
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.4445676803588867
Epoch: 36, Steps: 52 | Train Loss: 1.0157530 Vali Loss: 0.3366841 Test Loss: 0.2116150
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.45263671875
Epoch: 37, Steps: 52 | Train Loss: 1.0134140 Vali Loss: 0.3409308 Test Loss: 0.2116150
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.3827173709869385
Epoch: 38, Steps: 52 | Train Loss: 1.0355635 Vali Loss: 0.3367846 Test Loss: 0.2116150
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.3616206645965576
Epoch: 39, Steps: 52 | Train Loss: 1.0273909 Vali Loss: 0.3350032 Test Loss: 0.2116150
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.43683505058288574
Epoch: 40, Steps: 52 | Train Loss: 1.0204575 Vali Loss: 0.3407338 Test Loss: 0.2116150
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.2530667781829834
Epoch: 41, Steps: 52 | Train Loss: 1.0100293 Vali Loss: 0.3329405 Test Loss: 0.2116150
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.22612237930297852
Epoch: 42, Steps: 52 | Train Loss: 1.0118384 Vali Loss: 0.3355508 Test Loss: 0.2116150
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.21741390228271484
Epoch: 43, Steps: 52 | Train Loss: 1.0412743 Vali Loss: 0.3372568 Test Loss: 0.2116150
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.21761584281921387
Epoch: 44, Steps: 52 | Train Loss: 1.0170228 Vali Loss: 0.3290139 Test Loss: 0.2116150
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.21758604049682617
Epoch: 45, Steps: 52 | Train Loss: 1.0644440 Vali Loss: 0.3431758 Test Loss: 0.2116150
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2120, mae:0.3471, msIC:0.0069, msIR:0.0136
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.23415136337280273
Epoch: 1, Steps: 52 | Train Loss: 1.0868290 Vali Loss: 0.3367901 Test Loss: 0.2252141
Validation loss decreased (inf --> 0.336790).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.25620222091674805
Epoch: 2, Steps: 52 | Train Loss: 1.0441112 Vali Loss: 0.3388361 Test Loss: 0.2193458
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2239837646484375
Epoch: 3, Steps: 52 | Train Loss: 1.0105970 Vali Loss: 0.3447119 Test Loss: 0.2098247
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.25649118423461914
Epoch: 4, Steps: 52 | Train Loss: 1.0156058 Vali Loss: 0.3413166 Test Loss: 0.2102446
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.22160577774047852
Epoch: 5, Steps: 52 | Train Loss: 1.0052065 Vali Loss: 0.3384717 Test Loss: 0.2165355
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.21750140190124512
Epoch: 6, Steps: 52 | Train Loss: 1.0115375 Vali Loss: 0.3314060 Test Loss: 0.2153626
Validation loss decreased (0.336790 --> 0.331406).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.3471336364746094
Epoch: 7, Steps: 52 | Train Loss: 1.0154990 Vali Loss: 0.3355823 Test Loss: 0.2163470
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.26875734329223633
Epoch: 8, Steps: 52 | Train Loss: 1.0092660 Vali Loss: 0.3352677 Test Loss: 0.2166934
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.27255940437316895
Epoch: 9, Steps: 52 | Train Loss: 1.0150758 Vali Loss: 0.3354349 Test Loss: 0.2169724
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.22811603546142578
Epoch: 10, Steps: 52 | Train Loss: 1.0103169 Vali Loss: 0.3387571 Test Loss: 0.2170204
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.24473285675048828
Epoch: 11, Steps: 52 | Train Loss: 1.0050891 Vali Loss: 0.3450160 Test Loss: 0.2170047
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.23986172676086426
Epoch: 12, Steps: 52 | Train Loss: 1.0144770 Vali Loss: 0.3336035 Test Loss: 0.2169967
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.3560914993286133
Epoch: 13, Steps: 52 | Train Loss: 1.0152284 Vali Loss: 0.3341550 Test Loss: 0.2170323
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.22076034545898438
Epoch: 14, Steps: 52 | Train Loss: 1.0143784 Vali Loss: 0.3387221 Test Loss: 0.2170379
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.21749424934387207
Epoch: 15, Steps: 52 | Train Loss: 1.0126050 Vali Loss: 0.3429385 Test Loss: 0.2170301
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.21718263626098633
Epoch: 16, Steps: 52 | Train Loss: 1.0141007 Vali Loss: 0.3347715 Test Loss: 0.2170304
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.21890974044799805
Epoch: 17, Steps: 52 | Train Loss: 1.0070880 Vali Loss: 0.3369564 Test Loss: 0.2170318
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.21746468544006348
Epoch: 18, Steps: 52 | Train Loss: 1.0025045 Vali Loss: 0.3415229 Test Loss: 0.2170317
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.21706461906433105
Epoch: 19, Steps: 52 | Train Loss: 1.0112024 Vali Loss: 0.3385412 Test Loss: 0.2170319
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.21719932556152344
Epoch: 20, Steps: 52 | Train Loss: 1.0179579 Vali Loss: 0.3340281 Test Loss: 0.2170318
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.41199660301208496
Epoch: 21, Steps: 52 | Train Loss: 1.0064543 Vali Loss: 0.3316372 Test Loss: 0.2170318
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Transformer_pl5_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2157, mae:0.3499, msIC:0.0120, msIR:0.0232
Total Evaluation 

MSE:0.2144Â±0.0018
MAE:0.3489Â±0.0013
msIC:0.0013Â±0.0117
msIR:0.0025Â±0.0228
  Evaluating Transformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: Autoformer
  Training Autoformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Autoformer_pl5Model:              Autoformer          

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 1.1049365997314453
Epoch: 1, Steps: 52 | Train Loss: 1.1917503 Vali Loss: 0.3642147 Test Loss: 0.2351232
Validation loss decreased (inf --> 0.364215).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.684028148651123
Epoch: 2, Steps: 52 | Train Loss: 1.0876038 Vali Loss: 0.3583077 Test Loss: 0.2273606
Validation loss decreased (0.364215 --> 0.358308).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.6650543212890625
Epoch: 3, Steps: 52 | Train Loss: 1.0563552 Vali Loss: 0.3484779 Test Loss: 0.2212764
Validation loss decreased (0.358308 --> 0.348478).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.7225003242492676
Epoch: 4, Steps: 52 | Train Loss: 1.0309237 Vali Loss: 0.3493512 Test Loss: 0.2206362
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5959346294403076
Epoch: 5, Steps: 52 | Train Loss: 1.0303376 Vali Loss: 0.3487477 Test Loss: 0.2247589
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5993633270263672
Epoch: 6, Steps: 52 | Train Loss: 1.0815212 Vali Loss: 0.3479260 Test Loss: 0.2238474
Validation loss decreased (0.348478 --> 0.347926).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.6564209461212158
Epoch: 7, Steps: 52 | Train Loss: 1.0309668 Vali Loss: 0.3466150 Test Loss: 0.2236093
Validation loss decreased (0.347926 --> 0.346615).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.6155698299407959
Epoch: 8, Steps: 52 | Train Loss: 1.0341679 Vali Loss: 0.3496156 Test Loss: 0.2236648
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5946478843688965
Epoch: 9, Steps: 52 | Train Loss: 1.0356080 Vali Loss: 0.3516596 Test Loss: 0.2236684
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.593848466873169
Epoch: 10, Steps: 52 | Train Loss: 1.0267662 Vali Loss: 0.3505114 Test Loss: 0.2235385
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5943048000335693
Epoch: 11, Steps: 52 | Train Loss: 1.0417840 Vali Loss: 0.3537375 Test Loss: 0.2234953
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.6308495998382568
Epoch: 12, Steps: 52 | Train Loss: 1.0275381 Vali Loss: 0.3491121 Test Loss: 0.2235113
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.6728546619415283
Epoch: 13, Steps: 52 | Train Loss: 1.0331291 Vali Loss: 0.3453620 Test Loss: 0.2234944
Validation loss decreased (0.346615 --> 0.345362).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.6168906688690186
Epoch: 14, Steps: 52 | Train Loss: 1.0328882 Vali Loss: 0.3538113 Test Loss: 0.2235366
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.6324112415313721
Epoch: 15, Steps: 52 | Train Loss: 1.0279101 Vali Loss: 0.3575510 Test Loss: 0.2235113
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.6211297512054443
Epoch: 16, Steps: 52 | Train Loss: 1.0330943 Vali Loss: 0.3473306 Test Loss: 0.2235130
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.6021552085876465
Epoch: 17, Steps: 52 | Train Loss: 1.0413948 Vali Loss: 0.3534726 Test Loss: 0.2235130
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.5946307182312012
Epoch: 18, Steps: 52 | Train Loss: 1.0259245 Vali Loss: 0.3495429 Test Loss: 0.2235142
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.597088098526001
Epoch: 19, Steps: 52 | Train Loss: 1.0270470 Vali Loss: 0.3498961 Test Loss: 0.2235141
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.5955891609191895
Epoch: 20, Steps: 52 | Train Loss: 1.0334447 Vali Loss: 0.3450259 Test Loss: 0.2235140
Validation loss decreased (0.345362 --> 0.345026).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.6150639057159424
Epoch: 21, Steps: 52 | Train Loss: 1.0293226 Vali Loss: 0.3572406 Test Loss: 0.2235131
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.6034860610961914
Epoch: 22, Steps: 52 | Train Loss: 1.0305154 Vali Loss: 0.3507584 Test Loss: 0.2235131
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.5913786888122559
Epoch: 23, Steps: 52 | Train Loss: 1.0278218 Vali Loss: 0.3493150 Test Loss: 0.2235130
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.5907509326934814
Epoch: 24, Steps: 52 | Train Loss: 1.0708814 Vali Loss: 0.3550556 Test Loss: 0.2235132
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.5894896984100342
Epoch: 25, Steps: 52 | Train Loss: 1.0319239 Vali Loss: 0.3542262 Test Loss: 0.2235132
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.5969576835632324
Epoch: 26, Steps: 52 | Train Loss: 1.0304855 Vali Loss: 0.3520041 Test Loss: 0.2235133
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.6123075485229492
Epoch: 27, Steps: 52 | Train Loss: 1.0273850 Vali Loss: 0.3490352 Test Loss: 0.2235133
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.5944554805755615
Epoch: 28, Steps: 52 | Train Loss: 1.0310274 Vali Loss: 0.3440143 Test Loss: 0.2235133
Validation loss decreased (0.345026 --> 0.344014).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.6164150238037109
Epoch: 29, Steps: 52 | Train Loss: 1.0294074 Vali Loss: 0.3440936 Test Loss: 0.2235133
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.6238372325897217
Epoch: 30, Steps: 52 | Train Loss: 1.0243505 Vali Loss: 0.3520890 Test Loss: 0.2235133
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.5954403877258301
Epoch: 31, Steps: 52 | Train Loss: 1.0337720 Vali Loss: 0.3497569 Test Loss: 0.2235133
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.6296658515930176
Epoch: 32, Steps: 52 | Train Loss: 1.0865842 Vali Loss: 0.3485557 Test Loss: 0.2235133
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.595513105392456
Epoch: 33, Steps: 52 | Train Loss: 1.0328470 Vali Loss: 0.3512554 Test Loss: 0.2235133
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.6306920051574707
Epoch: 34, Steps: 52 | Train Loss: 1.0412743 Vali Loss: 0.3537596 Test Loss: 0.2235133
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.5956780910491943
Epoch: 35, Steps: 52 | Train Loss: 1.0428000 Vali Loss: 0.3548164 Test Loss: 0.2235133
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.5899512767791748
Epoch: 36, Steps: 52 | Train Loss: 1.0392912 Vali Loss: 0.3535279 Test Loss: 0.2235133
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.5931639671325684
Epoch: 37, Steps: 52 | Train Loss: 1.0361107 Vali Loss: 0.3473335 Test Loss: 0.2235133
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.588902473449707
Epoch: 38, Steps: 52 | Train Loss: 1.0297056 Vali Loss: 0.3525907 Test Loss: 0.2235133
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.6372029781341553
Epoch: 39, Steps: 52 | Train Loss: 1.0283937 Vali Loss: 0.3482058 Test Loss: 0.2235133
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.6219320297241211
Epoch: 40, Steps: 52 | Train Loss: 1.0271330 Vali Loss: 0.3565057 Test Loss: 0.2235133
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.6244983673095703
Epoch: 41, Steps: 52 | Train Loss: 1.0253453 Vali Loss: 0.3531657 Test Loss: 0.2235133
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.61470627784729
Epoch: 42, Steps: 52 | Train Loss: 1.0390838 Vali Loss: 0.3494107 Test Loss: 0.2235133
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.5892314910888672
Epoch: 43, Steps: 52 | Train Loss: 1.0249035 Vali Loss: 0.3516683 Test Loss: 0.2235133
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2242, mae:0.3612, msIC:0.0021, msIR:0.0043
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.594590425491333
Epoch: 1, Steps: 52 | Train Loss: 1.1550833 Vali Loss: 0.3756641 Test Loss: 0.2275430
Validation loss decreased (inf --> 0.375664).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.6111421585083008
Epoch: 2, Steps: 52 | Train Loss: 1.0684484 Vali Loss: 0.3635853 Test Loss: 0.2319303
Validation loss decreased (0.375664 --> 0.363585).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.6130280494689941
Epoch: 3, Steps: 52 | Train Loss: 1.0502414 Vali Loss: 0.3642773 Test Loss: 0.2279597
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.6136753559112549
Epoch: 4, Steps: 52 | Train Loss: 1.0599449 Vali Loss: 0.3586184 Test Loss: 0.2292323
Validation loss decreased (0.363585 --> 0.358618).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.6125714778900146
Epoch: 5, Steps: 52 | Train Loss: 1.0266681 Vali Loss: 0.3609698 Test Loss: 0.2264394
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5899357795715332
Epoch: 6, Steps: 52 | Train Loss: 1.0249355 Vali Loss: 0.3617822 Test Loss: 0.2272563
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.5911777019500732
Epoch: 7, Steps: 52 | Train Loss: 1.0290693 Vali Loss: 0.3593676 Test Loss: 0.2260823
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.5899515151977539
Epoch: 8, Steps: 52 | Train Loss: 1.0364876 Vali Loss: 0.3589000 Test Loss: 0.2264117
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.6137540340423584
Epoch: 9, Steps: 52 | Train Loss: 1.0568381 Vali Loss: 0.3590082 Test Loss: 0.2264582
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.6480028629302979
Epoch: 10, Steps: 52 | Train Loss: 1.0351786 Vali Loss: 0.3629562 Test Loss: 0.2264955
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.6355242729187012
Epoch: 11, Steps: 52 | Train Loss: 1.0247956 Vali Loss: 0.3686995 Test Loss: 0.2264502
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.661231517791748
Epoch: 12, Steps: 52 | Train Loss: 1.0539243 Vali Loss: 0.3656400 Test Loss: 0.2263617
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.5883893966674805
Epoch: 13, Steps: 52 | Train Loss: 1.0473408 Vali Loss: 0.3506080 Test Loss: 0.2263538
Validation loss decreased (0.358618 --> 0.350608).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.800875186920166
Epoch: 14, Steps: 52 | Train Loss: 1.0482704 Vali Loss: 0.3568253 Test Loss: 0.2262999
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.6363682746887207
Epoch: 15, Steps: 52 | Train Loss: 1.0240645 Vali Loss: 0.3602716 Test Loss: 0.2263004
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.5883786678314209
Epoch: 16, Steps: 52 | Train Loss: 1.0170898 Vali Loss: 0.3568888 Test Loss: 0.2263006
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.6433866024017334
Epoch: 17, Steps: 52 | Train Loss: 1.0235712 Vali Loss: 0.3610347 Test Loss: 0.2263503
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.7110245227813721
Epoch: 18, Steps: 52 | Train Loss: 1.0172594 Vali Loss: 0.3591947 Test Loss: 0.2263004
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.6028122901916504
Epoch: 19, Steps: 52 | Train Loss: 1.0494501 Vali Loss: 0.3622361 Test Loss: 0.2263003
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.6037054061889648
Epoch: 20, Steps: 52 | Train Loss: 1.0266878 Vali Loss: 0.3670952 Test Loss: 0.2263005
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.5908880233764648
Epoch: 21, Steps: 52 | Train Loss: 1.0326370 Vali Loss: 0.3643889 Test Loss: 0.2263006
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.5888619422912598
Epoch: 22, Steps: 52 | Train Loss: 1.0387453 Vali Loss: 0.3585459 Test Loss: 0.2263005
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.588015079498291
Epoch: 23, Steps: 52 | Train Loss: 1.0298763 Vali Loss: 0.3546859 Test Loss: 0.2263004
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.5966296195983887
Epoch: 24, Steps: 52 | Train Loss: 1.0194300 Vali Loss: 0.3601704 Test Loss: 0.2263003
EarlyStopping counter: 11 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.615605354309082
Epoch: 25, Steps: 52 | Train Loss: 1.0258000 Vali Loss: 0.3669485 Test Loss: 0.2263003
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.593390703201294
Epoch: 26, Steps: 52 | Train Loss: 1.0253638 Vali Loss: 0.3623924 Test Loss: 0.2263003
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.6305637359619141
Epoch: 27, Steps: 52 | Train Loss: 1.0302785 Vali Loss: 0.3567187 Test Loss: 0.2263003
EarlyStopping counter: 14 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.6404628753662109
Epoch: 28, Steps: 52 | Train Loss: 1.0273102 Vali Loss: 0.3555938 Test Loss: 0.2263003
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2268, mae:0.3678, msIC:-0.0432, msIR:-0.0895
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.6130292415618896
Epoch: 1, Steps: 52 | Train Loss: 1.1561745 Vali Loss: 0.3513581 Test Loss: 0.2403471
Validation loss decreased (inf --> 0.351358).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.6178274154663086
Epoch: 2, Steps: 52 | Train Loss: 1.1155565 Vali Loss: 0.3836021 Test Loss: 0.2445359
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.5927462577819824
Epoch: 3, Steps: 52 | Train Loss: 1.0581373 Vali Loss: 0.3819703 Test Loss: 0.2403246
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.6803634166717529
Epoch: 4, Steps: 52 | Train Loss: 1.0539650 Vali Loss: 0.3894317 Test Loss: 0.2487450
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.6223676204681396
Epoch: 5, Steps: 52 | Train Loss: 1.0420037 Vali Loss: 0.3882536 Test Loss: 0.2515891
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.6352887153625488
Epoch: 6, Steps: 52 | Train Loss: 1.0311589 Vali Loss: 0.3913224 Test Loss: 0.2535925
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.6100413799285889
Epoch: 7, Steps: 52 | Train Loss: 1.0292667 Vali Loss: 0.3784021 Test Loss: 0.2545784
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.6396396160125732
Epoch: 8, Steps: 52 | Train Loss: 1.0293127 Vali Loss: 0.3870480 Test Loss: 0.2550685
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.6883020401000977
Epoch: 9, Steps: 52 | Train Loss: 1.0364330 Vali Loss: 0.3933898 Test Loss: 0.2551521
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.7088334560394287
Epoch: 10, Steps: 52 | Train Loss: 1.0305561 Vali Loss: 0.3814967 Test Loss: 0.2549732
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.6482274532318115
Epoch: 11, Steps: 52 | Train Loss: 1.0211778 Vali Loss: 0.3944432 Test Loss: 0.2553004
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.592510461807251
Epoch: 12, Steps: 52 | Train Loss: 1.0240341 Vali Loss: 0.3892782 Test Loss: 0.2551930
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.6026601791381836
Epoch: 13, Steps: 52 | Train Loss: 1.0337524 Vali Loss: 0.3897434 Test Loss: 0.2552140
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.5919618606567383
Epoch: 14, Steps: 52 | Train Loss: 1.0313497 Vali Loss: 0.3853224 Test Loss: 0.2552138
EarlyStopping counter: 13 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.6335318088531494
Epoch: 15, Steps: 52 | Train Loss: 1.0221556 Vali Loss: 0.3972544 Test Loss: 0.2552526
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.6120033264160156
Epoch: 16, Steps: 52 | Train Loss: 1.0767069 Vali Loss: 0.3917519 Test Loss: 0.2552573
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Autoformer_pl5_Autoformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2406, mae:0.3790, msIC:-0.0523, msIR:-0.1058
Total Evaluation 

MSE:0.2305Â±0.0072
MAE:0.3693Â±0.0074
msIC:-0.0311Â±0.0238
msIR:-0.0637Â±0.0485
  Evaluating Autoformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: FEDformer
  Training FEDformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_FEDformer_pl5Model:              FEDformer           

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[2, 4, 8, 13, 22, 28, 30, 34, 35, 42, 45, 47, 59, 65, 75, 78, 79, 82, 84, 87, 88, 89, 92, 95, 105, 106, 113, 114, 118, 119, 120, 124]
fourier enhanced block used!
modes=32, index=[0, 8, 13, 14, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 33, 37, 40, 43, 44, 46, 47, 51, 53, 54, 55, 56, 57, 59, 61, 62, 63]
 fourier enhanced cross attention used!
modes_q=32, index_q=[1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 20, 22, 28, 30, 31, 34, 36, 37, 38, 39, 44, 47, 48, 51, 54, 55, 61, 62, 63, 65]
modes_kv=32, index_kv=[0, 5, 10, 11, 15, 18, 22, 24, 43, 45, 46, 49, 52, 57, 58, 66, 71, 73, 75, 84, 87, 89, 92, 97, 98, 103, 106, 109, 112, 116, 118, 121]
>>>>>>>start training : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 3.000277280807495
Epoch: 1, Steps: 52 | Train Loss: 1.2132498 Vali Loss: 0.3613692 Test Loss: 0.2347180
Validation loss decreased (inf --> 0.361369).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.73140025138855
Epoch: 2, Steps: 52 | Train Loss: 1.1022977 Vali Loss: 0.3610450 Test Loss: 0.2311304
Validation loss decreased (0.361369 --> 0.361045).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 2.7476158142089844
Epoch: 3, Steps: 52 | Train Loss: 1.0716104 Vali Loss: 0.3480637 Test Loss: 0.2216608
Validation loss decreased (0.361045 --> 0.348064).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 2.819401741027832
Epoch: 4, Steps: 52 | Train Loss: 1.0524855 Vali Loss: 0.3465911 Test Loss: 0.2170537
Validation loss decreased (0.348064 --> 0.346591).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 2.7684879302978516
Epoch: 5, Steps: 52 | Train Loss: 1.0618891 Vali Loss: 0.3490268 Test Loss: 0.2176154
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 2.692572832107544
Epoch: 6, Steps: 52 | Train Loss: 1.0683408 Vali Loss: 0.3395195 Test Loss: 0.2157506
Validation loss decreased (0.346591 --> 0.339520).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 2.721224784851074
Epoch: 7, Steps: 52 | Train Loss: 1.0836630 Vali Loss: 0.3370877 Test Loss: 0.2151982
Validation loss decreased (0.339520 --> 0.337088).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 2.756730794906616
Epoch: 8, Steps: 52 | Train Loss: 1.0650317 Vali Loss: 0.3500330 Test Loss: 0.2150943
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 2.82175874710083
Epoch: 9, Steps: 52 | Train Loss: 1.0471001 Vali Loss: 0.3380629 Test Loss: 0.2150372
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 2.746852397918701
Epoch: 10, Steps: 52 | Train Loss: 1.0453895 Vali Loss: 0.3415912 Test Loss: 0.2150377
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 2.7375736236572266
Epoch: 11, Steps: 52 | Train Loss: 1.0635677 Vali Loss: 0.3408688 Test Loss: 0.2150315
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 2.715252161026001
Epoch: 12, Steps: 52 | Train Loss: 1.0539917 Vali Loss: 0.3444772 Test Loss: 0.2150532
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 2.7439124584198
Epoch: 13, Steps: 52 | Train Loss: 1.0891075 Vali Loss: 0.3403999 Test Loss: 0.2150418
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 2.7365169525146484
Epoch: 14, Steps: 52 | Train Loss: 1.0499390 Vali Loss: 0.3406780 Test Loss: 0.2150477
EarlyStopping counter: 7 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 2.7333388328552246
Epoch: 15, Steps: 52 | Train Loss: 1.0523984 Vali Loss: 0.3415524 Test Loss: 0.2150471
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 2.816065549850464
Epoch: 16, Steps: 52 | Train Loss: 1.0612517 Vali Loss: 0.3443971 Test Loss: 0.2150465
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 2.723907709121704
Epoch: 17, Steps: 52 | Train Loss: 1.1530881 Vali Loss: 0.3390722 Test Loss: 0.2150460
EarlyStopping counter: 10 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 2.757061243057251
Epoch: 18, Steps: 52 | Train Loss: 1.0612003 Vali Loss: 0.3405309 Test Loss: 0.2150462
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 2.7017085552215576
Epoch: 19, Steps: 52 | Train Loss: 1.1017696 Vali Loss: 0.3392888 Test Loss: 0.2150461
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 2.7222793102264404
Epoch: 20, Steps: 52 | Train Loss: 1.0506147 Vali Loss: 0.3397802 Test Loss: 0.2150462
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 2.7552356719970703
Epoch: 21, Steps: 52 | Train Loss: 1.0442333 Vali Loss: 0.3446247 Test Loss: 0.2150463
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 2.7141876220703125
Epoch: 22, Steps: 52 | Train Loss: 1.0407752 Vali Loss: 0.3478078 Test Loss: 0.2150462
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2157, mae:0.3547, msIC:-0.0226, msIR:-0.0458
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[16, 17, 20, 24, 26, 30, 34, 36, 38, 43, 45, 46, 54, 58, 69, 75, 77, 78, 79, 82, 88, 89, 90, 95, 99, 104, 107, 109, 111, 118, 124, 127]
fourier enhanced block used!
modes=32, index=[1, 2, 3, 5, 6, 9, 15, 16, 18, 20, 22, 26, 27, 28, 31, 32, 33, 37, 38, 39, 41, 43, 44, 46, 49, 51, 53, 55, 59, 61, 62, 63]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 3, 4, 8, 9, 15, 17, 18, 20, 21, 22, 24, 26, 28, 32, 33, 34, 37, 38, 40, 43, 46, 48, 49, 50, 54, 55, 57, 58, 59, 64, 65]
modes_kv=32, index_kv=[5, 7, 8, 12, 13, 24, 28, 35, 36, 42, 44, 46, 48, 50, 53, 56, 58, 62, 72, 75, 85, 90, 98, 100, 101, 104, 109, 112, 113, 114, 120, 125]
>>>>>>>start training : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 2.829890251159668
Epoch: 1, Steps: 52 | Train Loss: 1.2176205 Vali Loss: 0.3697833 Test Loss: 0.2486480
Validation loss decreased (inf --> 0.369783).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.731450319290161
Epoch: 2, Steps: 52 | Train Loss: 1.0787683 Vali Loss: 0.3501529 Test Loss: 0.2214270
Validation loss decreased (0.369783 --> 0.350153).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 2.68923020362854
Epoch: 3, Steps: 52 | Train Loss: 1.0668709 Vali Loss: 0.3626145 Test Loss: 0.2241390
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 2.6962757110595703
Epoch: 4, Steps: 52 | Train Loss: 1.0600351 Vali Loss: 0.3545355 Test Loss: 0.2247790
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 2.681682586669922
Epoch: 5, Steps: 52 | Train Loss: 1.0447077 Vali Loss: 0.3562636 Test Loss: 0.2248825
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 2.695415496826172
Epoch: 6, Steps: 52 | Train Loss: 1.0491563 Vali Loss: 0.3575317 Test Loss: 0.2219580
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 2.668301820755005
Epoch: 7, Steps: 52 | Train Loss: 1.0435113 Vali Loss: 0.3484909 Test Loss: 0.2226395
Validation loss decreased (0.350153 --> 0.348491).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 2.7568647861480713
Epoch: 8, Steps: 52 | Train Loss: 1.0963330 Vali Loss: 0.3484761 Test Loss: 0.2219892
Validation loss decreased (0.348491 --> 0.348476).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 2.7937467098236084
Epoch: 9, Steps: 52 | Train Loss: 1.0463229 Vali Loss: 0.3504130 Test Loss: 0.2219919
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 2.661428451538086
Epoch: 10, Steps: 52 | Train Loss: 1.0461499 Vali Loss: 0.3494207 Test Loss: 0.2220756
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 2.7130579948425293
Epoch: 11, Steps: 52 | Train Loss: 1.0889972 Vali Loss: 0.3497671 Test Loss: 0.2220244
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 2.864872694015503
Epoch: 12, Steps: 52 | Train Loss: 1.0750366 Vali Loss: 0.3544602 Test Loss: 0.2220255
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 2.6879770755767822
Epoch: 13, Steps: 52 | Train Loss: 1.0445830 Vali Loss: 0.3490947 Test Loss: 0.2219777
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 2.6879210472106934
Epoch: 14, Steps: 52 | Train Loss: 1.0438400 Vali Loss: 0.3465738 Test Loss: 0.2219806
Validation loss decreased (0.348476 --> 0.346574).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 2.6960537433624268
Epoch: 15, Steps: 52 | Train Loss: 1.0497966 Vali Loss: 0.3511455 Test Loss: 0.2219951
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 2.688870429992676
Epoch: 16, Steps: 52 | Train Loss: 1.0534706 Vali Loss: 0.3495101 Test Loss: 0.2219992
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 2.68861985206604
Epoch: 17, Steps: 52 | Train Loss: 1.0507491 Vali Loss: 0.3580284 Test Loss: 0.2220007
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 2.6671559810638428
Epoch: 18, Steps: 52 | Train Loss: 1.0430272 Vali Loss: 0.3550814 Test Loss: 0.2219938
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 2.710559844970703
Epoch: 19, Steps: 52 | Train Loss: 1.0519356 Vali Loss: 0.3538198 Test Loss: 0.2219938
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 2.6587154865264893
Epoch: 20, Steps: 52 | Train Loss: 1.0386519 Vali Loss: 0.3502407 Test Loss: 0.2219939
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 2.6886343955993652
Epoch: 21, Steps: 52 | Train Loss: 1.0454576 Vali Loss: 0.3541521 Test Loss: 0.2219938
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 2.718981981277466
Epoch: 22, Steps: 52 | Train Loss: 1.0440485 Vali Loss: 0.3483496 Test Loss: 0.2219938
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 2.6688482761383057
Epoch: 23, Steps: 52 | Train Loss: 1.0443676 Vali Loss: 0.3515677 Test Loss: 0.2219937
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 2.6916937828063965
Epoch: 24, Steps: 52 | Train Loss: 1.0406610 Vali Loss: 0.3494937 Test Loss: 0.2219938
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 2.6690285205841064
Epoch: 25, Steps: 52 | Train Loss: 1.0551765 Vali Loss: 0.3522895 Test Loss: 0.2219938
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 2.6894891262054443
Epoch: 26, Steps: 52 | Train Loss: 1.0474658 Vali Loss: 0.3494633 Test Loss: 0.2219938
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 2.6631810665130615
Epoch: 27, Steps: 52 | Train Loss: 1.0393101 Vali Loss: 0.3546418 Test Loss: 0.2219938
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 2.6513493061065674
Epoch: 28, Steps: 52 | Train Loss: 1.0382154 Vali Loss: 0.3452949 Test Loss: 0.2219938
Validation loss decreased (0.346574 --> 0.345295).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 2.7138173580169678
Epoch: 29, Steps: 52 | Train Loss: 1.0499244 Vali Loss: 0.3502555 Test Loss: 0.2219938
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 2.6639633178710938
Epoch: 30, Steps: 52 | Train Loss: 1.0405695 Vali Loss: 0.3565848 Test Loss: 0.2219938
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 2.676151752471924
Epoch: 31, Steps: 52 | Train Loss: 1.0511872 Vali Loss: 0.3565683 Test Loss: 0.2219938
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 2.6917381286621094
Epoch: 32, Steps: 52 | Train Loss: 1.0473314 Vali Loss: 0.3520837 Test Loss: 0.2219938
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 2.674476146697998
Epoch: 33, Steps: 52 | Train Loss: 1.0382880 Vali Loss: 0.3547310 Test Loss: 0.2219938
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 2.6714706420898438
Epoch: 34, Steps: 52 | Train Loss: 1.0407071 Vali Loss: 0.3519221 Test Loss: 0.2219938
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 2.6761574745178223
Epoch: 35, Steps: 52 | Train Loss: 1.0521196 Vali Loss: 0.3512419 Test Loss: 0.2219938
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 2.7152321338653564
Epoch: 36, Steps: 52 | Train Loss: 1.0471959 Vali Loss: 0.3506941 Test Loss: 0.2219938
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 2.664032459259033
Epoch: 37, Steps: 52 | Train Loss: 1.0408292 Vali Loss: 0.3505416 Test Loss: 0.2219938
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 2.692779302597046
Epoch: 38, Steps: 52 | Train Loss: 1.0592464 Vali Loss: 0.3509924 Test Loss: 0.2219938
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 2.6926934719085693
Epoch: 39, Steps: 52 | Train Loss: 1.0554452 Vali Loss: 0.3501934 Test Loss: 0.2219938
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 2.7102794647216797
Epoch: 40, Steps: 52 | Train Loss: 1.0704448 Vali Loss: 0.3522634 Test Loss: 0.2219938
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 2.708010673522949
Epoch: 41, Steps: 52 | Train Loss: 1.0470010 Vali Loss: 0.3489432 Test Loss: 0.2219938
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 2.655716896057129
Epoch: 42, Steps: 52 | Train Loss: 1.0461606 Vali Loss: 0.3511032 Test Loss: 0.2219938
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 2.7090792655944824
Epoch: 43, Steps: 52 | Train Loss: 1.0367653 Vali Loss: 0.3531295 Test Loss: 0.2219938
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2226, mae:0.3646, msIC:-0.0179, msIR:-0.0359
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[6, 7, 8, 11, 18, 21, 26, 27, 34, 38, 40, 45, 48, 54, 56, 63, 74, 80, 84, 85, 86, 97, 98, 99, 100, 101, 108, 110, 111, 113, 119, 123]
fourier enhanced block used!
modes=32, index=[0, 3, 5, 7, 11, 12, 16, 18, 20, 22, 23, 24, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 51, 53, 54, 55, 59, 60, 62, 64, 65]
 fourier enhanced cross attention used!
modes_q=32, index_q=[3, 6, 8, 10, 12, 13, 14, 16, 23, 25, 26, 27, 29, 30, 31, 32, 35, 36, 38, 42, 43, 44, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61]
modes_kv=32, index_kv=[5, 7, 9, 13, 15, 21, 22, 28, 32, 37, 41, 44, 47, 55, 62, 64, 69, 71, 72, 75, 79, 80, 88, 91, 95, 98, 106, 111, 113, 114, 118, 123]
>>>>>>>start training : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 2.6633081436157227
Epoch: 1, Steps: 52 | Train Loss: 1.2206477 Vali Loss: 0.3665854 Test Loss: 0.2321847
Validation loss decreased (inf --> 0.366585).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.679814100265503
Epoch: 2, Steps: 52 | Train Loss: 1.0978909 Vali Loss: 0.3564698 Test Loss: 0.2260704
Validation loss decreased (0.366585 --> 0.356470).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 2.70681095123291
Epoch: 3, Steps: 52 | Train Loss: 1.0702088 Vali Loss: 0.3544191 Test Loss: 0.2231116
Validation loss decreased (0.356470 --> 0.354419).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 2.691357374191284
Epoch: 4, Steps: 52 | Train Loss: 1.0666224 Vali Loss: 0.3541446 Test Loss: 0.2205249
Validation loss decreased (0.354419 --> 0.354145).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 2.7119882106781006
Epoch: 5, Steps: 52 | Train Loss: 1.0623211 Vali Loss: 0.3491893 Test Loss: 0.2210785
Validation loss decreased (0.354145 --> 0.349189).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 2.696713924407959
Epoch: 6, Steps: 52 | Train Loss: 1.0567683 Vali Loss: 0.3590825 Test Loss: 0.2209947
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 2.7352960109710693
Epoch: 7, Steps: 52 | Train Loss: 1.0514506 Vali Loss: 0.3535575 Test Loss: 0.2207735
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 2.6698973178863525
Epoch: 8, Steps: 52 | Train Loss: 1.0574088 Vali Loss: 0.3598453 Test Loss: 0.2211183
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 2.664238929748535
Epoch: 9, Steps: 52 | Train Loss: 1.0526950 Vali Loss: 0.3529763 Test Loss: 0.2210477
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 2.7433106899261475
Epoch: 10, Steps: 52 | Train Loss: 1.0557816 Vali Loss: 0.3526786 Test Loss: 0.2207823
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 2.6677255630493164
Epoch: 11, Steps: 52 | Train Loss: 1.0489528 Vali Loss: 0.3469393 Test Loss: 0.2207301
Validation loss decreased (0.349189 --> 0.346939).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 2.7179300785064697
Epoch: 12, Steps: 52 | Train Loss: 1.0399000 Vali Loss: 0.3531690 Test Loss: 0.2207745
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 2.6869866847991943
Epoch: 13, Steps: 52 | Train Loss: 1.0710270 Vali Loss: 0.3523550 Test Loss: 0.2207861
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 2.6528117656707764
Epoch: 14, Steps: 52 | Train Loss: 1.0555055 Vali Loss: 0.3522542 Test Loss: 0.2207803
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 2.6845786571502686
Epoch: 15, Steps: 52 | Train Loss: 1.0528180 Vali Loss: 0.3487522 Test Loss: 0.2207893
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 2.6670870780944824
Epoch: 16, Steps: 52 | Train Loss: 1.0530851 Vali Loss: 0.3536817 Test Loss: 0.2207880
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 2.6672863960266113
Epoch: 17, Steps: 52 | Train Loss: 1.0586370 Vali Loss: 0.3555883 Test Loss: 0.2207869
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 2.6752820014953613
Epoch: 18, Steps: 52 | Train Loss: 1.0584067 Vali Loss: 0.3509453 Test Loss: 0.2207862
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 2.642210006713867
Epoch: 19, Steps: 52 | Train Loss: 1.0549992 Vali Loss: 0.3524731 Test Loss: 0.2207862
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 2.6963794231414795
Epoch: 20, Steps: 52 | Train Loss: 1.0542597 Vali Loss: 0.3482774 Test Loss: 0.2207862
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 2.6452796459198
Epoch: 21, Steps: 52 | Train Loss: 1.0661917 Vali Loss: 0.3503836 Test Loss: 0.2207862
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 2.6594438552856445
Epoch: 22, Steps: 52 | Train Loss: 1.0548048 Vali Loss: 0.3486148 Test Loss: 0.2207862
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 2.7229573726654053
Epoch: 23, Steps: 52 | Train Loss: 1.0594582 Vali Loss: 0.3512789 Test Loss: 0.2207862
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 2.640716791152954
Epoch: 24, Steps: 52 | Train Loss: 1.0873322 Vali Loss: 0.3609768 Test Loss: 0.2207862
EarlyStopping counter: 13 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 2.6742238998413086
Epoch: 25, Steps: 52 | Train Loss: 1.0747911 Vali Loss: 0.3555930 Test Loss: 0.2207862
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 2.6910958290100098
Epoch: 26, Steps: 52 | Train Loss: 1.0548349 Vali Loss: 0.3516835 Test Loss: 0.2207862
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_FEDformer_pl5_FEDformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2213, mae:0.3620, msIC:0.0037, msIR:0.0071
Total Evaluation 

MSE:0.2198Â±0.0030
MAE:0.3604Â±0.0042
msIC:-0.0123Â±0.0115
msIR:-0.0249Â±0.0230
  Evaluating FEDformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: TiDE
  Training TiDE...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_TiDE_pl5   Model:              TiDE                

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            256                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               256                 
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         512                 
  Patience:           15                  Learning Rate:      0.01                
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.1823735237121582
Epoch: 1, Steps: 4 | Train Loss: 1.3766472 Vali Loss: 0.4547371 Test Loss: 0.2290841
Validation loss decreased (inf --> 0.454737).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.11916589736938477
Epoch: 2, Steps: 4 | Train Loss: 0.9595054 Vali Loss: 0.4590476 Test Loss: 0.2346042
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.005
Epoch: 3 cost time: 0.09830665588378906
Epoch: 3, Steps: 4 | Train Loss: 0.9957380 Vali Loss: 0.4636902 Test Loss: 0.2369886
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.08623886108398438
Epoch: 4, Steps: 4 | Train Loss: 0.9014925 Vali Loss: 0.4622492 Test Loss: 0.2359802
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.08814787864685059
Epoch: 5, Steps: 4 | Train Loss: 0.9194430 Vali Loss: 0.4604412 Test Loss: 0.2349021
EarlyStopping counter: 4 out of 15
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.09756827354431152
Epoch: 6, Steps: 4 | Train Loss: 0.9343058 Vali Loss: 0.4591074 Test Loss: 0.2341600
EarlyStopping counter: 5 out of 15
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.09782934188842773
Epoch: 7, Steps: 4 | Train Loss: 0.9574274 Vali Loss: 0.4584490 Test Loss: 0.2338002
EarlyStopping counter: 6 out of 15
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.09694814682006836
Epoch: 8, Steps: 4 | Train Loss: 0.9064036 Vali Loss: 0.4580493 Test Loss: 0.2336206
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.09213399887084961
Epoch: 9, Steps: 4 | Train Loss: 0.8660273 Vali Loss: 0.4578283 Test Loss: 0.2335373
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.09016203880310059
Epoch: 10, Steps: 4 | Train Loss: 0.9771086 Vali Loss: 0.4577184 Test Loss: 0.2334998
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.09906172752380371
Epoch: 11, Steps: 4 | Train Loss: 0.9427558 Vali Loss: 0.4576717 Test Loss: 0.2334879
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.08322477340698242
Epoch: 12, Steps: 4 | Train Loss: 0.8685300 Vali Loss: 0.4576446 Test Loss: 0.2334796
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.08905315399169922
Epoch: 13, Steps: 4 | Train Loss: 0.8524605 Vali Loss: 0.4576310 Test Loss: 0.2334748
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.08326411247253418
Epoch: 14, Steps: 4 | Train Loss: 0.8673828 Vali Loss: 0.4576233 Test Loss: 0.2334725
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.0848233699798584
Epoch: 15, Steps: 4 | Train Loss: 0.8887340 Vali Loss: 0.4576195 Test Loss: 0.2334712
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.08353400230407715
Epoch: 16, Steps: 4 | Train Loss: 0.8543377 Vali Loss: 0.4576173 Test Loss: 0.2334704
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2376, mae:0.3745, msIC:0.0122, msIR:0.0230
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.08440947532653809
Epoch: 1, Steps: 4 | Train Loss: 1.2735761 Vali Loss: 0.4325508 Test Loss: 0.2253217
Validation loss decreased (inf --> 0.432551).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.11010599136352539
Epoch: 2, Steps: 4 | Train Loss: 0.9292321 Vali Loss: 0.4436463 Test Loss: 0.2340409
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.005
Epoch: 3 cost time: 0.08293294906616211
Epoch: 3, Steps: 4 | Train Loss: 1.0007173 Vali Loss: 0.4525051 Test Loss: 0.2363389
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.08712983131408691
Epoch: 4, Steps: 4 | Train Loss: 0.9359120 Vali Loss: 0.4521961 Test Loss: 0.2360913
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.08701491355895996
Epoch: 5, Steps: 4 | Train Loss: 0.8997847 Vali Loss: 0.4506755 Test Loss: 0.2356366
EarlyStopping counter: 4 out of 15
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.08724141120910645
Epoch: 6, Steps: 4 | Train Loss: 0.9228770 Vali Loss: 0.4496665 Test Loss: 0.2351891
EarlyStopping counter: 5 out of 15
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.08365774154663086
Epoch: 7, Steps: 4 | Train Loss: 0.8921740 Vali Loss: 0.4490447 Test Loss: 0.2348982
EarlyStopping counter: 6 out of 15
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.08270859718322754
Epoch: 8, Steps: 4 | Train Loss: 0.8657482 Vali Loss: 0.4487100 Test Loss: 0.2347335
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.08267450332641602
Epoch: 9, Steps: 4 | Train Loss: 0.8448062 Vali Loss: 0.4484904 Test Loss: 0.2346542
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.08267331123352051
Epoch: 10, Steps: 4 | Train Loss: 0.8648153 Vali Loss: 0.4483607 Test Loss: 0.2346111
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.08280706405639648
Epoch: 11, Steps: 4 | Train Loss: 0.8533551 Vali Loss: 0.4483036 Test Loss: 0.2345903
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.08287668228149414
Epoch: 12, Steps: 4 | Train Loss: 0.8871315 Vali Loss: 0.4482749 Test Loss: 0.2345791
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.08262157440185547
Epoch: 13, Steps: 4 | Train Loss: 0.8906955 Vali Loss: 0.4482609 Test Loss: 0.2345732
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.08282065391540527
Epoch: 14, Steps: 4 | Train Loss: 0.8856453 Vali Loss: 0.4482532 Test Loss: 0.2345701
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.08405160903930664
Epoch: 15, Steps: 4 | Train Loss: 0.8469955 Vali Loss: 0.4482503 Test Loss: 0.2345688
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.08355450630187988
Epoch: 16, Steps: 4 | Train Loss: 0.9844535 Vali Loss: 0.4482485 Test Loss: 0.2345681
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2344, mae:0.3743, msIC:0.0072, msIR:0.0142
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.08619427680969238
Epoch: 1, Steps: 4 | Train Loss: 1.2189345 Vali Loss: 0.4620390 Test Loss: 0.2275049
Validation loss decreased (inf --> 0.462039).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.12762808799743652
Epoch: 2, Steps: 4 | Train Loss: 1.0408813 Vali Loss: 0.4628733 Test Loss: 0.2290014
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.005
Epoch: 3 cost time: 0.0829319953918457
Epoch: 3, Steps: 4 | Train Loss: 0.8758121 Vali Loss: 0.4714962 Test Loss: 0.2343680
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.08304691314697266
Epoch: 4, Steps: 4 | Train Loss: 0.8929812 Vali Loss: 0.4688944 Test Loss: 0.2346927
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.08295607566833496
Epoch: 5, Steps: 4 | Train Loss: 0.8730479 Vali Loss: 0.4663462 Test Loss: 0.2342664
EarlyStopping counter: 4 out of 15
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.08300495147705078
Epoch: 6, Steps: 4 | Train Loss: 0.8479410 Vali Loss: 0.4647099 Test Loss: 0.2338601
EarlyStopping counter: 5 out of 15
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.08802509307861328
Epoch: 7, Steps: 4 | Train Loss: 0.8845534 Vali Loss: 0.4637378 Test Loss: 0.2336203
EarlyStopping counter: 6 out of 15
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.09173870086669922
Epoch: 8, Steps: 4 | Train Loss: 0.9313350 Vali Loss: 0.4631836 Test Loss: 0.2335245
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.09367227554321289
Epoch: 9, Steps: 4 | Train Loss: 0.8758361 Vali Loss: 0.4629046 Test Loss: 0.2334926
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.09362387657165527
Epoch: 10, Steps: 4 | Train Loss: 1.0053903 Vali Loss: 0.4627751 Test Loss: 0.2334742
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.08543276786804199
Epoch: 11, Steps: 4 | Train Loss: 0.9264633 Vali Loss: 0.4627172 Test Loss: 0.2334672
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.08275151252746582
Epoch: 12, Steps: 4 | Train Loss: 0.8802889 Vali Loss: 0.4626869 Test Loss: 0.2334618
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.08279848098754883
Epoch: 13, Steps: 4 | Train Loss: 0.8387274 Vali Loss: 0.4626724 Test Loss: 0.2334578
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.08281946182250977
Epoch: 14, Steps: 4 | Train Loss: 1.0218194 Vali Loss: 0.4626642 Test Loss: 0.2334559
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.08276534080505371
Epoch: 15, Steps: 4 | Train Loss: 0.8461013 Vali Loss: 0.4626597 Test Loss: 0.2334547
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.08295059204101562
Epoch: 16, Steps: 4 | Train Loss: 0.8560378 Vali Loss: 0.4626574 Test Loss: 0.2334540
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TiDE_pl5_TiDE_custom_ftMS_sl256_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2412, mae:0.3775, msIC:0.0113, msIR:0.0222
Total Evaluation 

MSE:0.2378Â±0.0028
MAE:0.3754Â±0.0015
msIC:0.0102Â±0.0022
msIR:0.0198Â±0.0040
  Evaluating TiDE results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: TimesNet
  Training TimesNet...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_TimesNet_pl5Model:              TimesNet            

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 2.400219678878784
Epoch: 1, Steps: 52 | Train Loss: 1.1281842 Vali Loss: 0.3861341 Test Loss: 0.2210840
Validation loss decreased (inf --> 0.386134).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9112253189086914
Epoch: 2, Steps: 52 | Train Loss: 1.0714935 Vali Loss: 0.3701623 Test Loss: 0.2121370
Validation loss decreased (0.386134 --> 0.370162).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.891892433166504
Epoch: 3, Steps: 52 | Train Loss: 1.0160014 Vali Loss: 0.3612227 Test Loss: 0.2126504
Validation loss decreased (0.370162 --> 0.361223).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.8878364562988281
Epoch: 4, Steps: 52 | Train Loss: 0.9409794 Vali Loss: 0.3597549 Test Loss: 0.2176381
Validation loss decreased (0.361223 --> 0.359755).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.8908147811889648
Epoch: 5, Steps: 52 | Train Loss: 0.9059565 Vali Loss: 0.3689813 Test Loss: 0.2214443
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.8848059177398682
Epoch: 6, Steps: 52 | Train Loss: 0.8932312 Vali Loss: 0.3678719 Test Loss: 0.2215910
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.892136573791504
Epoch: 7, Steps: 52 | Train Loss: 0.8838410 Vali Loss: 0.3688435 Test Loss: 0.2223979
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.8907551765441895
Epoch: 8, Steps: 52 | Train Loss: 0.8829439 Vali Loss: 0.3763910 Test Loss: 0.2231493
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.8906874656677246
Epoch: 9, Steps: 52 | Train Loss: 0.8718903 Vali Loss: 0.3632278 Test Loss: 0.2232115
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.889890432357788
Epoch: 10, Steps: 52 | Train Loss: 0.8669542 Vali Loss: 0.3695515 Test Loss: 0.2233829
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.8872318267822266
Epoch: 11, Steps: 52 | Train Loss: 0.8706662 Vali Loss: 0.3740650 Test Loss: 0.2234252
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.8908038139343262
Epoch: 12, Steps: 52 | Train Loss: 0.8729385 Vali Loss: 0.3711369 Test Loss: 0.2234382
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.8939671516418457
Epoch: 13, Steps: 52 | Train Loss: 0.8693480 Vali Loss: 0.3807242 Test Loss: 0.2234548
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.8849637508392334
Epoch: 14, Steps: 52 | Train Loss: 0.8834906 Vali Loss: 0.3807525 Test Loss: 0.2234626
EarlyStopping counter: 10 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.9286348819732666
Epoch: 15, Steps: 52 | Train Loss: 0.8686120 Vali Loss: 0.3773553 Test Loss: 0.2234699
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.8886988162994385
Epoch: 16, Steps: 52 | Train Loss: 0.8788681 Vali Loss: 0.3772553 Test Loss: 0.2234730
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.8904476165771484
Epoch: 17, Steps: 52 | Train Loss: 0.8788806 Vali Loss: 0.3782115 Test Loss: 0.2234738
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 1.8884496688842773
Epoch: 18, Steps: 52 | Train Loss: 0.8788783 Vali Loss: 0.3719554 Test Loss: 0.2234739
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 1.891282558441162
Epoch: 19, Steps: 52 | Train Loss: 0.8686180 Vali Loss: 0.3702601 Test Loss: 0.2234740
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2181, mae:0.3547, msIC:0.0088, msIR:0.0180
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 1.9999301433563232
Epoch: 1, Steps: 52 | Train Loss: 1.1629721 Vali Loss: 0.3475403 Test Loss: 0.2095271
Validation loss decreased (inf --> 0.347540).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9262256622314453
Epoch: 2, Steps: 52 | Train Loss: 1.0482645 Vali Loss: 0.3424252 Test Loss: 0.2075435
Validation loss decreased (0.347540 --> 0.342425).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.895029067993164
Epoch: 3, Steps: 52 | Train Loss: 1.0133330 Vali Loss: 0.3565853 Test Loss: 0.2121366
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.898545503616333
Epoch: 4, Steps: 52 | Train Loss: 0.9827647 Vali Loss: 0.3572060 Test Loss: 0.2088016
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.9053590297698975
Epoch: 5, Steps: 52 | Train Loss: 0.9781711 Vali Loss: 0.3535304 Test Loss: 0.2092896
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.90889310836792
Epoch: 6, Steps: 52 | Train Loss: 0.9686192 Vali Loss: 0.3597453 Test Loss: 0.2087638
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.9034020900726318
Epoch: 7, Steps: 52 | Train Loss: 0.9965802 Vali Loss: 0.3627096 Test Loss: 0.2087616
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.9066295623779297
Epoch: 8, Steps: 52 | Train Loss: 0.9590181 Vali Loss: 0.3563235 Test Loss: 0.2089436
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.898442268371582
Epoch: 9, Steps: 52 | Train Loss: 0.9634799 Vali Loss: 0.3590672 Test Loss: 0.2089434
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.9036524295806885
Epoch: 10, Steps: 52 | Train Loss: 0.9691826 Vali Loss: 0.3529882 Test Loss: 0.2089995
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.922351360321045
Epoch: 11, Steps: 52 | Train Loss: 0.9930250 Vali Loss: 0.3593607 Test Loss: 0.2089994
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.9031236171722412
Epoch: 12, Steps: 52 | Train Loss: 0.9728318 Vali Loss: 0.3649411 Test Loss: 0.2090070
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.9177145957946777
Epoch: 13, Steps: 52 | Train Loss: 0.9614985 Vali Loss: 0.3571178 Test Loss: 0.2090092
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.9219639301300049
Epoch: 14, Steps: 52 | Train Loss: 0.9610241 Vali Loss: 0.3591924 Test Loss: 0.2090136
EarlyStopping counter: 12 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.9005467891693115
Epoch: 15, Steps: 52 | Train Loss: 0.9632787 Vali Loss: 0.3557656 Test Loss: 0.2090155
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.9000904560089111
Epoch: 16, Steps: 52 | Train Loss: 0.9564445 Vali Loss: 0.3619191 Test Loss: 0.2090162
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.9014511108398438
Epoch: 17, Steps: 52 | Train Loss: 1.0004596 Vali Loss: 0.3550662 Test Loss: 0.2090166
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2080, mae:0.3461, msIC:-0.0081, msIR:-0.0163
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 1.9244344234466553
Epoch: 1, Steps: 52 | Train Loss: 1.1357372 Vali Loss: 0.3489447 Test Loss: 0.2096515
Validation loss decreased (inf --> 0.348945).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.9328606128692627
Epoch: 2, Steps: 52 | Train Loss: 1.0462605 Vali Loss: 0.3469400 Test Loss: 0.2096631
Validation loss decreased (0.348945 --> 0.346940).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.9212257862091064
Epoch: 3, Steps: 52 | Train Loss: 1.0113601 Vali Loss: 0.3396810 Test Loss: 0.2112660
Validation loss decreased (0.346940 --> 0.339681).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.9157493114471436
Epoch: 4, Steps: 52 | Train Loss: 1.0091683 Vali Loss: 0.3453758 Test Loss: 0.2115610
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.9203801155090332
Epoch: 5, Steps: 52 | Train Loss: 0.9739223 Vali Loss: 0.3338795 Test Loss: 0.2117339
Validation loss decreased (0.339681 --> 0.333880).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.9216957092285156
Epoch: 6, Steps: 52 | Train Loss: 0.9612233 Vali Loss: 0.3389322 Test Loss: 0.2122146
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.9264709949493408
Epoch: 7, Steps: 52 | Train Loss: 0.9688635 Vali Loss: 0.3461239 Test Loss: 0.2124493
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.9606492519378662
Epoch: 8, Steps: 52 | Train Loss: 0.9548206 Vali Loss: 0.3374943 Test Loss: 0.2124856
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.9189367294311523
Epoch: 9, Steps: 52 | Train Loss: 0.9548193 Vali Loss: 0.3400828 Test Loss: 0.2124631
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.9164466857910156
Epoch: 10, Steps: 52 | Train Loss: 0.9946755 Vali Loss: 0.3378195 Test Loss: 0.2125121
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.9205281734466553
Epoch: 11, Steps: 52 | Train Loss: 0.9549738 Vali Loss: 0.3440134 Test Loss: 0.2125288
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.9155492782592773
Epoch: 12, Steps: 52 | Train Loss: 0.9653251 Vali Loss: 0.3371760 Test Loss: 0.2125348
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.9145774841308594
Epoch: 13, Steps: 52 | Train Loss: 0.9583144 Vali Loss: 0.3419688 Test Loss: 0.2125466
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.913517713546753
Epoch: 14, Steps: 52 | Train Loss: 0.9499430 Vali Loss: 0.3393271 Test Loss: 0.2125459
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.91139817237854
Epoch: 15, Steps: 52 | Train Loss: 0.9538148 Vali Loss: 0.3368654 Test Loss: 0.2125489
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.916717767715454
Epoch: 16, Steps: 52 | Train Loss: 0.9538409 Vali Loss: 0.3330388 Test Loss: 0.2125497
Validation loss decreased (0.333880 --> 0.333039).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.921466588973999
Epoch: 17, Steps: 52 | Train Loss: 0.9538167 Vali Loss: 0.3360027 Test Loss: 0.2125497
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 1.914665937423706
Epoch: 18, Steps: 52 | Train Loss: 0.9612476 Vali Loss: 0.3413202 Test Loss: 0.2125499
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 1.9157755374908447
Epoch: 19, Steps: 52 | Train Loss: 0.9602955 Vali Loss: 0.3350175 Test Loss: 0.2125500
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 1.915686845779419
Epoch: 20, Steps: 52 | Train Loss: 0.9663202 Vali Loss: 0.3403834 Test Loss: 0.2125501
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 1.9269945621490479
Epoch: 21, Steps: 52 | Train Loss: 0.9586749 Vali Loss: 0.3326738 Test Loss: 0.2125501
Validation loss decreased (0.333039 --> 0.332674).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 1.922684669494629
Epoch: 22, Steps: 52 | Train Loss: 0.9599741 Vali Loss: 0.3389290 Test Loss: 0.2125501
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 1.9164233207702637
Epoch: 23, Steps: 52 | Train Loss: 0.9638994 Vali Loss: 0.3394294 Test Loss: 0.2125501
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 1.9157297611236572
Epoch: 24, Steps: 52 | Train Loss: 0.9650319 Vali Loss: 0.3418607 Test Loss: 0.2125501
EarlyStopping counter: 3 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 1.9164457321166992
Epoch: 25, Steps: 52 | Train Loss: 0.9542960 Vali Loss: 0.3455048 Test Loss: 0.2125501
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 1.9168589115142822
Epoch: 26, Steps: 52 | Train Loss: 0.9570344 Vali Loss: 0.3444310 Test Loss: 0.2125501
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 1.914717197418213
Epoch: 27, Steps: 52 | Train Loss: 0.9672720 Vali Loss: 0.3399369 Test Loss: 0.2125501
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 1.9280915260314941
Epoch: 28, Steps: 52 | Train Loss: 0.9556051 Vali Loss: 0.3351296 Test Loss: 0.2125501
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 1.9136543273925781
Epoch: 29, Steps: 52 | Train Loss: 0.9593017 Vali Loss: 0.3360394 Test Loss: 0.2125501
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 1.9159736633300781
Epoch: 30, Steps: 52 | Train Loss: 0.9549923 Vali Loss: 0.3428388 Test Loss: 0.2125501
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 1.910893201828003
Epoch: 31, Steps: 52 | Train Loss: 0.9840539 Vali Loss: 0.3411012 Test Loss: 0.2125501
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 1.9130346775054932
Epoch: 32, Steps: 52 | Train Loss: 0.9588568 Vali Loss: 0.3394409 Test Loss: 0.2125501
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 1.9153904914855957
Epoch: 33, Steps: 52 | Train Loss: 0.9639562 Vali Loss: 0.3441364 Test Loss: 0.2125501
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 1.9148664474487305
Epoch: 34, Steps: 52 | Train Loss: 0.9509612 Vali Loss: 0.3334728 Test Loss: 0.2125501
EarlyStopping counter: 13 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 1.914438247680664
Epoch: 35, Steps: 52 | Train Loss: 0.9591206 Vali Loss: 0.3395309 Test Loss: 0.2125501
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 1.915513277053833
Epoch: 36, Steps: 52 | Train Loss: 0.9595661 Vali Loss: 0.3377672 Test Loss: 0.2125501
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TimesNet_pl5_TimesNet_custom_ftMS_sl256_ll48_pl5_dm64_nh8_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2129, mae:0.3500, msIC:0.0147, msIR:0.0294
Total Evaluation 

MSE:0.2130Â±0.0041
MAE:0.3503Â±0.0035
msIC:0.0051Â±0.0097
msIR:0.0104Â±0.0194
  Evaluating TimesNet results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: Crossformer
  Training Crossformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Crossformer_pl5Model:              Crossformer         

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.6986141204833984
Epoch: 1, Steps: 52 | Train Loss: 1.1569573 Vali Loss: 0.3588528 Test Loss: 0.2209775
Validation loss decreased (inf --> 0.358853).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.6539723873138428
Epoch: 2, Steps: 52 | Train Loss: 1.0685935 Vali Loss: 0.3618688 Test Loss: 0.2251199
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.5802209377288818
Epoch: 3, Steps: 52 | Train Loss: 1.0482986 Vali Loss: 0.3441469 Test Loss: 0.2068724
Validation loss decreased (0.358853 --> 0.344147).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.6086664199829102
Epoch: 4, Steps: 52 | Train Loss: 1.0427438 Vali Loss: 0.3340372 Test Loss: 0.2103592
Validation loss decreased (0.344147 --> 0.334037).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.7278909683227539
Epoch: 5, Steps: 52 | Train Loss: 1.0310724 Vali Loss: 0.3341080 Test Loss: 0.2032859
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.6488790512084961
Epoch: 6, Steps: 52 | Train Loss: 1.0304054 Vali Loss: 0.3325774 Test Loss: 0.2034971
Validation loss decreased (0.334037 --> 0.332577).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.6144473552703857
Epoch: 7, Steps: 52 | Train Loss: 1.0411615 Vali Loss: 0.3371817 Test Loss: 0.2034096
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.6667301654815674
Epoch: 8, Steps: 52 | Train Loss: 1.0618867 Vali Loss: 0.3378472 Test Loss: 0.2031326
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.580986499786377
Epoch: 9, Steps: 52 | Train Loss: 1.0255665 Vali Loss: 0.3394009 Test Loss: 0.2030884
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.5808920860290527
Epoch: 10, Steps: 52 | Train Loss: 1.0277748 Vali Loss: 0.3282686 Test Loss: 0.2030319
Validation loss decreased (0.332577 --> 0.328269).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.59244704246521
Epoch: 11, Steps: 52 | Train Loss: 1.0609343 Vali Loss: 0.3350151 Test Loss: 0.2030285
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.5802571773529053
Epoch: 12, Steps: 52 | Train Loss: 1.0250505 Vali Loss: 0.3361645 Test Loss: 0.2030237
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.6329598426818848
Epoch: 13, Steps: 52 | Train Loss: 1.0222505 Vali Loss: 0.3443209 Test Loss: 0.2030212
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.6396887302398682
Epoch: 14, Steps: 52 | Train Loss: 1.0334726 Vali Loss: 0.3353167 Test Loss: 0.2030202
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.6799633502960205
Epoch: 15, Steps: 52 | Train Loss: 1.0283594 Vali Loss: 0.3314116 Test Loss: 0.2030222
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.6237432956695557
Epoch: 16, Steps: 52 | Train Loss: 1.0306021 Vali Loss: 0.3296804 Test Loss: 0.2030216
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.6435110569000244
Epoch: 17, Steps: 52 | Train Loss: 1.0311149 Vali Loss: 0.3379000 Test Loss: 0.2030220
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.5857510566711426
Epoch: 18, Steps: 52 | Train Loss: 1.0869315 Vali Loss: 0.3411733 Test Loss: 0.2030220
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.622520923614502
Epoch: 19, Steps: 52 | Train Loss: 1.0289323 Vali Loss: 0.3312286 Test Loss: 0.2030220
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.6071555614471436
Epoch: 20, Steps: 52 | Train Loss: 1.0563237 Vali Loss: 0.3311984 Test Loss: 0.2030220
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.5916860103607178
Epoch: 21, Steps: 52 | Train Loss: 1.0218413 Vali Loss: 0.3394233 Test Loss: 0.2030220
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.5801076889038086
Epoch: 22, Steps: 52 | Train Loss: 1.0242321 Vali Loss: 0.3322687 Test Loss: 0.2030220
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.5808448791503906
Epoch: 23, Steps: 52 | Train Loss: 1.0288196 Vali Loss: 0.3318300 Test Loss: 0.2030220
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.5807974338531494
Epoch: 24, Steps: 52 | Train Loss: 1.0285874 Vali Loss: 0.3361031 Test Loss: 0.2030220
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.57987380027771
Epoch: 25, Steps: 52 | Train Loss: 1.0283337 Vali Loss: 0.3350234 Test Loss: 0.2030220
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2035, mae:0.3424, msIC:-0.0100, msIR:-0.0207
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.5880904197692871
Epoch: 1, Steps: 52 | Train Loss: 1.1529012 Vali Loss: 0.3640248 Test Loss: 0.2310212
Validation loss decreased (inf --> 0.364025).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.6086087226867676
Epoch: 2, Steps: 52 | Train Loss: 1.0756934 Vali Loss: 0.3427815 Test Loss: 0.2104385
Validation loss decreased (0.364025 --> 0.342782).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.6018400192260742
Epoch: 3, Steps: 52 | Train Loss: 1.0468174 Vali Loss: 0.3483926 Test Loss: 0.2128237
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5856537818908691
Epoch: 4, Steps: 52 | Train Loss: 1.0369129 Vali Loss: 0.3442058 Test Loss: 0.2109685
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5838134288787842
Epoch: 5, Steps: 52 | Train Loss: 1.0274652 Vali Loss: 0.3446528 Test Loss: 0.2097362
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.6623296737670898
Epoch: 6, Steps: 52 | Train Loss: 1.1047432 Vali Loss: 0.3349684 Test Loss: 0.2038382
Validation loss decreased (0.342782 --> 0.334968).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.6072239875793457
Epoch: 7, Steps: 52 | Train Loss: 1.0513686 Vali Loss: 0.3396226 Test Loss: 0.2030037
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.5831196308135986
Epoch: 8, Steps: 52 | Train Loss: 1.0275117 Vali Loss: 0.3404905 Test Loss: 0.2030745
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5842576026916504
Epoch: 9, Steps: 52 | Train Loss: 1.0324894 Vali Loss: 0.3339398 Test Loss: 0.2030649
Validation loss decreased (0.334968 --> 0.333940).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.6260430812835693
Epoch: 10, Steps: 52 | Train Loss: 1.0253305 Vali Loss: 0.3316490 Test Loss: 0.2030644
Validation loss decreased (0.333940 --> 0.331649).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.621563196182251
Epoch: 11, Steps: 52 | Train Loss: 1.0239560 Vali Loss: 0.3322886 Test Loss: 0.2030866
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.5838432312011719
Epoch: 12, Steps: 52 | Train Loss: 1.0397059 Vali Loss: 0.3316619 Test Loss: 0.2030871
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.5851929187774658
Epoch: 13, Steps: 52 | Train Loss: 1.0211402 Vali Loss: 0.3318684 Test Loss: 0.2030818
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.5828728675842285
Epoch: 14, Steps: 52 | Train Loss: 1.0268560 Vali Loss: 0.3291232 Test Loss: 0.2030803
Validation loss decreased (0.331649 --> 0.329123).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.626326322555542
Epoch: 15, Steps: 52 | Train Loss: 1.0328718 Vali Loss: 0.3367768 Test Loss: 0.2030789
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.585385799407959
Epoch: 16, Steps: 52 | Train Loss: 1.0295795 Vali Loss: 0.3334997 Test Loss: 0.2030796
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.6442890167236328
Epoch: 17, Steps: 52 | Train Loss: 1.0330451 Vali Loss: 0.3319074 Test Loss: 0.2030799
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.6116917133331299
Epoch: 18, Steps: 52 | Train Loss: 1.0348494 Vali Loss: 0.3333073 Test Loss: 0.2030798
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.6025440692901611
Epoch: 19, Steps: 52 | Train Loss: 1.0242668 Vali Loss: 0.3381735 Test Loss: 0.2030798
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.5890142917633057
Epoch: 20, Steps: 52 | Train Loss: 1.0296146 Vali Loss: 0.3403831 Test Loss: 0.2030798
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.6850109100341797
Epoch: 21, Steps: 52 | Train Loss: 1.0291709 Vali Loss: 0.3397493 Test Loss: 0.2030798
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.6030139923095703
Epoch: 22, Steps: 52 | Train Loss: 1.0308247 Vali Loss: 0.3373611 Test Loss: 0.2030798
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.6017038822174072
Epoch: 23, Steps: 52 | Train Loss: 1.0277751 Vali Loss: 0.3361317 Test Loss: 0.2030798
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.6044497489929199
Epoch: 24, Steps: 52 | Train Loss: 1.0395446 Vali Loss: 0.3346621 Test Loss: 0.2030798
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.6544497013092041
Epoch: 25, Steps: 52 | Train Loss: 1.0300760 Vali Loss: 0.3349361 Test Loss: 0.2030798
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.613689661026001
Epoch: 26, Steps: 52 | Train Loss: 1.0279357 Vali Loss: 0.3333944 Test Loss: 0.2030798
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.583869457244873
Epoch: 27, Steps: 52 | Train Loss: 1.0703529 Vali Loss: 0.3398054 Test Loss: 0.2030798
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.5847129821777344
Epoch: 28, Steps: 52 | Train Loss: 1.0314982 Vali Loss: 0.3392057 Test Loss: 0.2030798
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.623892068862915
Epoch: 29, Steps: 52 | Train Loss: 1.0243894 Vali Loss: 0.3321216 Test Loss: 0.2030798
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2036, mae:0.3426, msIC:-0.0030, msIR:-0.0062
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.603515625
Epoch: 1, Steps: 52 | Train Loss: 1.2220879 Vali Loss: 0.3308374 Test Loss: 0.2090546
Validation loss decreased (inf --> 0.330837).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.6154520511627197
Epoch: 2, Steps: 52 | Train Loss: 1.0837105 Vali Loss: 0.3728219 Test Loss: 0.2383059
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.605457067489624
Epoch: 3, Steps: 52 | Train Loss: 1.0617287 Vali Loss: 0.3631266 Test Loss: 0.2249084
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5845937728881836
Epoch: 4, Steps: 52 | Train Loss: 1.0423376 Vali Loss: 0.3417852 Test Loss: 0.2048117
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.6379539966583252
Epoch: 5, Steps: 52 | Train Loss: 1.0331406 Vali Loss: 0.3375540 Test Loss: 0.2069932
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.6951689720153809
Epoch: 6, Steps: 52 | Train Loss: 1.0278775 Vali Loss: 0.3315236 Test Loss: 0.2029646
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.5940122604370117
Epoch: 7, Steps: 52 | Train Loss: 1.0332855 Vali Loss: 0.3345359 Test Loss: 0.2038600
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.584636926651001
Epoch: 8, Steps: 52 | Train Loss: 1.0246928 Vali Loss: 0.3336048 Test Loss: 0.2036346
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5933854579925537
Epoch: 9, Steps: 52 | Train Loss: 1.0885352 Vali Loss: 0.3347133 Test Loss: 0.2033109
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.587566614151001
Epoch: 10, Steps: 52 | Train Loss: 1.0270339 Vali Loss: 0.3371063 Test Loss: 0.2032950
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5837287902832031
Epoch: 11, Steps: 52 | Train Loss: 1.0336194 Vali Loss: 0.3338412 Test Loss: 0.2032756
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.5844039916992188
Epoch: 12, Steps: 52 | Train Loss: 1.0370312 Vali Loss: 0.3358472 Test Loss: 0.2032776
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.584376335144043
Epoch: 13, Steps: 52 | Train Loss: 1.0248403 Vali Loss: 0.3305437 Test Loss: 0.2032752
Validation loss decreased (0.330837 --> 0.330544).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.6086330413818359
Epoch: 14, Steps: 52 | Train Loss: 1.0308985 Vali Loss: 0.3354188 Test Loss: 0.2032669
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.6086926460266113
Epoch: 15, Steps: 52 | Train Loss: 1.0762401 Vali Loss: 0.3344363 Test Loss: 0.2032674
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.641993522644043
Epoch: 16, Steps: 52 | Train Loss: 1.0294190 Vali Loss: 0.3365381 Test Loss: 0.2032677
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.6102578639984131
Epoch: 17, Steps: 52 | Train Loss: 1.0336728 Vali Loss: 0.3349076 Test Loss: 0.2032674
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.6038088798522949
Epoch: 18, Steps: 52 | Train Loss: 1.0745971 Vali Loss: 0.3333739 Test Loss: 0.2032672
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.5982077121734619
Epoch: 19, Steps: 52 | Train Loss: 1.0904173 Vali Loss: 0.3273294 Test Loss: 0.2032672
Validation loss decreased (0.330544 --> 0.327329).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.6071887016296387
Epoch: 20, Steps: 52 | Train Loss: 1.0284076 Vali Loss: 0.3279610 Test Loss: 0.2032672
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.6421959400177002
Epoch: 21, Steps: 52 | Train Loss: 1.0279954 Vali Loss: 0.3327304 Test Loss: 0.2032672
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.6812846660614014
Epoch: 22, Steps: 52 | Train Loss: 1.0285189 Vali Loss: 0.3371161 Test Loss: 0.2032672
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.6254968643188477
Epoch: 23, Steps: 52 | Train Loss: 1.0228243 Vali Loss: 0.3367546 Test Loss: 0.2032672
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.6291229724884033
Epoch: 24, Steps: 52 | Train Loss: 1.0255549 Vali Loss: 0.3311228 Test Loss: 0.2032672
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.584174394607544
Epoch: 25, Steps: 52 | Train Loss: 1.0333682 Vali Loss: 0.3441999 Test Loss: 0.2032672
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.5832772254943848
Epoch: 26, Steps: 52 | Train Loss: 1.0417764 Vali Loss: 0.3348053 Test Loss: 0.2032672
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.5854525566101074
Epoch: 27, Steps: 52 | Train Loss: 1.0574215 Vali Loss: 0.3401116 Test Loss: 0.2032672
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.5842247009277344
Epoch: 28, Steps: 52 | Train Loss: 1.0345739 Vali Loss: 0.3362591 Test Loss: 0.2032672
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.5830788612365723
Epoch: 29, Steps: 52 | Train Loss: 1.0342921 Vali Loss: 0.3393977 Test Loss: 0.2032672
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.5849778652191162
Epoch: 30, Steps: 52 | Train Loss: 1.0593555 Vali Loss: 0.3342361 Test Loss: 0.2032672
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.5847451686859131
Epoch: 31, Steps: 52 | Train Loss: 1.0271916 Vali Loss: 0.3320566 Test Loss: 0.2032672
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.6127257347106934
Epoch: 32, Steps: 52 | Train Loss: 1.0268132 Vali Loss: 0.3341466 Test Loss: 0.2032672
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.5840494632720947
Epoch: 33, Steps: 52 | Train Loss: 1.0561065 Vali Loss: 0.3411460 Test Loss: 0.2032672
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.5840182304382324
Epoch: 34, Steps: 52 | Train Loss: 1.0226097 Vali Loss: 0.3299104 Test Loss: 0.2032672
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Crossformer_pl5_Crossformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc1_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2037, mae:0.3420, msIC:-0.0104, msIR:-0.0203
Total Evaluation 

MSE:0.2036Â±0.0001
MAE:0.3423Â±0.0002
msIC:-0.0078Â±0.0034
msIR:-0.0157Â±0.0067
  Evaluating Crossformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: TSMixer
  Training TSMixer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_TSMixer_pl5Model:              TSMixer             

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.1539597511291504
Epoch: 1, Steps: 52 | Train Loss: 1.3470821 Vali Loss: 0.4676357 Test Loss: 0.2320484
Validation loss decreased (inf --> 0.467636).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.0968177318572998
Epoch: 2, Steps: 52 | Train Loss: 1.0822095 Vali Loss: 0.4170603 Test Loss: 0.2200671
Validation loss decreased (0.467636 --> 0.417060).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.13204336166381836
Epoch: 3, Steps: 52 | Train Loss: 1.0068824 Vali Loss: 0.4097122 Test Loss: 0.2198604
Validation loss decreased (0.417060 --> 0.409712).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.142380952835083
Epoch: 4, Steps: 52 | Train Loss: 0.9854100 Vali Loss: 0.4152390 Test Loss: 0.2194188
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.07968497276306152
Epoch: 5, Steps: 52 | Train Loss: 0.9749238 Vali Loss: 0.4198232 Test Loss: 0.2196847
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.07029342651367188
Epoch: 6, Steps: 52 | Train Loss: 1.0048961 Vali Loss: 0.4183708 Test Loss: 0.2198117
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.07017087936401367
Epoch: 7, Steps: 52 | Train Loss: 0.9700859 Vali Loss: 0.4090261 Test Loss: 0.2198578
Validation loss decreased (0.409712 --> 0.409026).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.11706662178039551
Epoch: 8, Steps: 52 | Train Loss: 0.9713075 Vali Loss: 0.4021394 Test Loss: 0.2198897
Validation loss decreased (0.409026 --> 0.402139).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.13278818130493164
Epoch: 9, Steps: 52 | Train Loss: 0.9731681 Vali Loss: 0.4162846 Test Loss: 0.2198905
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.12906956672668457
Epoch: 10, Steps: 52 | Train Loss: 1.0105717 Vali Loss: 0.4097799 Test Loss: 0.2199006
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.12242984771728516
Epoch: 11, Steps: 52 | Train Loss: 0.9747569 Vali Loss: 0.4159354 Test Loss: 0.2199106
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.09582972526550293
Epoch: 12, Steps: 52 | Train Loss: 0.9776394 Vali Loss: 0.4059798 Test Loss: 0.2199143
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.13545775413513184
Epoch: 13, Steps: 52 | Train Loss: 0.9661088 Vali Loss: 0.4048520 Test Loss: 0.2199164
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.12567830085754395
Epoch: 14, Steps: 52 | Train Loss: 0.9685491 Vali Loss: 0.4184887 Test Loss: 0.2199167
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.0857548713684082
Epoch: 15, Steps: 52 | Train Loss: 0.9670586 Vali Loss: 0.4079283 Test Loss: 0.2199173
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.07828879356384277
Epoch: 16, Steps: 52 | Train Loss: 0.9732548 Vali Loss: 0.4056781 Test Loss: 0.2199175
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.07543802261352539
Epoch: 17, Steps: 52 | Train Loss: 0.9699154 Vali Loss: 0.4102100 Test Loss: 0.2199175
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.08143734931945801
Epoch: 18, Steps: 52 | Train Loss: 0.9841489 Vali Loss: 0.4049883 Test Loss: 0.2199175
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.13757705688476562
Epoch: 19, Steps: 52 | Train Loss: 0.9712800 Vali Loss: 0.4068422 Test Loss: 0.2199175
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13744521141052246
Epoch: 20, Steps: 52 | Train Loss: 0.9688800 Vali Loss: 0.4077643 Test Loss: 0.2199175
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.1029665470123291
Epoch: 21, Steps: 52 | Train Loss: 0.9673613 Vali Loss: 0.4064413 Test Loss: 0.2199175
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.07016277313232422
Epoch: 22, Steps: 52 | Train Loss: 0.9615726 Vali Loss: 0.4156697 Test Loss: 0.2199175
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.07049155235290527
Epoch: 23, Steps: 52 | Train Loss: 0.9673607 Vali Loss: 0.4010209 Test Loss: 0.2199175
Validation loss decreased (0.402139 --> 0.401021).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.0702822208404541
Epoch: 24, Steps: 52 | Train Loss: 0.9724783 Vali Loss: 0.3987265 Test Loss: 0.2199175
Validation loss decreased (0.401021 --> 0.398727).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.09667468070983887
Epoch: 25, Steps: 52 | Train Loss: 0.9632624 Vali Loss: 0.4071029 Test Loss: 0.2199175
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.12981677055358887
Epoch: 26, Steps: 52 | Train Loss: 0.9716680 Vali Loss: 0.4072795 Test Loss: 0.2199175
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13000059127807617
Epoch: 27, Steps: 52 | Train Loss: 0.9741711 Vali Loss: 0.4088231 Test Loss: 0.2199175
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.13205170631408691
Epoch: 28, Steps: 52 | Train Loss: 0.9639266 Vali Loss: 0.4002842 Test Loss: 0.2199175
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.1264333724975586
Epoch: 29, Steps: 52 | Train Loss: 0.9715930 Vali Loss: 0.4181037 Test Loss: 0.2199175
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.13881206512451172
Epoch: 30, Steps: 52 | Train Loss: 0.9646945 Vali Loss: 0.4102823 Test Loss: 0.2199175
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.13884305953979492
Epoch: 31, Steps: 52 | Train Loss: 0.9691652 Vali Loss: 0.4069010 Test Loss: 0.2199175
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.12499618530273438
Epoch: 32, Steps: 52 | Train Loss: 0.9663345 Vali Loss: 0.4104095 Test Loss: 0.2199175
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.12924909591674805
Epoch: 33, Steps: 52 | Train Loss: 0.9658907 Vali Loss: 0.4251787 Test Loss: 0.2199175
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.12168049812316895
Epoch: 34, Steps: 52 | Train Loss: 0.9676354 Vali Loss: 0.4097922 Test Loss: 0.2199175
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.1220555305480957
Epoch: 35, Steps: 52 | Train Loss: 0.9794834 Vali Loss: 0.4099066 Test Loss: 0.2199175
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.09678912162780762
Epoch: 36, Steps: 52 | Train Loss: 0.9688156 Vali Loss: 0.4116871 Test Loss: 0.2199175
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.09556388854980469
Epoch: 37, Steps: 52 | Train Loss: 0.9661792 Vali Loss: 0.4049288 Test Loss: 0.2199175
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.08087658882141113
Epoch: 38, Steps: 52 | Train Loss: 0.9713532 Vali Loss: 0.4085016 Test Loss: 0.2199175
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.13787460327148438
Epoch: 39, Steps: 52 | Train Loss: 0.9737451 Vali Loss: 0.4087966 Test Loss: 0.2199175
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2204, mae:0.3600, msIC:0.0215, msIR:0.0432
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.11179590225219727
Epoch: 1, Steps: 52 | Train Loss: 1.2585127 Vali Loss: 0.4673581 Test Loss: 0.2525036
Validation loss decreased (inf --> 0.467358).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.11449670791625977
Epoch: 2, Steps: 52 | Train Loss: 1.0546861 Vali Loss: 0.4176763 Test Loss: 0.2389563
Validation loss decreased (0.467358 --> 0.417676).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.12557077407836914
Epoch: 3, Steps: 52 | Train Loss: 0.9984906 Vali Loss: 0.4151380 Test Loss: 0.2347709
Validation loss decreased (0.417676 --> 0.415138).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.10098028182983398
Epoch: 4, Steps: 52 | Train Loss: 0.9846298 Vali Loss: 0.4209996 Test Loss: 0.2351922
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.13509774208068848
Epoch: 5, Steps: 52 | Train Loss: 0.9622686 Vali Loss: 0.4093477 Test Loss: 0.2353674
Validation loss decreased (0.415138 --> 0.409348).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.12835693359375
Epoch: 6, Steps: 52 | Train Loss: 0.9634915 Vali Loss: 0.4261173 Test Loss: 0.2358671
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.13564658164978027
Epoch: 7, Steps: 52 | Train Loss: 0.9592932 Vali Loss: 0.4225633 Test Loss: 0.2361108
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.13470053672790527
Epoch: 8, Steps: 52 | Train Loss: 0.9686380 Vali Loss: 0.4135859 Test Loss: 0.2361110
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.10542058944702148
Epoch: 9, Steps: 52 | Train Loss: 0.9700198 Vali Loss: 0.4224664 Test Loss: 0.2361776
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.09724950790405273
Epoch: 10, Steps: 52 | Train Loss: 0.9544977 Vali Loss: 0.4232878 Test Loss: 0.2362138
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.11408042907714844
Epoch: 11, Steps: 52 | Train Loss: 0.9514728 Vali Loss: 0.4155244 Test Loss: 0.2362062
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.13640642166137695
Epoch: 12, Steps: 52 | Train Loss: 1.0077686 Vali Loss: 0.4272321 Test Loss: 0.2362131
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.09589600563049316
Epoch: 13, Steps: 52 | Train Loss: 0.9654863 Vali Loss: 0.4245702 Test Loss: 0.2362168
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.08014702796936035
Epoch: 14, Steps: 52 | Train Loss: 0.9559096 Vali Loss: 0.4169108 Test Loss: 0.2362186
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.10412406921386719
Epoch: 15, Steps: 52 | Train Loss: 0.9772681 Vali Loss: 0.4166638 Test Loss: 0.2362197
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.13810276985168457
Epoch: 16, Steps: 52 | Train Loss: 0.9605005 Vali Loss: 0.4196095 Test Loss: 0.2362196
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.11808967590332031
Epoch: 17, Steps: 52 | Train Loss: 0.9643084 Vali Loss: 0.4224727 Test Loss: 0.2362199
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.07796955108642578
Epoch: 18, Steps: 52 | Train Loss: 0.9892322 Vali Loss: 0.4135744 Test Loss: 0.2362200
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.12555408477783203
Epoch: 19, Steps: 52 | Train Loss: 0.9582534 Vali Loss: 0.4248782 Test Loss: 0.2362200
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13638806343078613
Epoch: 20, Steps: 52 | Train Loss: 0.9535952 Vali Loss: 0.4190464 Test Loss: 0.2362200
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2358, mae:0.3731, msIC:0.0025, msIR:0.0050
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.09175610542297363
Epoch: 1, Steps: 52 | Train Loss: 1.2526594 Vali Loss: 0.4168382 Test Loss: 0.2306194
Validation loss decreased (inf --> 0.416838).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.12671136856079102
Epoch: 2, Steps: 52 | Train Loss: 1.0631483 Vali Loss: 0.3881144 Test Loss: 0.2255358
Validation loss decreased (0.416838 --> 0.388114).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.12025880813598633
Epoch: 3, Steps: 52 | Train Loss: 1.0261607 Vali Loss: 0.3906054 Test Loss: 0.2255149
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.07878756523132324
Epoch: 4, Steps: 52 | Train Loss: 0.9985457 Vali Loss: 0.3885377 Test Loss: 0.2252175
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.0765531063079834
Epoch: 5, Steps: 52 | Train Loss: 0.9876683 Vali Loss: 0.3798714 Test Loss: 0.2256370
Validation loss decreased (0.388114 --> 0.379871).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.12557435035705566
Epoch: 6, Steps: 52 | Train Loss: 1.0024188 Vali Loss: 0.4017778 Test Loss: 0.2262455
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.07813382148742676
Epoch: 7, Steps: 52 | Train Loss: 0.9902184 Vali Loss: 0.3946540 Test Loss: 0.2268948
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.07640337944030762
Epoch: 8, Steps: 52 | Train Loss: 0.9722616 Vali Loss: 0.3844482 Test Loss: 0.2270103
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.09351801872253418
Epoch: 9, Steps: 52 | Train Loss: 0.9789892 Vali Loss: 0.3857476 Test Loss: 0.2270432
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.14182686805725098
Epoch: 10, Steps: 52 | Train Loss: 1.0102302 Vali Loss: 0.3907974 Test Loss: 0.2270702
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.12301182746887207
Epoch: 11, Steps: 52 | Train Loss: 0.9708594 Vali Loss: 0.3940748 Test Loss: 0.2270920
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.09888052940368652
Epoch: 12, Steps: 52 | Train Loss: 0.9763790 Vali Loss: 0.3992046 Test Loss: 0.2270994
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.10091662406921387
Epoch: 13, Steps: 52 | Train Loss: 0.9894007 Vali Loss: 0.3956245 Test Loss: 0.2271002
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.1036825180053711
Epoch: 14, Steps: 52 | Train Loss: 0.9747625 Vali Loss: 0.3915764 Test Loss: 0.2271025
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.09455370903015137
Epoch: 15, Steps: 52 | Train Loss: 0.9759078 Vali Loss: 0.3896876 Test Loss: 0.2271035
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.09591245651245117
Epoch: 16, Steps: 52 | Train Loss: 0.9677774 Vali Loss: 0.3879790 Test Loss: 0.2271042
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.11779117584228516
Epoch: 17, Steps: 52 | Train Loss: 0.9674458 Vali Loss: 0.3887953 Test Loss: 0.2271042
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13463973999023438
Epoch: 18, Steps: 52 | Train Loss: 0.9695531 Vali Loss: 0.3884187 Test Loss: 0.2271043
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.13232922554016113
Epoch: 19, Steps: 52 | Train Loss: 0.9726630 Vali Loss: 0.3959979 Test Loss: 0.2271043
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13716864585876465
Epoch: 20, Steps: 52 | Train Loss: 0.9725827 Vali Loss: 0.3945957 Test Loss: 0.2271043
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_TSMixer_pl5_TSMixer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2259, mae:0.3593, msIC:-0.0109, msIR:-0.0224
Total Evaluation 

MSE:0.2274Â±0.0064
MAE:0.3641Â±0.0064
msIC:0.0044Â±0.0133
msIR:0.0086Â±0.0269
  Evaluating TSMixer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: Koopa
  Training Koopa...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Koopa_pl5  Model:              Koopa               

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.001               
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 1641
>>>>>>>start training : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 7.4146599769592285
Epoch: 1, Steps: 52 | Train Loss: 1.0818283 Vali Loss: 0.4143092 Test Loss: 0.2351698
Validation loss decreased (inf --> 0.414309).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.233773946762085
Epoch: 2, Steps: 52 | Train Loss: 1.0392607 Vali Loss: 0.4215855 Test Loss: 0.2225609
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.217282295227051
Epoch: 3, Steps: 52 | Train Loss: 0.9683814 Vali Loss: 0.4633986 Test Loss: 0.2288016
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.221419811248779
Epoch: 4, Steps: 52 | Train Loss: 0.9144625 Vali Loss: 0.4443498 Test Loss: 0.2299457
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.2284135818481445
Epoch: 5, Steps: 52 | Train Loss: 0.8830580 Vali Loss: 0.4455680 Test Loss: 0.2303125
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.238059043884277
Epoch: 6, Steps: 52 | Train Loss: 0.8630166 Vali Loss: 0.4582284 Test Loss: 0.2306259
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.232557058334351
Epoch: 7, Steps: 52 | Train Loss: 0.8629231 Vali Loss: 0.4551734 Test Loss: 0.2308619
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.235121965408325
Epoch: 8, Steps: 52 | Train Loss: 0.8570575 Vali Loss: 0.4532335 Test Loss: 0.2311191
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.234044075012207
Epoch: 9, Steps: 52 | Train Loss: 0.8531803 Vali Loss: 0.4647523 Test Loss: 0.2313350
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.232100009918213
Epoch: 10, Steps: 52 | Train Loss: 0.8800159 Vali Loss: 0.4585401 Test Loss: 0.2313155
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.229972839355469
Epoch: 11, Steps: 52 | Train Loss: 0.8997929 Vali Loss: 0.4518067 Test Loss: 0.2313620
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.226505279541016
Epoch: 12, Steps: 52 | Train Loss: 0.8506816 Vali Loss: 0.4651547 Test Loss: 0.2313519
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 7.2358245849609375
Epoch: 13, Steps: 52 | Train Loss: 0.8946165 Vali Loss: 0.4566389 Test Loss: 0.2313423
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.239708423614502
Epoch: 14, Steps: 52 | Train Loss: 0.8597202 Vali Loss: 0.4677973 Test Loss: 0.2313421
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.234125375747681
Epoch: 15, Steps: 52 | Train Loss: 0.8537202 Vali Loss: 0.4513754 Test Loss: 0.2313456
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.2334020137786865
Epoch: 16, Steps: 52 | Train Loss: 0.8511354 Vali Loss: 0.4592210 Test Loss: 0.2313459
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2357, mae:0.3667, msIC:-0.0258, msIR:-0.0506
Use GPU: cuda:0
train 1641
>>>>>>>start training : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 7.247930288314819
Epoch: 1, Steps: 52 | Train Loss: 1.1373638 Vali Loss: 0.4051457 Test Loss: 0.2147347
Validation loss decreased (inf --> 0.405146).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.235658168792725
Epoch: 2, Steps: 52 | Train Loss: 1.0285916 Vali Loss: 0.4437162 Test Loss: 0.2285101
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.23483681678772
Epoch: 3, Steps: 52 | Train Loss: 0.9678265 Vali Loss: 0.4206191 Test Loss: 0.2248385
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.234774112701416
Epoch: 4, Steps: 52 | Train Loss: 0.9197492 Vali Loss: 0.4206852 Test Loss: 0.2250114
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.228842496871948
Epoch: 5, Steps: 52 | Train Loss: 0.8947942 Vali Loss: 0.4257216 Test Loss: 0.2273798
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.222245216369629
Epoch: 6, Steps: 52 | Train Loss: 0.8714810 Vali Loss: 0.4374191 Test Loss: 0.2282193
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.239604473114014
Epoch: 7, Steps: 52 | Train Loss: 0.8834099 Vali Loss: 0.4412640 Test Loss: 0.2286978
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.226685523986816
Epoch: 8, Steps: 52 | Train Loss: 0.8633761 Vali Loss: 0.4378015 Test Loss: 0.2284782
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.226576328277588
Epoch: 9, Steps: 52 | Train Loss: 0.8623412 Vali Loss: 0.4367109 Test Loss: 0.2285642
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.235005855560303
Epoch: 10, Steps: 52 | Train Loss: 0.8607260 Vali Loss: 0.4254873 Test Loss: 0.2286848
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.237381935119629
Epoch: 11, Steps: 52 | Train Loss: 0.9316541 Vali Loss: 0.4351455 Test Loss: 0.2286913
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.233426809310913
Epoch: 12, Steps: 52 | Train Loss: 0.8670475 Vali Loss: 0.4307318 Test Loss: 0.2286955
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 7.222431898117065
Epoch: 13, Steps: 52 | Train Loss: 0.8620443 Vali Loss: 0.4425670 Test Loss: 0.2286898
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.218775510787964
Epoch: 14, Steps: 52 | Train Loss: 0.8578780 Vali Loss: 0.4288402 Test Loss: 0.2286874
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.232606410980225
Epoch: 15, Steps: 52 | Train Loss: 0.8603739 Vali Loss: 0.4399654 Test Loss: 0.2286900
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.219706296920776
Epoch: 16, Steps: 52 | Train Loss: 0.8646723 Vali Loss: 0.4282118 Test Loss: 0.2286885
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2153, mae:0.3506, msIC:0.0522, msIR:0.1052
Use GPU: cuda:0
train 1641
>>>>>>>start training : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 7.234309911727905
Epoch: 1, Steps: 52 | Train Loss: 1.1755099 Vali Loss: 0.4053237 Test Loss: 0.2203522
Validation loss decreased (inf --> 0.405324).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.241865873336792
Epoch: 2, Steps: 52 | Train Loss: 1.0510704 Vali Loss: 0.4340905 Test Loss: 0.2304402
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.239025354385376
Epoch: 3, Steps: 52 | Train Loss: 0.9878793 Vali Loss: 0.4353883 Test Loss: 0.2270994
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.239848852157593
Epoch: 4, Steps: 52 | Train Loss: 0.9146905 Vali Loss: 0.4594049 Test Loss: 0.2253938
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.234426498413086
Epoch: 5, Steps: 52 | Train Loss: 0.9265937 Vali Loss: 0.4567758 Test Loss: 0.2261353
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.252593040466309
Epoch: 6, Steps: 52 | Train Loss: 0.8796486 Vali Loss: 0.4560896 Test Loss: 0.2283425
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.236292362213135
Epoch: 7, Steps: 52 | Train Loss: 0.8694618 Vali Loss: 0.4614081 Test Loss: 0.2283894
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.234565496444702
Epoch: 8, Steps: 52 | Train Loss: 0.8743128 Vali Loss: 0.4527239 Test Loss: 0.2286050
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.2316734790802
Epoch: 9, Steps: 52 | Train Loss: 0.8695797 Vali Loss: 0.4588615 Test Loss: 0.2286417
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.245290040969849
Epoch: 10, Steps: 52 | Train Loss: 0.8784905 Vali Loss: 0.4547801 Test Loss: 0.2286949
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.234142303466797
Epoch: 11, Steps: 52 | Train Loss: 0.8720556 Vali Loss: 0.4581073 Test Loss: 0.2287021
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.2381556034088135
Epoch: 12, Steps: 52 | Train Loss: 0.8692209 Vali Loss: 0.4546945 Test Loss: 0.2287057
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 7.2273266315460205
Epoch: 13, Steps: 52 | Train Loss: 0.8671263 Vali Loss: 0.4575571 Test Loss: 0.2287094
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.238214731216431
Epoch: 14, Steps: 52 | Train Loss: 0.8662260 Vali Loss: 0.4566090 Test Loss: 0.2287151
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.278884410858154
Epoch: 15, Steps: 52 | Train Loss: 0.8575257 Vali Loss: 0.4547353 Test Loss: 0.2287168
EarlyStopping counter: 14 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.290614604949951
Epoch: 16, Steps: 52 | Train Loss: 0.8700627 Vali Loss: 0.4497766 Test Loss: 0.2287171
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Koopa_pl5_Koopa_custom_ftMS_sl256_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2207, mae:0.3563, msIC:0.0239, msIR:0.0473
Total Evaluation 

MSE:0.2239Â±0.0086
MAE:0.3579Â±0.0067
msIC:0.0168Â±0.0322
msIR:0.0340Â±0.0643
  Evaluating Koopa results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[RECENT10] Model: Nonstationary_Transformer
  Training Nonstationary_Transformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           RECENT10_Nonstationary_Transformer_pl5Model:              Nonstationary_Transformer

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2015.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            256                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            64                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                RECENT10            Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      256, 256            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.7714145183563232
Epoch: 1, Steps: 52 | Train Loss: 1.1500178 Vali Loss: 0.3368828 Test Loss: 0.2047959
Validation loss decreased (inf --> 0.336883).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.35066771507263184
Epoch: 2, Steps: 52 | Train Loss: 1.0450931 Vali Loss: 0.3425287 Test Loss: 0.2080609
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.3569512367248535
Epoch: 3, Steps: 52 | Train Loss: 1.0595798 Vali Loss: 0.3399583 Test Loss: 0.2054841
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5403876304626465
Epoch: 4, Steps: 52 | Train Loss: 1.0078011 Vali Loss: 0.3413027 Test Loss: 0.2039159
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.40467214584350586
Epoch: 5, Steps: 52 | Train Loss: 1.0007016 Vali Loss: 0.3461380 Test Loss: 0.2036965
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.48061108589172363
Epoch: 6, Steps: 52 | Train Loss: 1.0049986 Vali Loss: 0.3474865 Test Loss: 0.2037067
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2754044532775879
Epoch: 7, Steps: 52 | Train Loss: 0.9940431 Vali Loss: 0.3493910 Test Loss: 0.2037260
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.3199198246002197
Epoch: 8, Steps: 52 | Train Loss: 0.9920758 Vali Loss: 0.3488216 Test Loss: 0.2037730
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.3731565475463867
Epoch: 9, Steps: 52 | Train Loss: 0.9928208 Vali Loss: 0.3435117 Test Loss: 0.2038276
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.4513218402862549
Epoch: 10, Steps: 52 | Train Loss: 0.9907365 Vali Loss: 0.3601834 Test Loss: 0.2038452
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5490682125091553
Epoch: 11, Steps: 52 | Train Loss: 0.9978929 Vali Loss: 0.3502501 Test Loss: 0.2038438
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.33692002296447754
Epoch: 12, Steps: 52 | Train Loss: 1.0245509 Vali Loss: 0.3532752 Test Loss: 0.2038419
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2647373676300049
Epoch: 13, Steps: 52 | Train Loss: 0.9953790 Vali Loss: 0.3500363 Test Loss: 0.2038392
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.47278404235839844
Epoch: 14, Steps: 52 | Train Loss: 0.9911866 Vali Loss: 0.3508773 Test Loss: 0.2038393
EarlyStopping counter: 13 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.5489592552185059
Epoch: 15, Steps: 52 | Train Loss: 1.0015894 Vali Loss: 0.3495855 Test Loss: 0.2038390
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.2627289295196533
Epoch: 16, Steps: 52 | Train Loss: 0.9998508 Vali Loss: 0.3530526 Test Loss: 0.2038391
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2053, mae:0.3424, msIC:0.0397, msIR:0.0813
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.33197593688964844
Epoch: 1, Steps: 52 | Train Loss: 1.1418697 Vali Loss: 0.3651064 Test Loss: 0.2089936
Validation loss decreased (inf --> 0.365106).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.3417692184448242
Epoch: 2, Steps: 52 | Train Loss: 1.0432441 Vali Loss: 0.3572232 Test Loss: 0.2084314
Validation loss decreased (0.365106 --> 0.357223).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.4739878177642822
Epoch: 3, Steps: 52 | Train Loss: 1.0113798 Vali Loss: 0.3538421 Test Loss: 0.2089172
Validation loss decreased (0.357223 --> 0.353842).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.3143501281738281
Epoch: 4, Steps: 52 | Train Loss: 1.0171672 Vali Loss: 0.3613447 Test Loss: 0.2114760
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2623422145843506
Epoch: 5, Steps: 52 | Train Loss: 0.9975723 Vali Loss: 0.3805493 Test Loss: 0.2154669
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2629268169403076
Epoch: 6, Steps: 52 | Train Loss: 0.9942773 Vali Loss: 0.3786454 Test Loss: 0.2159608
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2847731113433838
Epoch: 7, Steps: 52 | Train Loss: 0.9867866 Vali Loss: 0.3777378 Test Loss: 0.2155971
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.2940378189086914
Epoch: 8, Steps: 52 | Train Loss: 0.9923137 Vali Loss: 0.3741514 Test Loss: 0.2159793
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.511124849319458
Epoch: 9, Steps: 52 | Train Loss: 0.9809410 Vali Loss: 0.3701369 Test Loss: 0.2161523
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.4908576011657715
Epoch: 10, Steps: 52 | Train Loss: 0.9811817 Vali Loss: 0.3694355 Test Loss: 0.2162645
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.3270113468170166
Epoch: 11, Steps: 52 | Train Loss: 0.9859822 Vali Loss: 0.3759607 Test Loss: 0.2162561
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.28107237815856934
Epoch: 12, Steps: 52 | Train Loss: 0.9923149 Vali Loss: 0.3829016 Test Loss: 0.2163282
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.27815985679626465
Epoch: 13, Steps: 52 | Train Loss: 0.9830387 Vali Loss: 0.3847171 Test Loss: 0.2163343
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2888612747192383
Epoch: 14, Steps: 52 | Train Loss: 0.9854549 Vali Loss: 0.3775202 Test Loss: 0.2163519
EarlyStopping counter: 11 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.27118659019470215
Epoch: 15, Steps: 52 | Train Loss: 0.9980947 Vali Loss: 0.3712738 Test Loss: 0.2163544
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.3032801151275635
Epoch: 16, Steps: 52 | Train Loss: 0.9944694 Vali Loss: 0.3716564 Test Loss: 0.2163569
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.2661864757537842
Epoch: 17, Steps: 52 | Train Loss: 0.9868571 Vali Loss: 0.3776636 Test Loss: 0.2163573
EarlyStopping counter: 14 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.3072512149810791
Epoch: 18, Steps: 52 | Train Loss: 0.9970109 Vali Loss: 0.3759364 Test Loss: 0.2163577
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2094, mae:0.3454, msIC:0.0200, msIR:0.0404
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 1641
val 269
test 539
Epoch: 1 cost time: 0.26767396926879883
Epoch: 1, Steps: 52 | Train Loss: 1.1313112 Vali Loss: 0.3433360 Test Loss: 0.2047353
Validation loss decreased (inf --> 0.343336).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.3181145191192627
Epoch: 2, Steps: 52 | Train Loss: 1.0320347 Vali Loss: 0.3509356 Test Loss: 0.2060967
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2858774662017822
Epoch: 3, Steps: 52 | Train Loss: 1.0182686 Vali Loss: 0.3437212 Test Loss: 0.2066433
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5395689010620117
Epoch: 4, Steps: 52 | Train Loss: 1.0206380 Vali Loss: 0.3627788 Test Loss: 0.2047311
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5761985778808594
Epoch: 5, Steps: 52 | Train Loss: 1.0054813 Vali Loss: 0.3702943 Test Loss: 0.2046031
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5084474086761475
Epoch: 6, Steps: 52 | Train Loss: 1.0051044 Vali Loss: 0.3689880 Test Loss: 0.2052348
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.3123588562011719
Epoch: 7, Steps: 52 | Train Loss: 1.0038321 Vali Loss: 0.3563799 Test Loss: 0.2052897
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.26947712898254395
Epoch: 8, Steps: 52 | Train Loss: 0.9993322 Vali Loss: 0.3680771 Test Loss: 0.2053746
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.26572299003601074
Epoch: 9, Steps: 52 | Train Loss: 0.9945460 Vali Loss: 0.3588852 Test Loss: 0.2053202
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.2705502510070801
Epoch: 10, Steps: 52 | Train Loss: 1.0010704 Vali Loss: 0.3524297 Test Loss: 0.2053320
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.26584386825561523
Epoch: 11, Steps: 52 | Train Loss: 0.9923298 Vali Loss: 0.3629979 Test Loss: 0.2053497
EarlyStopping counter: 10 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.26606297492980957
Epoch: 12, Steps: 52 | Train Loss: 1.0402109 Vali Loss: 0.3704181 Test Loss: 0.2053457
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.282545804977417
Epoch: 13, Steps: 52 | Train Loss: 0.9945143 Vali Loss: 0.3655295 Test Loss: 0.2053486
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2642223834991455
Epoch: 14, Steps: 52 | Train Loss: 1.0020236 Vali Loss: 0.3657780 Test Loss: 0.2053480
EarlyStopping counter: 13 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.26413798332214355
Epoch: 15, Steps: 52 | Train Loss: 1.0127327 Vali Loss: 0.3616441 Test Loss: 0.2053476
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.2697947025299072
Epoch: 16, Steps: 52 | Train Loss: 0.9899572 Vali Loss: 0.3577032 Test Loss: 0.2053479
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_RECENT10_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl256_ll48_pl5_dm64_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_RECENT10_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 539
test shape: (539, 5, 1) (539, 5, 1)
test shape: (539, 5, 1) (539, 5, 1)
mse:0.2053, mae:0.3454, msIC:0.0018, msIR:0.0036
Total Evaluation 

MSE:0.2067Â±0.0019
MAE:0.3444Â±0.0014
msIC:0.0205Â±0.0155
msIR:0.0418Â±0.0317
  Evaluating Nonstationary_Transformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

==============================================================
PERIOD: POST_COVID
Data: WTI-log-2020.csv | SeqLen: 128 | D_Model: 32
==============================================================

[POST_COVID] Model: Naive
  Training Naive...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Naive_pl5Model:              Naive               

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       1                   Batch Size:         32                  
  Patience:           7                   Learning Rate:      0.0002              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.08304238319396973
Epoch: 1, Steps: 28 | Train Loss: 0.8914893 Vali Loss: 0.2109582 Test Loss: 0.3598356
Validation loss decreased (inf --> 0.210958).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.3601, mae:0.4563, msIC:0.0309, msIR:0.0620
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.01813483238220215
Epoch: 1, Steps: 28 | Train Loss: 0.8926595 Vali Loss: 0.2167404 Test Loss: 0.3598406
Validation loss decreased (inf --> 0.216740).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.3601, mae:0.4563, msIC:0.0096, msIR:0.0191
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.017722129821777344
Epoch: 1, Steps: 28 | Train Loss: 0.8917031 Vali Loss: 0.2154056 Test Loss: 0.3598328
Validation loss decreased (inf --> 0.215406).  Saving model ...
Updating learning rate to 0.0002
>>>>>>>testing : long_term_forecast_POST_COVID_Naive_pl5_Naive_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.3601, mae:0.4563, msIC:-0.0210, msIR:-0.0423
Total Evaluation 

MSE:0.3601Â±0.0000
MAE:0.4563Â±0.0000
msIC:0.0065Â±0.0213
msIR:0.0129Â±0.0428
  Evaluating Naive results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: DLinear
  Training DLinear...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_DLinear_pl5Model:              DLinear             

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.001               
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.0857236385345459
Epoch: 1, Steps: 28 | Train Loss: 0.4466168 Vali Loss: 0.1026991 Test Loss: 0.1770787
Validation loss decreased (inf --> 0.102699).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.021059751510620117
Epoch: 2, Steps: 28 | Train Loss: 0.4172635 Vali Loss: 0.1029845 Test Loss: 0.1761048
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.020169496536254883
Epoch: 3, Steps: 28 | Train Loss: 0.4021364 Vali Loss: 0.1030375 Test Loss: 0.1762834
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.020057201385498047
Epoch: 4, Steps: 28 | Train Loss: 0.3953610 Vali Loss: 0.1040306 Test Loss: 0.1764976
EarlyStopping counter: 3 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.020172834396362305
Epoch: 5, Steps: 28 | Train Loss: 0.3957210 Vali Loss: 0.1016490 Test Loss: 0.1766370
Validation loss decreased (0.102699 --> 0.101649).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.020528078079223633
Epoch: 6, Steps: 28 | Train Loss: 0.3931581 Vali Loss: 0.1082440 Test Loss: 0.1767104
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.020090579986572266
Epoch: 7, Steps: 28 | Train Loss: 0.3918174 Vali Loss: 0.1035151 Test Loss: 0.1767272
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.02013397216796875
Epoch: 8, Steps: 28 | Train Loss: 0.3936020 Vali Loss: 0.1074606 Test Loss: 0.1767443
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.020099878311157227
Epoch: 9, Steps: 28 | Train Loss: 0.3912602 Vali Loss: 0.1029465 Test Loss: 0.1767519
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.021543025970458984
Epoch: 10, Steps: 28 | Train Loss: 0.3921324 Vali Loss: 0.1013761 Test Loss: 0.1767563
Validation loss decreased (0.101649 --> 0.101376).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.022399425506591797
Epoch: 11, Steps: 28 | Train Loss: 0.3928437 Vali Loss: 0.1053262 Test Loss: 0.1767579
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.022255420684814453
Epoch: 12, Steps: 28 | Train Loss: 0.3909644 Vali Loss: 0.1008935 Test Loss: 0.1767591
Validation loss decreased (0.101376 --> 0.100894).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.022292613983154297
Epoch: 13, Steps: 28 | Train Loss: 0.3918571 Vali Loss: 0.1014543 Test Loss: 0.1767595
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.022262096405029297
Epoch: 14, Steps: 28 | Train Loss: 0.3930055 Vali Loss: 0.1006296 Test Loss: 0.1767599
Validation loss decreased (0.100894 --> 0.100630).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.02171492576599121
Epoch: 15, Steps: 28 | Train Loss: 0.3918379 Vali Loss: 0.0995046 Test Loss: 0.1767600
Validation loss decreased (0.100630 --> 0.099505).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.022235631942749023
Epoch: 16, Steps: 28 | Train Loss: 0.3917612 Vali Loss: 0.1013672 Test Loss: 0.1767600
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.021335124969482422
Epoch: 17, Steps: 28 | Train Loss: 0.3925486 Vali Loss: 0.1010130 Test Loss: 0.1767601
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.021609067916870117
Epoch: 18, Steps: 28 | Train Loss: 0.3915420 Vali Loss: 0.0996799 Test Loss: 0.1767601
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.021657466888427734
Epoch: 19, Steps: 28 | Train Loss: 0.3924902 Vali Loss: 0.1032098 Test Loss: 0.1767601
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.02126622200012207
Epoch: 20, Steps: 28 | Train Loss: 0.3920780 Vali Loss: 0.1002094 Test Loss: 0.1767601
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.022052526473999023
Epoch: 21, Steps: 28 | Train Loss: 0.3911939 Vali Loss: 0.1059905 Test Loss: 0.1767601
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.02222156524658203
Epoch: 22, Steps: 28 | Train Loss: 0.3921859 Vali Loss: 0.0997249 Test Loss: 0.1767601
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.022229909896850586
Epoch: 23, Steps: 28 | Train Loss: 0.3913696 Vali Loss: 0.0992297 Test Loss: 0.1767601
Validation loss decreased (0.099505 --> 0.099230).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.02237677574157715
Epoch: 24, Steps: 28 | Train Loss: 0.3934242 Vali Loss: 0.1025036 Test Loss: 0.1767601
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.02222156524658203
Epoch: 25, Steps: 28 | Train Loss: 0.3924507 Vali Loss: 0.1014168 Test Loss: 0.1767601
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.022156476974487305
Epoch: 26, Steps: 28 | Train Loss: 0.3932952 Vali Loss: 0.1027020 Test Loss: 0.1767601
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.022191524505615234
Epoch: 27, Steps: 28 | Train Loss: 0.3938587 Vali Loss: 0.0987083 Test Loss: 0.1767601
Validation loss decreased (0.099230 --> 0.098708).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.022431612014770508
Epoch: 28, Steps: 28 | Train Loss: 0.3958033 Vali Loss: 0.1046101 Test Loss: 0.1767601
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.022152185440063477
Epoch: 29, Steps: 28 | Train Loss: 0.3939082 Vali Loss: 0.1042623 Test Loss: 0.1767601
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.022260665893554688
Epoch: 30, Steps: 28 | Train Loss: 0.3929393 Vali Loss: 0.1009712 Test Loss: 0.1767601
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.022028684616088867
Epoch: 31, Steps: 28 | Train Loss: 0.3937724 Vali Loss: 0.0999699 Test Loss: 0.1767601
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.022256135940551758
Epoch: 32, Steps: 28 | Train Loss: 0.3915134 Vali Loss: 0.1013138 Test Loss: 0.1767601
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.022259235382080078
Epoch: 33, Steps: 28 | Train Loss: 0.3913516 Vali Loss: 0.0990390 Test Loss: 0.1767601
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.022177934646606445
Epoch: 34, Steps: 28 | Train Loss: 0.3926642 Vali Loss: 0.1030359 Test Loss: 0.1767601
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.02229022979736328
Epoch: 35, Steps: 28 | Train Loss: 0.3919285 Vali Loss: 0.1011523 Test Loss: 0.1767601
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.021775484085083008
Epoch: 36, Steps: 28 | Train Loss: 0.3921348 Vali Loss: 0.1017774 Test Loss: 0.1767601
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.02137136459350586
Epoch: 37, Steps: 28 | Train Loss: 0.3932350 Vali Loss: 0.1027104 Test Loss: 0.1767601
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.022235631942749023
Epoch: 38, Steps: 28 | Train Loss: 0.3935791 Vali Loss: 0.0969840 Test Loss: 0.1767601
Validation loss decreased (0.098708 --> 0.096984).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.02226853370666504
Epoch: 39, Steps: 28 | Train Loss: 0.3927689 Vali Loss: 0.1005265 Test Loss: 0.1767601
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.022063493728637695
Epoch: 40, Steps: 28 | Train Loss: 0.3920292 Vali Loss: 0.1030971 Test Loss: 0.1767601
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.021691322326660156
Epoch: 41, Steps: 28 | Train Loss: 0.3934124 Vali Loss: 0.1017500 Test Loss: 0.1767601
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.019502878189086914
Epoch: 42, Steps: 28 | Train Loss: 0.3939267 Vali Loss: 0.1005958 Test Loss: 0.1767601
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.019280433654785156
Epoch: 43, Steps: 28 | Train Loss: 0.3924891 Vali Loss: 0.0984631 Test Loss: 0.1767601
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.020073890686035156
Epoch: 44, Steps: 28 | Train Loss: 0.3934814 Vali Loss: 0.1001074 Test Loss: 0.1767601
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.020139217376708984
Epoch: 45, Steps: 28 | Train Loss: 0.3921400 Vali Loss: 0.1023576 Test Loss: 0.1767601
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.0207669734954834
Epoch: 46, Steps: 28 | Train Loss: 0.3914345 Vali Loss: 0.1041154 Test Loss: 0.1767601
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.020247697830200195
Epoch: 47, Steps: 28 | Train Loss: 0.3917399 Vali Loss: 0.1033533 Test Loss: 0.1767601
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.020116090774536133
Epoch: 48, Steps: 28 | Train Loss: 0.3916277 Vali Loss: 0.1005906 Test Loss: 0.1767601
EarlyStopping counter: 10 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.02007317543029785
Epoch: 49, Steps: 28 | Train Loss: 0.3906104 Vali Loss: 0.1018928 Test Loss: 0.1767601
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.02004837989807129
Epoch: 50, Steps: 28 | Train Loss: 0.3913317 Vali Loss: 0.1029806 Test Loss: 0.1767601
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.020241975784301758
Epoch: 51, Steps: 28 | Train Loss: 0.3918085 Vali Loss: 0.1034490 Test Loss: 0.1767601
EarlyStopping counter: 13 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.01998424530029297
Epoch: 52, Steps: 28 | Train Loss: 0.3909476 Vali Loss: 0.1057433 Test Loss: 0.1767601
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.02025151252746582
Epoch: 53, Steps: 28 | Train Loss: 0.3934097 Vali Loss: 0.1031699 Test Loss: 0.1767601
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1769, mae:0.3181, msIC:-0.0153, msIR:-0.0298
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.02247452735900879
Epoch: 1, Steps: 28 | Train Loss: 0.4439179 Vali Loss: 0.1012104 Test Loss: 0.1768758
Validation loss decreased (inf --> 0.101210).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.022287607192993164
Epoch: 2, Steps: 28 | Train Loss: 0.4157231 Vali Loss: 0.1004688 Test Loss: 0.1760573
Validation loss decreased (0.101210 --> 0.100469).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.02141094207763672
Epoch: 3, Steps: 28 | Train Loss: 0.4025064 Vali Loss: 0.1019556 Test Loss: 0.1763590
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.021392822265625
Epoch: 4, Steps: 28 | Train Loss: 0.3957033 Vali Loss: 0.1044642 Test Loss: 0.1765389
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.021683454513549805
Epoch: 5, Steps: 28 | Train Loss: 0.3952084 Vali Loss: 0.0998799 Test Loss: 0.1766602
Validation loss decreased (0.100469 --> 0.099880).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.021299362182617188
Epoch: 6, Steps: 28 | Train Loss: 0.3941808 Vali Loss: 0.1009421 Test Loss: 0.1767236
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.021296024322509766
Epoch: 7, Steps: 28 | Train Loss: 0.3918722 Vali Loss: 0.1008926 Test Loss: 0.1767474
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.021485328674316406
Epoch: 8, Steps: 28 | Train Loss: 0.3929227 Vali Loss: 0.1051472 Test Loss: 0.1767629
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.02148747444152832
Epoch: 9, Steps: 28 | Train Loss: 0.3942177 Vali Loss: 0.1002734 Test Loss: 0.1767733
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.021183490753173828
Epoch: 10, Steps: 28 | Train Loss: 0.3914485 Vali Loss: 0.1018745 Test Loss: 0.1767773
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.02132558822631836
Epoch: 11, Steps: 28 | Train Loss: 0.3917338 Vali Loss: 0.1010374 Test Loss: 0.1767790
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.02122783660888672
Epoch: 12, Steps: 28 | Train Loss: 0.3917929 Vali Loss: 0.1028009 Test Loss: 0.1767802
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.021173477172851562
Epoch: 13, Steps: 28 | Train Loss: 0.3927698 Vali Loss: 0.1039152 Test Loss: 0.1767807
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.02124190330505371
Epoch: 14, Steps: 28 | Train Loss: 0.3928957 Vali Loss: 0.0993235 Test Loss: 0.1767810
Validation loss decreased (0.099880 --> 0.099323).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.021319150924682617
Epoch: 15, Steps: 28 | Train Loss: 0.3921782 Vali Loss: 0.1041050 Test Loss: 0.1767811
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.021250486373901367
Epoch: 16, Steps: 28 | Train Loss: 0.3916886 Vali Loss: 0.1077665 Test Loss: 0.1767811
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.021192550659179688
Epoch: 17, Steps: 28 | Train Loss: 0.3935431 Vali Loss: 0.0989803 Test Loss: 0.1767812
Validation loss decreased (0.099323 --> 0.098980).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.021424055099487305
Epoch: 18, Steps: 28 | Train Loss: 0.3920767 Vali Loss: 0.1041927 Test Loss: 0.1767812
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.02276325225830078
Epoch: 19, Steps: 28 | Train Loss: 0.3916556 Vali Loss: 0.1040391 Test Loss: 0.1767812
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.022446870803833008
Epoch: 20, Steps: 28 | Train Loss: 0.3932605 Vali Loss: 0.1020076 Test Loss: 0.1767812
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.02231574058532715
Epoch: 21, Steps: 28 | Train Loss: 0.3935015 Vali Loss: 0.1007174 Test Loss: 0.1767812
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.02251148223876953
Epoch: 22, Steps: 28 | Train Loss: 0.3912732 Vali Loss: 0.0994204 Test Loss: 0.1767812
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.023679018020629883
Epoch: 23, Steps: 28 | Train Loss: 0.3911293 Vali Loss: 0.1008453 Test Loss: 0.1767812
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.020650386810302734
Epoch: 24, Steps: 28 | Train Loss: 0.3927137 Vali Loss: 0.0989527 Test Loss: 0.1767812
Validation loss decreased (0.098980 --> 0.098953).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.0202028751373291
Epoch: 25, Steps: 28 | Train Loss: 0.3909032 Vali Loss: 0.1011183 Test Loss: 0.1767812
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.02016758918762207
Epoch: 26, Steps: 28 | Train Loss: 0.3922439 Vali Loss: 0.1043390 Test Loss: 0.1767812
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.020496368408203125
Epoch: 27, Steps: 28 | Train Loss: 0.3918306 Vali Loss: 0.1007231 Test Loss: 0.1767812
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.022319316864013672
Epoch: 28, Steps: 28 | Train Loss: 0.3911565 Vali Loss: 0.1025381 Test Loss: 0.1767812
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.022264480590820312
Epoch: 29, Steps: 28 | Train Loss: 0.3915814 Vali Loss: 0.1011223 Test Loss: 0.1767812
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.02241992950439453
Epoch: 30, Steps: 28 | Train Loss: 0.3931850 Vali Loss: 0.1006625 Test Loss: 0.1767812
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.02219533920288086
Epoch: 31, Steps: 28 | Train Loss: 0.3927204 Vali Loss: 0.1050736 Test Loss: 0.1767812
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.022228002548217773
Epoch: 32, Steps: 28 | Train Loss: 0.3921408 Vali Loss: 0.1024552 Test Loss: 0.1767812
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.022165298461914062
Epoch: 33, Steps: 28 | Train Loss: 0.3908838 Vali Loss: 0.1034355 Test Loss: 0.1767812
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.02142500877380371
Epoch: 34, Steps: 28 | Train Loss: 0.3918658 Vali Loss: 0.1034718 Test Loss: 0.1767812
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.021613597869873047
Epoch: 35, Steps: 28 | Train Loss: 0.3923792 Vali Loss: 0.1048364 Test Loss: 0.1767812
EarlyStopping counter: 11 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.022094011306762695
Epoch: 36, Steps: 28 | Train Loss: 0.3920817 Vali Loss: 0.1000217 Test Loss: 0.1767812
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.0222165584564209
Epoch: 37, Steps: 28 | Train Loss: 0.3917079 Vali Loss: 0.1015472 Test Loss: 0.1767812
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.02228069305419922
Epoch: 38, Steps: 28 | Train Loss: 0.3919170 Vali Loss: 0.1001592 Test Loss: 0.1767812
EarlyStopping counter: 14 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.02228832244873047
Epoch: 39, Steps: 28 | Train Loss: 0.3914967 Vali Loss: 0.1015153 Test Loss: 0.1767812
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1770, mae:0.3186, msIC:-0.0051, msIR:-0.0101
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.022588491439819336
Epoch: 1, Steps: 28 | Train Loss: 0.4442289 Vali Loss: 0.1024190 Test Loss: 0.1759434
Validation loss decreased (inf --> 0.102419).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.022215604782104492
Epoch: 2, Steps: 28 | Train Loss: 0.4200484 Vali Loss: 0.0993142 Test Loss: 0.1752797
Validation loss decreased (0.102419 --> 0.099314).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.02159738540649414
Epoch: 3, Steps: 28 | Train Loss: 0.4028313 Vali Loss: 0.1025984 Test Loss: 0.1756034
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.022213220596313477
Epoch: 4, Steps: 28 | Train Loss: 0.3997285 Vali Loss: 0.1014883 Test Loss: 0.1758055
EarlyStopping counter: 2 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.021649599075317383
Epoch: 5, Steps: 28 | Train Loss: 0.3947015 Vali Loss: 0.1025357 Test Loss: 0.1759289
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.02150273323059082
Epoch: 6, Steps: 28 | Train Loss: 0.3937193 Vali Loss: 0.1042531 Test Loss: 0.1759963
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.022153615951538086
Epoch: 7, Steps: 28 | Train Loss: 0.3930546 Vali Loss: 0.1045324 Test Loss: 0.1760286
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.02257251739501953
Epoch: 8, Steps: 28 | Train Loss: 0.3926960 Vali Loss: 0.1006351 Test Loss: 0.1760440
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.021723508834838867
Epoch: 9, Steps: 28 | Train Loss: 0.3931285 Vali Loss: 0.0986762 Test Loss: 0.1760549
Validation loss decreased (0.099314 --> 0.098676).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.021578073501586914
Epoch: 10, Steps: 28 | Train Loss: 0.3921672 Vali Loss: 0.1016310 Test Loss: 0.1760588
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.021335124969482422
Epoch: 11, Steps: 28 | Train Loss: 0.3930367 Vali Loss: 0.1029152 Test Loss: 0.1760612
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.021329879760742188
Epoch: 12, Steps: 28 | Train Loss: 0.3936421 Vali Loss: 0.1042923 Test Loss: 0.1760622
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.021544218063354492
Epoch: 13, Steps: 28 | Train Loss: 0.3921894 Vali Loss: 0.1024188 Test Loss: 0.1760629
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.02139115333557129
Epoch: 14, Steps: 28 | Train Loss: 0.3924198 Vali Loss: 0.1042268 Test Loss: 0.1760632
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.021130084991455078
Epoch: 15, Steps: 28 | Train Loss: 0.3931111 Vali Loss: 0.1011823 Test Loss: 0.1760634
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.020149946212768555
Epoch: 16, Steps: 28 | Train Loss: 0.3923628 Vali Loss: 0.0974889 Test Loss: 0.1760634
Validation loss decreased (0.098676 --> 0.097489).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.02033233642578125
Epoch: 17, Steps: 28 | Train Loss: 0.3915877 Vali Loss: 0.1009927 Test Loss: 0.1760635
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.019532442092895508
Epoch: 18, Steps: 28 | Train Loss: 0.3913581 Vali Loss: 0.1019113 Test Loss: 0.1760635
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.019483089447021484
Epoch: 19, Steps: 28 | Train Loss: 0.3916467 Vali Loss: 0.1004429 Test Loss: 0.1760635
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.020665884017944336
Epoch: 20, Steps: 28 | Train Loss: 0.3925988 Vali Loss: 0.0990088 Test Loss: 0.1760635
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.02017807960510254
Epoch: 21, Steps: 28 | Train Loss: 0.3935630 Vali Loss: 0.1042542 Test Loss: 0.1760635
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.01943230628967285
Epoch: 22, Steps: 28 | Train Loss: 0.3926310 Vali Loss: 0.0992539 Test Loss: 0.1760635
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.02041935920715332
Epoch: 23, Steps: 28 | Train Loss: 0.3936165 Vali Loss: 0.1047239 Test Loss: 0.1760635
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.01957559585571289
Epoch: 24, Steps: 28 | Train Loss: 0.3911372 Vali Loss: 0.1018333 Test Loss: 0.1760635
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.021222829818725586
Epoch: 25, Steps: 28 | Train Loss: 0.3923149 Vali Loss: 0.1017999 Test Loss: 0.1760635
EarlyStopping counter: 9 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.020294189453125
Epoch: 26, Steps: 28 | Train Loss: 0.3924638 Vali Loss: 0.1012508 Test Loss: 0.1760635
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.02025628089904785
Epoch: 27, Steps: 28 | Train Loss: 0.3927862 Vali Loss: 0.0997005 Test Loss: 0.1760635
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.020194530487060547
Epoch: 28, Steps: 28 | Train Loss: 0.3929091 Vali Loss: 0.1019798 Test Loss: 0.1760635
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.020214557647705078
Epoch: 29, Steps: 28 | Train Loss: 0.3929753 Vali Loss: 0.1015320 Test Loss: 0.1760635
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.019644498825073242
Epoch: 30, Steps: 28 | Train Loss: 0.3936579 Vali Loss: 0.1010382 Test Loss: 0.1760635
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.019975900650024414
Epoch: 31, Steps: 28 | Train Loss: 0.3935500 Vali Loss: 0.1012504 Test Loss: 0.1760635
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_DLinear_pl5_DLinear_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1762, mae:0.3186, msIC:-0.0219, msIR:-0.0432
Total Evaluation 

MSE:0.1767Â±0.0003
MAE:0.3184Â±0.0002
msIC:-0.0141Â±0.0069
msIR:-0.0277Â±0.0136
  Evaluating DLinear results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: PatchTST
  Training PatchTST...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_PatchTST_pl5Model:              PatchTST            

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.2605624198913574
Epoch: 1, Steps: 28 | Train Loss: 0.7836367 Vali Loss: 0.1212011 Test Loss: 0.2020591
Validation loss decreased (inf --> 0.121201).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.06851053237915039
Epoch: 2, Steps: 28 | Train Loss: 0.6941838 Vali Loss: 0.1171716 Test Loss: 0.1968678
Validation loss decreased (0.121201 --> 0.117172).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.0664525032043457
Epoch: 3, Steps: 28 | Train Loss: 0.6505752 Vali Loss: 0.1160121 Test Loss: 0.1940314
Validation loss decreased (0.117172 --> 0.116012).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.06525778770446777
Epoch: 4, Steps: 28 | Train Loss: 0.6217379 Vali Loss: 0.1156401 Test Loss: 0.1927576
Validation loss decreased (0.116012 --> 0.115640).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.07841634750366211
Epoch: 5, Steps: 28 | Train Loss: 0.6144396 Vali Loss: 0.1142743 Test Loss: 0.1922732
Validation loss decreased (0.115640 --> 0.114274).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.06546711921691895
Epoch: 6, Steps: 28 | Train Loss: 0.6059920 Vali Loss: 0.1133956 Test Loss: 0.1919915
Validation loss decreased (0.114274 --> 0.113396).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.06597304344177246
Epoch: 7, Steps: 28 | Train Loss: 0.6010324 Vali Loss: 0.1096244 Test Loss: 0.1918033
Validation loss decreased (0.113396 --> 0.109624).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.06660103797912598
Epoch: 8, Steps: 28 | Train Loss: 0.5955510 Vali Loss: 0.1119414 Test Loss: 0.1917418
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.06536483764648438
Epoch: 9, Steps: 28 | Train Loss: 0.6118327 Vali Loss: 0.1116809 Test Loss: 0.1917031
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.06512069702148438
Epoch: 10, Steps: 28 | Train Loss: 0.6012482 Vali Loss: 0.1104219 Test Loss: 0.1917061
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.06457948684692383
Epoch: 11, Steps: 28 | Train Loss: 0.5936761 Vali Loss: 0.1134264 Test Loss: 0.1916647
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.06426548957824707
Epoch: 12, Steps: 28 | Train Loss: 0.6000594 Vali Loss: 0.1144699 Test Loss: 0.1916828
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.06546401977539062
Epoch: 13, Steps: 28 | Train Loss: 0.6214674 Vali Loss: 0.1121706 Test Loss: 0.1916574
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.06739234924316406
Epoch: 14, Steps: 28 | Train Loss: 0.5823342 Vali Loss: 0.1150599 Test Loss: 0.1916233
EarlyStopping counter: 7 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.0661306381225586
Epoch: 15, Steps: 28 | Train Loss: 0.6043025 Vali Loss: 0.1112891 Test Loss: 0.1916500
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06690263748168945
Epoch: 16, Steps: 28 | Train Loss: 0.6117179 Vali Loss: 0.1117687 Test Loss: 0.1916855
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.06667351722717285
Epoch: 17, Steps: 28 | Train Loss: 0.5883929 Vali Loss: 0.1116886 Test Loss: 0.1916804
EarlyStopping counter: 10 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06487154960632324
Epoch: 18, Steps: 28 | Train Loss: 0.6147969 Vali Loss: 0.1129602 Test Loss: 0.1916481
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.06452631950378418
Epoch: 19, Steps: 28 | Train Loss: 0.6146738 Vali Loss: 0.1132941 Test Loss: 0.1916845
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.06410670280456543
Epoch: 20, Steps: 28 | Train Loss: 0.6010091 Vali Loss: 0.1155651 Test Loss: 0.1916694
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.0639638900756836
Epoch: 21, Steps: 28 | Train Loss: 0.6055927 Vali Loss: 0.1143677 Test Loss: 0.1916654
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.06394195556640625
Epoch: 22, Steps: 28 | Train Loss: 0.6103543 Vali Loss: 0.1131435 Test Loss: 0.1916933
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1920, mae:0.3340, msIC:-0.0548, msIR:-0.1097
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.06703066825866699
Epoch: 1, Steps: 28 | Train Loss: 0.7667825 Vali Loss: 0.1252352 Test Loss: 0.2067144
Validation loss decreased (inf --> 0.125235).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.06672382354736328
Epoch: 2, Steps: 28 | Train Loss: 0.6947922 Vali Loss: 0.1149021 Test Loss: 0.1967565
Validation loss decreased (0.125235 --> 0.114902).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.07786822319030762
Epoch: 3, Steps: 28 | Train Loss: 0.6396624 Vali Loss: 0.1171355 Test Loss: 0.1940310
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.06401634216308594
Epoch: 4, Steps: 28 | Train Loss: 0.6172760 Vali Loss: 0.1156901 Test Loss: 0.1923632
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.06432127952575684
Epoch: 5, Steps: 28 | Train Loss: 0.6564187 Vali Loss: 0.1147140 Test Loss: 0.1925220
Validation loss decreased (0.114902 --> 0.114714).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.06823444366455078
Epoch: 6, Steps: 28 | Train Loss: 0.6203522 Vali Loss: 0.1159550 Test Loss: 0.1923524
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.07672762870788574
Epoch: 7, Steps: 28 | Train Loss: 0.6053509 Vali Loss: 0.1161077 Test Loss: 0.1921294
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.06602692604064941
Epoch: 8, Steps: 28 | Train Loss: 0.6272293 Vali Loss: 0.1167610 Test Loss: 0.1920453
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.06542348861694336
Epoch: 9, Steps: 28 | Train Loss: 0.6142676 Vali Loss: 0.1153291 Test Loss: 0.1920146
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.06650614738464355
Epoch: 10, Steps: 28 | Train Loss: 0.6198532 Vali Loss: 0.1126507 Test Loss: 0.1920992
Validation loss decreased (0.114714 --> 0.112651).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.08006954193115234
Epoch: 11, Steps: 28 | Train Loss: 0.5855837 Vali Loss: 0.1119244 Test Loss: 0.1921005
Validation loss decreased (0.112651 --> 0.111924).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.06756305694580078
Epoch: 12, Steps: 28 | Train Loss: 0.6180669 Vali Loss: 0.1128731 Test Loss: 0.1919741
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.06729650497436523
Epoch: 13, Steps: 28 | Train Loss: 0.5817138 Vali Loss: 0.1179516 Test Loss: 0.1919864
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.06507992744445801
Epoch: 14, Steps: 28 | Train Loss: 0.6209468 Vali Loss: 0.1122542 Test Loss: 0.1920187
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.06504058837890625
Epoch: 15, Steps: 28 | Train Loss: 0.6154704 Vali Loss: 0.1137105 Test Loss: 0.1920503
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06445145606994629
Epoch: 16, Steps: 28 | Train Loss: 0.5981068 Vali Loss: 0.1109762 Test Loss: 0.1920370
Validation loss decreased (0.111924 --> 0.110976).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.1268479824066162
Epoch: 17, Steps: 28 | Train Loss: 0.6186634 Vali Loss: 0.1124908 Test Loss: 0.1920112
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06835818290710449
Epoch: 18, Steps: 28 | Train Loss: 0.5951726 Vali Loss: 0.1106531 Test Loss: 0.1919786
Validation loss decreased (0.110976 --> 0.110653).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.10522627830505371
Epoch: 19, Steps: 28 | Train Loss: 0.6323040 Vali Loss: 0.1155017 Test Loss: 0.1920457
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.06986784934997559
Epoch: 20, Steps: 28 | Train Loss: 0.5995917 Vali Loss: 0.1138073 Test Loss: 0.1920234
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.07090401649475098
Epoch: 21, Steps: 28 | Train Loss: 0.6244103 Vali Loss: 0.1140641 Test Loss: 0.1920236
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.0696713924407959
Epoch: 22, Steps: 28 | Train Loss: 0.6196987 Vali Loss: 0.1117582 Test Loss: 0.1920515
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.07046866416931152
Epoch: 23, Steps: 28 | Train Loss: 0.6237789 Vali Loss: 0.1103747 Test Loss: 0.1919730
Validation loss decreased (0.110653 --> 0.110375).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.06667494773864746
Epoch: 24, Steps: 28 | Train Loss: 0.6007419 Vali Loss: 0.1112542 Test Loss: 0.1919986
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.06740283966064453
Epoch: 25, Steps: 28 | Train Loss: 0.6245233 Vali Loss: 0.1151315 Test Loss: 0.1920059
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.0698704719543457
Epoch: 26, Steps: 28 | Train Loss: 0.6125365 Vali Loss: 0.1139904 Test Loss: 0.1919581
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.07168912887573242
Epoch: 27, Steps: 28 | Train Loss: 0.6044130 Vali Loss: 0.1160280 Test Loss: 0.1920138
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.06915712356567383
Epoch: 28, Steps: 28 | Train Loss: 0.6131538 Vali Loss: 0.1120955 Test Loss: 0.1919748
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.06944108009338379
Epoch: 29, Steps: 28 | Train Loss: 0.6193266 Vali Loss: 0.1177569 Test Loss: 0.1920193
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.06933712959289551
Epoch: 30, Steps: 28 | Train Loss: 0.6159898 Vali Loss: 0.1135824 Test Loss: 0.1919419
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.06937670707702637
Epoch: 31, Steps: 28 | Train Loss: 0.6202931 Vali Loss: 0.1119711 Test Loss: 0.1919757
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.06932449340820312
Epoch: 32, Steps: 28 | Train Loss: 0.6086634 Vali Loss: 0.1175640 Test Loss: 0.1919373
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.06932377815246582
Epoch: 33, Steps: 28 | Train Loss: 0.6320975 Vali Loss: 0.1156675 Test Loss: 0.1919592
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.06986761093139648
Epoch: 34, Steps: 28 | Train Loss: 0.6268934 Vali Loss: 0.1124487 Test Loss: 0.1919573
EarlyStopping counter: 11 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.06950807571411133
Epoch: 35, Steps: 28 | Train Loss: 0.6215265 Vali Loss: 0.1134732 Test Loss: 0.1919217
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.07000541687011719
Epoch: 36, Steps: 28 | Train Loss: 0.6066320 Vali Loss: 0.1153808 Test Loss: 0.1920441
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.06939697265625
Epoch: 37, Steps: 28 | Train Loss: 0.6121575 Vali Loss: 0.1134591 Test Loss: 0.1919962
EarlyStopping counter: 14 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.06846952438354492
Epoch: 38, Steps: 28 | Train Loss: 0.6118083 Vali Loss: 0.1137859 Test Loss: 0.1920021
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1921, mae:0.3328, msIC:0.0252, msIR:0.0485
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.07022261619567871
Epoch: 1, Steps: 28 | Train Loss: 0.7640240 Vali Loss: 0.1207426 Test Loss: 0.2060333
Validation loss decreased (inf --> 0.120743).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.06718635559082031
Epoch: 2, Steps: 28 | Train Loss: 0.6861141 Vali Loss: 0.1171249 Test Loss: 0.2006963
Validation loss decreased (0.120743 --> 0.117125).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.07666802406311035
Epoch: 3, Steps: 28 | Train Loss: 0.6289515 Vali Loss: 0.1160745 Test Loss: 0.1975321
Validation loss decreased (0.117125 --> 0.116074).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.07845282554626465
Epoch: 4, Steps: 28 | Train Loss: 0.6088765 Vali Loss: 0.1110708 Test Loss: 0.1952923
Validation loss decreased (0.116074 --> 0.111071).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.07287025451660156
Epoch: 5, Steps: 28 | Train Loss: 0.6313558 Vali Loss: 0.1156943 Test Loss: 0.1944905
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.07051301002502441
Epoch: 6, Steps: 28 | Train Loss: 0.6093977 Vali Loss: 0.1146730 Test Loss: 0.1941350
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.06800675392150879
Epoch: 7, Steps: 28 | Train Loss: 0.6110327 Vali Loss: 0.1132422 Test Loss: 0.1939450
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.06985759735107422
Epoch: 8, Steps: 28 | Train Loss: 0.6067821 Vali Loss: 0.1116771 Test Loss: 0.1938762
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.0702219009399414
Epoch: 9, Steps: 28 | Train Loss: 0.6118911 Vali Loss: 0.1120398 Test Loss: 0.1937893
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.07067990303039551
Epoch: 10, Steps: 28 | Train Loss: 0.5942585 Vali Loss: 0.1145631 Test Loss: 0.1937336
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.06977009773254395
Epoch: 11, Steps: 28 | Train Loss: 0.5986051 Vali Loss: 0.1138333 Test Loss: 0.1937352
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.0694277286529541
Epoch: 12, Steps: 28 | Train Loss: 0.6090600 Vali Loss: 0.1130017 Test Loss: 0.1937580
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.06974458694458008
Epoch: 13, Steps: 28 | Train Loss: 0.6082480 Vali Loss: 0.1192789 Test Loss: 0.1937271
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.07013654708862305
Epoch: 14, Steps: 28 | Train Loss: 0.5937612 Vali Loss: 0.1122602 Test Loss: 0.1937396
EarlyStopping counter: 10 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.06982851028442383
Epoch: 15, Steps: 28 | Train Loss: 0.6139448 Vali Loss: 0.1129495 Test Loss: 0.1937640
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06922101974487305
Epoch: 16, Steps: 28 | Train Loss: 0.6089699 Vali Loss: 0.1109219 Test Loss: 0.1937551
Validation loss decreased (0.111071 --> 0.110922).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.10957717895507812
Epoch: 17, Steps: 28 | Train Loss: 0.5950638 Vali Loss: 0.1116047 Test Loss: 0.1938026
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06925058364868164
Epoch: 18, Steps: 28 | Train Loss: 0.5918135 Vali Loss: 0.1155066 Test Loss: 0.1937279
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.06957793235778809
Epoch: 19, Steps: 28 | Train Loss: 0.6379026 Vali Loss: 0.1119764 Test Loss: 0.1936870
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.06937551498413086
Epoch: 20, Steps: 28 | Train Loss: 0.6027894 Vali Loss: 0.1125261 Test Loss: 0.1937834
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.07254195213317871
Epoch: 21, Steps: 28 | Train Loss: 0.6114808 Vali Loss: 0.1117516 Test Loss: 0.1937369
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.06963944435119629
Epoch: 22, Steps: 28 | Train Loss: 0.6165924 Vali Loss: 0.1142966 Test Loss: 0.1937739
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.0682365894317627
Epoch: 23, Steps: 28 | Train Loss: 0.5952754 Vali Loss: 0.1146039 Test Loss: 0.1938064
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.06977033615112305
Epoch: 24, Steps: 28 | Train Loss: 0.6089539 Vali Loss: 0.1128871 Test Loss: 0.1937125
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.09110140800476074
Epoch: 25, Steps: 28 | Train Loss: 0.6074529 Vali Loss: 0.1141579 Test Loss: 0.1937322
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.07356953620910645
Epoch: 26, Steps: 28 | Train Loss: 0.5937573 Vali Loss: 0.1122766 Test Loss: 0.1937506
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.06539750099182129
Epoch: 27, Steps: 28 | Train Loss: 0.5961720 Vali Loss: 0.1118755 Test Loss: 0.1937909
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.07046627998352051
Epoch: 28, Steps: 28 | Train Loss: 0.5876726 Vali Loss: 0.1144589 Test Loss: 0.1937560
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.06994104385375977
Epoch: 29, Steps: 28 | Train Loss: 0.6079722 Vali Loss: 0.1160689 Test Loss: 0.1937385
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.07037973403930664
Epoch: 30, Steps: 28 | Train Loss: 0.6105751 Vali Loss: 0.1098277 Test Loss: 0.1937564
Validation loss decreased (0.110922 --> 0.109828).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.10722494125366211
Epoch: 31, Steps: 28 | Train Loss: 0.5971051 Vali Loss: 0.1128302 Test Loss: 0.1937003
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.06927824020385742
Epoch: 32, Steps: 28 | Train Loss: 0.6172116 Vali Loss: 0.1129257 Test Loss: 0.1937629
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.07398223876953125
Epoch: 33, Steps: 28 | Train Loss: 0.6035400 Vali Loss: 0.1147655 Test Loss: 0.1937693
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.0653843879699707
Epoch: 34, Steps: 28 | Train Loss: 0.6220810 Vali Loss: 0.1161335 Test Loss: 0.1937860
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.06953001022338867
Epoch: 35, Steps: 28 | Train Loss: 0.5939693 Vali Loss: 0.1149701 Test Loss: 0.1936817
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.06559443473815918
Epoch: 36, Steps: 28 | Train Loss: 0.6034845 Vali Loss: 0.1126627 Test Loss: 0.1937260
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.06609797477722168
Epoch: 37, Steps: 28 | Train Loss: 0.6097838 Vali Loss: 0.1158703 Test Loss: 0.1937398
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.06652307510375977
Epoch: 38, Steps: 28 | Train Loss: 0.5914533 Vali Loss: 0.1110792 Test Loss: 0.1937375
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.06394386291503906
Epoch: 39, Steps: 28 | Train Loss: 0.6086335 Vali Loss: 0.1137105 Test Loss: 0.1937666
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.06428384780883789
Epoch: 40, Steps: 28 | Train Loss: 0.6169589 Vali Loss: 0.1138507 Test Loss: 0.1937657
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.06736445426940918
Epoch: 41, Steps: 28 | Train Loss: 0.6146885 Vali Loss: 0.1119550 Test Loss: 0.1937503
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.0659186840057373
Epoch: 42, Steps: 28 | Train Loss: 0.6070972 Vali Loss: 0.1151813 Test Loss: 0.1937335
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.0669856071472168
Epoch: 43, Steps: 28 | Train Loss: 0.6155237 Vali Loss: 0.1160583 Test Loss: 0.1937738
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.06423616409301758
Epoch: 44, Steps: 28 | Train Loss: 0.5967118 Vali Loss: 0.1147892 Test Loss: 0.1937623
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.06485581398010254
Epoch: 45, Steps: 28 | Train Loss: 0.5947702 Vali Loss: 0.1085021 Test Loss: 0.1937549
Validation loss decreased (0.109828 --> 0.108502).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 0.09251141548156738
Epoch: 46, Steps: 28 | Train Loss: 0.6146218 Vali Loss: 0.1147325 Test Loss: 0.1937388
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 47 cost time: 0.07305574417114258
Epoch: 47, Steps: 28 | Train Loss: 0.6139698 Vali Loss: 0.1134168 Test Loss: 0.1936924
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 48 cost time: 0.06723260879516602
Epoch: 48, Steps: 28 | Train Loss: 0.6160344 Vali Loss: 0.1134405 Test Loss: 0.1938159
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 49 cost time: 0.06592130661010742
Epoch: 49, Steps: 28 | Train Loss: 0.6101272 Vali Loss: 0.1128884 Test Loss: 0.1937234
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 50 cost time: 0.06653308868408203
Epoch: 50, Steps: 28 | Train Loss: 0.6058258 Vali Loss: 0.1129152 Test Loss: 0.1937591
EarlyStopping counter: 5 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 51 cost time: 0.06429362297058105
Epoch: 51, Steps: 28 | Train Loss: 0.5936128 Vali Loss: 0.1147874 Test Loss: 0.1937773
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 52 cost time: 0.06410551071166992
Epoch: 52, Steps: 28 | Train Loss: 0.6210639 Vali Loss: 0.1151564 Test Loss: 0.1937886
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.220446049250313e-19
Epoch: 53 cost time: 0.06470227241516113
Epoch: 53, Steps: 28 | Train Loss: 0.6126479 Vali Loss: 0.1119854 Test Loss: 0.1937391
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.1102230246251566e-19
Epoch: 54 cost time: 0.06545186042785645
Epoch: 54, Steps: 28 | Train Loss: 0.6024156 Vali Loss: 0.1129145 Test Loss: 0.1937117
EarlyStopping counter: 9 out of 15
Updating learning rate to 5.551115123125783e-20
Epoch: 55 cost time: 0.06513547897338867
Epoch: 55, Steps: 28 | Train Loss: 0.6095438 Vali Loss: 0.1121857 Test Loss: 0.1937574
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.7755575615628914e-20
Epoch: 56 cost time: 0.06425881385803223
Epoch: 56, Steps: 28 | Train Loss: 0.6006097 Vali Loss: 0.1144664 Test Loss: 0.1937167
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.3877787807814457e-20
Epoch: 57 cost time: 0.06414914131164551
Epoch: 57, Steps: 28 | Train Loss: 0.6058274 Vali Loss: 0.1156718 Test Loss: 0.1937549
EarlyStopping counter: 12 out of 15
Updating learning rate to 6.938893903907229e-21
Epoch: 58 cost time: 0.0639798641204834
Epoch: 58, Steps: 28 | Train Loss: 0.6184752 Vali Loss: 0.1155609 Test Loss: 0.1937986
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.469446951953614e-21
Epoch: 59 cost time: 0.06525588035583496
Epoch: 59, Steps: 28 | Train Loss: 0.5916537 Vali Loss: 0.1149653 Test Loss: 0.1937714
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.734723475976807e-21
Epoch: 60 cost time: 0.0664362907409668
Epoch: 60, Steps: 28 | Train Loss: 0.6150143 Vali Loss: 0.1138964 Test Loss: 0.1937660
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_PatchTST_pl5_PatchTST_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1940, mae:0.3365, msIC:-0.0271, msIR:-0.0522
Total Evaluation 

MSE:0.1927Â±0.0009
MAE:0.3344Â±0.0016
msIC:-0.0189Â±0.0332
msIR:-0.0378Â±0.0654
  Evaluating PatchTST results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: iTransformer
  Training iTransformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_iTransformer_pl5Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.21644067764282227
Epoch: 1, Steps: 28 | Train Loss: 0.6608200 Vali Loss: 0.1369407 Test Loss: 0.1990024
Validation loss decreased (inf --> 0.136941).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.06352686882019043
Epoch: 2, Steps: 28 | Train Loss: 0.5718682 Vali Loss: 0.1228338 Test Loss: 0.1900024
Validation loss decreased (0.136941 --> 0.122834).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.0619199275970459
Epoch: 3, Steps: 28 | Train Loss: 0.5317820 Vali Loss: 0.1262803 Test Loss: 0.1870269
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.06299734115600586
Epoch: 4, Steps: 28 | Train Loss: 0.5129738 Vali Loss: 0.1186619 Test Loss: 0.1859038
Validation loss decreased (0.122834 --> 0.118662).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.06115603446960449
Epoch: 5, Steps: 28 | Train Loss: 0.5008562 Vali Loss: 0.1151006 Test Loss: 0.1854136
Validation loss decreased (0.118662 --> 0.115101).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.10314607620239258
Epoch: 6, Steps: 28 | Train Loss: 0.4977978 Vali Loss: 0.1167454 Test Loss: 0.1851539
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.06528759002685547
Epoch: 7, Steps: 28 | Train Loss: 0.5040815 Vali Loss: 0.1201893 Test Loss: 0.1850294
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.0648956298828125
Epoch: 8, Steps: 28 | Train Loss: 0.4933406 Vali Loss: 0.1209578 Test Loss: 0.1849698
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.06363749504089355
Epoch: 9, Steps: 28 | Train Loss: 0.4922828 Vali Loss: 0.1158835 Test Loss: 0.1849399
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.0646817684173584
Epoch: 10, Steps: 28 | Train Loss: 0.4968331 Vali Loss: 0.1198301 Test Loss: 0.1849266
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.06369614601135254
Epoch: 11, Steps: 28 | Train Loss: 0.5011746 Vali Loss: 0.1177940 Test Loss: 0.1849192
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.06251883506774902
Epoch: 12, Steps: 28 | Train Loss: 0.4914893 Vali Loss: 0.1187145 Test Loss: 0.1849142
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.06350278854370117
Epoch: 13, Steps: 28 | Train Loss: 0.4953051 Vali Loss: 0.1177753 Test Loss: 0.1849127
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.061594486236572266
Epoch: 14, Steps: 28 | Train Loss: 0.5026579 Vali Loss: 0.1167038 Test Loss: 0.1849115
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.0632939338684082
Epoch: 15, Steps: 28 | Train Loss: 0.4881297 Vali Loss: 0.1198082 Test Loss: 0.1849109
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06193065643310547
Epoch: 16, Steps: 28 | Train Loss: 0.4982721 Vali Loss: 0.1148581 Test Loss: 0.1849108
Validation loss decreased (0.115101 --> 0.114858).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.06102395057678223
Epoch: 17, Steps: 28 | Train Loss: 0.4976640 Vali Loss: 0.1165531 Test Loss: 0.1849106
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06160616874694824
Epoch: 18, Steps: 28 | Train Loss: 0.4909785 Vali Loss: 0.1178966 Test Loss: 0.1849106
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.06174206733703613
Epoch: 19, Steps: 28 | Train Loss: 0.5095589 Vali Loss: 0.1159628 Test Loss: 0.1849106
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.061372995376586914
Epoch: 20, Steps: 28 | Train Loss: 0.4906612 Vali Loss: 0.1200099 Test Loss: 0.1849106
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.06446433067321777
Epoch: 21, Steps: 28 | Train Loss: 0.4964907 Vali Loss: 0.1178460 Test Loss: 0.1849106
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.06366777420043945
Epoch: 22, Steps: 28 | Train Loss: 0.4918977 Vali Loss: 0.1157044 Test Loss: 0.1849105
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.0650930404663086
Epoch: 23, Steps: 28 | Train Loss: 0.4979065 Vali Loss: 0.1166465 Test Loss: 0.1849105
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.06343483924865723
Epoch: 24, Steps: 28 | Train Loss: 0.4981122 Vali Loss: 0.1201628 Test Loss: 0.1849105
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.06259942054748535
Epoch: 25, Steps: 28 | Train Loss: 0.5045987 Vali Loss: 0.1164642 Test Loss: 0.1849105
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.06353902816772461
Epoch: 26, Steps: 28 | Train Loss: 0.4993834 Vali Loss: 0.1167526 Test Loss: 0.1849105
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.062499284744262695
Epoch: 27, Steps: 28 | Train Loss: 0.5071282 Vali Loss: 0.1170220 Test Loss: 0.1849105
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.06495022773742676
Epoch: 28, Steps: 28 | Train Loss: 0.4989158 Vali Loss: 0.1170088 Test Loss: 0.1849105
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.06213569641113281
Epoch: 29, Steps: 28 | Train Loss: 0.5029289 Vali Loss: 0.1154993 Test Loss: 0.1849105
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.0616610050201416
Epoch: 30, Steps: 28 | Train Loss: 0.4998311 Vali Loss: 0.1148474 Test Loss: 0.1849105
Validation loss decreased (0.114858 --> 0.114847).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.06107592582702637
Epoch: 31, Steps: 28 | Train Loss: 0.4969614 Vali Loss: 0.1165506 Test Loss: 0.1849105
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.0750892162322998
Epoch: 32, Steps: 28 | Train Loss: 0.4900885 Vali Loss: 0.1171724 Test Loss: 0.1849105
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.061719655990600586
Epoch: 33, Steps: 28 | Train Loss: 0.5099271 Vali Loss: 0.1210829 Test Loss: 0.1849105
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.06214594841003418
Epoch: 34, Steps: 28 | Train Loss: 0.5000865 Vali Loss: 0.1170178 Test Loss: 0.1849105
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.06300091743469238
Epoch: 35, Steps: 28 | Train Loss: 0.5019373 Vali Loss: 0.1234116 Test Loss: 0.1849105
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.06510758399963379
Epoch: 36, Steps: 28 | Train Loss: 0.4880688 Vali Loss: 0.1170631 Test Loss: 0.1849105
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.0631554126739502
Epoch: 37, Steps: 28 | Train Loss: 0.4884260 Vali Loss: 0.1202427 Test Loss: 0.1849105
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.06183886528015137
Epoch: 38, Steps: 28 | Train Loss: 0.4971019 Vali Loss: 0.1186585 Test Loss: 0.1849105
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.0620269775390625
Epoch: 39, Steps: 28 | Train Loss: 0.4962930 Vali Loss: 0.1231636 Test Loss: 0.1849105
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.06474471092224121
Epoch: 40, Steps: 28 | Train Loss: 0.4933791 Vali Loss: 0.1146934 Test Loss: 0.1849105
Validation loss decreased (0.114847 --> 0.114693).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.06156349182128906
Epoch: 41, Steps: 28 | Train Loss: 0.4923130 Vali Loss: 0.1157032 Test Loss: 0.1849105
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.06206822395324707
Epoch: 42, Steps: 28 | Train Loss: 0.5037867 Vali Loss: 0.1184015 Test Loss: 0.1849105
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.06212329864501953
Epoch: 43, Steps: 28 | Train Loss: 0.4877584 Vali Loss: 0.1188047 Test Loss: 0.1849105
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.06188607215881348
Epoch: 44, Steps: 28 | Train Loss: 0.4986325 Vali Loss: 0.1190883 Test Loss: 0.1849105
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.06186199188232422
Epoch: 45, Steps: 28 | Train Loss: 0.4968088 Vali Loss: 0.1195415 Test Loss: 0.1849105
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 0.061860084533691406
Epoch: 46, Steps: 28 | Train Loss: 0.5031739 Vali Loss: 0.1163439 Test Loss: 0.1849105
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 47 cost time: 0.06179046630859375
Epoch: 47, Steps: 28 | Train Loss: 0.5031631 Vali Loss: 0.1193533 Test Loss: 0.1849105
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 48 cost time: 0.06277775764465332
Epoch: 48, Steps: 28 | Train Loss: 0.4914862 Vali Loss: 0.1220126 Test Loss: 0.1849105
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 49 cost time: 0.0623326301574707
Epoch: 49, Steps: 28 | Train Loss: 0.4971677 Vali Loss: 0.1183656 Test Loss: 0.1849105
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 50 cost time: 0.06301426887512207
Epoch: 50, Steps: 28 | Train Loss: 0.4972711 Vali Loss: 0.1208148 Test Loss: 0.1849105
EarlyStopping counter: 10 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 51 cost time: 0.06319093704223633
Epoch: 51, Steps: 28 | Train Loss: 0.4908503 Vali Loss: 0.1171906 Test Loss: 0.1849105
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 52 cost time: 0.06184697151184082
Epoch: 52, Steps: 28 | Train Loss: 0.4989307 Vali Loss: 0.1145412 Test Loss: 0.1849105
Validation loss decreased (0.114693 --> 0.114541).  Saving model ...
Updating learning rate to 2.220446049250313e-19
Epoch: 53 cost time: 0.06406116485595703
Epoch: 53, Steps: 28 | Train Loss: 0.5052662 Vali Loss: 0.1199461 Test Loss: 0.1849105
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1102230246251566e-19
Epoch: 54 cost time: 0.061786651611328125
Epoch: 54, Steps: 28 | Train Loss: 0.4979474 Vali Loss: 0.1184167 Test Loss: 0.1849105
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.551115123125783e-20
Epoch: 55 cost time: 0.0631856918334961
Epoch: 55, Steps: 28 | Train Loss: 0.4903437 Vali Loss: 0.1178700 Test Loss: 0.1849105
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.7755575615628914e-20
Epoch: 56 cost time: 0.06187629699707031
Epoch: 56, Steps: 28 | Train Loss: 0.4923283 Vali Loss: 0.1161870 Test Loss: 0.1849105
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.3877787807814457e-20
Epoch: 57 cost time: 0.06177926063537598
Epoch: 57, Steps: 28 | Train Loss: 0.4982934 Vali Loss: 0.1157593 Test Loss: 0.1849105
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.938893903907229e-21
Epoch: 58 cost time: 0.06167459487915039
Epoch: 58, Steps: 28 | Train Loss: 0.5068802 Vali Loss: 0.1169670 Test Loss: 0.1849105
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.469446951953614e-21
Epoch: 59 cost time: 0.0621485710144043
Epoch: 59, Steps: 28 | Train Loss: 0.5004517 Vali Loss: 0.1224187 Test Loss: 0.1849105
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.734723475976807e-21
Epoch: 60 cost time: 0.06347537040710449
Epoch: 60, Steps: 28 | Train Loss: 0.5016360 Vali Loss: 0.1170357 Test Loss: 0.1849105
EarlyStopping counter: 8 out of 15
Updating learning rate to 8.673617379884036e-22
Epoch: 61 cost time: 0.0643925666809082
Epoch: 61, Steps: 28 | Train Loss: 0.4929593 Vali Loss: 0.1204462 Test Loss: 0.1849105
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.336808689942018e-22
Epoch: 62 cost time: 0.06193113327026367
Epoch: 62, Steps: 28 | Train Loss: 0.4890523 Vali Loss: 0.1169633 Test Loss: 0.1849105
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.168404344971009e-22
Epoch: 63 cost time: 0.06227421760559082
Epoch: 63, Steps: 28 | Train Loss: 0.5063591 Vali Loss: 0.1197992 Test Loss: 0.1849105
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.0842021724855045e-22
Epoch: 64 cost time: 0.06566357612609863
Epoch: 64, Steps: 28 | Train Loss: 0.4935451 Vali Loss: 0.1179239 Test Loss: 0.1849105
EarlyStopping counter: 12 out of 15
Updating learning rate to 5.421010862427522e-23
Epoch: 65 cost time: 0.06174039840698242
Epoch: 65, Steps: 28 | Train Loss: 0.4931274 Vali Loss: 0.1177543 Test Loss: 0.1849105
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.710505431213761e-23
Epoch: 66 cost time: 0.06169581413269043
Epoch: 66, Steps: 28 | Train Loss: 0.4921155 Vali Loss: 0.1212542 Test Loss: 0.1849105
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.3552527156068806e-23
Epoch: 67 cost time: 0.06272435188293457
Epoch: 67, Steps: 28 | Train Loss: 0.4971371 Vali Loss: 0.1137116 Test Loss: 0.1849105
Validation loss decreased (0.114541 --> 0.113712).  Saving model ...
Updating learning rate to 6.776263578034403e-24
Epoch: 68 cost time: 0.06158804893493652
Epoch: 68, Steps: 28 | Train Loss: 0.4809293 Vali Loss: 0.1237633 Test Loss: 0.1849105
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.3881317890172014e-24
Epoch: 69 cost time: 0.06169867515563965
Epoch: 69, Steps: 28 | Train Loss: 0.5097091 Vali Loss: 0.1181528 Test Loss: 0.1849105
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.6940658945086007e-24
Epoch: 70 cost time: 0.0620112419128418
Epoch: 70, Steps: 28 | Train Loss: 0.4996878 Vali Loss: 0.1160151 Test Loss: 0.1849105
EarlyStopping counter: 3 out of 15
Updating learning rate to 8.470329472543004e-25
Epoch: 71 cost time: 0.06308436393737793
Epoch: 71, Steps: 28 | Train Loss: 0.5016423 Vali Loss: 0.1181587 Test Loss: 0.1849105
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.235164736271502e-25
Epoch: 72 cost time: 0.062384605407714844
Epoch: 72, Steps: 28 | Train Loss: 0.5030857 Vali Loss: 0.1151541 Test Loss: 0.1849105
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.117582368135751e-25
Epoch: 73 cost time: 0.06170177459716797
Epoch: 73, Steps: 28 | Train Loss: 0.4932901 Vali Loss: 0.1182739 Test Loss: 0.1849105
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.0587911840678754e-25
Epoch: 74 cost time: 0.06371688842773438
Epoch: 74, Steps: 28 | Train Loss: 0.4916020 Vali Loss: 0.1190707 Test Loss: 0.1849105
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.293955920339377e-26
Epoch: 75 cost time: 0.06396770477294922
Epoch: 75, Steps: 28 | Train Loss: 0.5009760 Vali Loss: 0.1168859 Test Loss: 0.1849105
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.6469779601696886e-26
Epoch: 76 cost time: 0.06365132331848145
Epoch: 76, Steps: 28 | Train Loss: 0.4937784 Vali Loss: 0.1165346 Test Loss: 0.1849105
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.3234889800848443e-26
Epoch: 77 cost time: 0.06309628486633301
Epoch: 77, Steps: 28 | Train Loss: 0.4958521 Vali Loss: 0.1167918 Test Loss: 0.1849105
EarlyStopping counter: 10 out of 15
Updating learning rate to 6.617444900424222e-27
Epoch: 78 cost time: 0.06280970573425293
Epoch: 78, Steps: 28 | Train Loss: 0.4973342 Vali Loss: 0.1153467 Test Loss: 0.1849105
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.308722450212111e-27
Epoch: 79 cost time: 0.06196141242980957
Epoch: 79, Steps: 28 | Train Loss: 0.5024056 Vali Loss: 0.1168668 Test Loss: 0.1849105
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.6543612251060554e-27
Epoch: 80 cost time: 0.06218457221984863
Epoch: 80, Steps: 28 | Train Loss: 0.4907460 Vali Loss: 0.1192527 Test Loss: 0.1849105
EarlyStopping counter: 13 out of 15
Updating learning rate to 8.271806125530277e-28
Epoch: 81 cost time: 0.06196761131286621
Epoch: 81, Steps: 28 | Train Loss: 0.5000160 Vali Loss: 0.1210917 Test Loss: 0.1849105
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.1359030627651385e-28
Epoch: 82 cost time: 0.06198477745056152
Epoch: 82, Steps: 28 | Train Loss: 0.4970869 Vali Loss: 0.1153911 Test Loss: 0.1849105
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1851, mae:0.3236, msIC:0.0576, msIR:0.1139
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.06766533851623535
Epoch: 1, Steps: 28 | Train Loss: 0.6315541 Vali Loss: 0.1287291 Test Loss: 0.1984052
Validation loss decreased (inf --> 0.128729).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.062236785888671875
Epoch: 2, Steps: 28 | Train Loss: 0.5521050 Vali Loss: 0.1169020 Test Loss: 0.1889239
Validation loss decreased (0.128729 --> 0.116902).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.06222224235534668
Epoch: 3, Steps: 28 | Train Loss: 0.5115372 Vali Loss: 0.1157614 Test Loss: 0.1861477
Validation loss decreased (0.116902 --> 0.115761).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.0626220703125
Epoch: 4, Steps: 28 | Train Loss: 0.4906206 Vali Loss: 0.1111041 Test Loss: 0.1851084
Validation loss decreased (0.115761 --> 0.111104).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.06529402732849121
Epoch: 5, Steps: 28 | Train Loss: 0.4856207 Vali Loss: 0.1063824 Test Loss: 0.1846537
Validation loss decreased (0.111104 --> 0.106382).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.0647273063659668
Epoch: 6, Steps: 28 | Train Loss: 0.4918625 Vali Loss: 0.1119109 Test Loss: 0.1844322
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.06229686737060547
Epoch: 7, Steps: 28 | Train Loss: 0.4806936 Vali Loss: 0.1143218 Test Loss: 0.1843351
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.06270122528076172
Epoch: 8, Steps: 28 | Train Loss: 0.4807509 Vali Loss: 0.1088248 Test Loss: 0.1842832
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.06736326217651367
Epoch: 9, Steps: 28 | Train Loss: 0.4879361 Vali Loss: 0.1124483 Test Loss: 0.1842543
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.06647729873657227
Epoch: 10, Steps: 28 | Train Loss: 0.4914096 Vali Loss: 0.1072253 Test Loss: 0.1842404
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.06436705589294434
Epoch: 11, Steps: 28 | Train Loss: 0.4775033 Vali Loss: 0.1142268 Test Loss: 0.1842348
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.06535696983337402
Epoch: 12, Steps: 28 | Train Loss: 0.4743633 Vali Loss: 0.1078438 Test Loss: 0.1842320
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.06879210472106934
Epoch: 13, Steps: 28 | Train Loss: 0.4876457 Vali Loss: 0.1146717 Test Loss: 0.1842299
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.06784415245056152
Epoch: 14, Steps: 28 | Train Loss: 0.4753944 Vali Loss: 0.1072873 Test Loss: 0.1842291
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.06700992584228516
Epoch: 15, Steps: 28 | Train Loss: 0.4930691 Vali Loss: 0.1100472 Test Loss: 0.1842285
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06690573692321777
Epoch: 16, Steps: 28 | Train Loss: 0.4758978 Vali Loss: 0.1092007 Test Loss: 0.1842281
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.06699109077453613
Epoch: 17, Steps: 28 | Train Loss: 0.4795835 Vali Loss: 0.1113335 Test Loss: 0.1842281
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06399941444396973
Epoch: 18, Steps: 28 | Train Loss: 0.4836599 Vali Loss: 0.1075399 Test Loss: 0.1842280
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.06358122825622559
Epoch: 19, Steps: 28 | Train Loss: 0.4892386 Vali Loss: 0.1101442 Test Loss: 0.1842280
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.06297135353088379
Epoch: 20, Steps: 28 | Train Loss: 0.4904285 Vali Loss: 0.1100902 Test Loss: 0.1842280
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1849, mae:0.3260, msIC:0.0419, msIR:0.0850
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.06434798240661621
Epoch: 1, Steps: 28 | Train Loss: 0.6243420 Vali Loss: 0.1217984 Test Loss: 0.2053597
Validation loss decreased (inf --> 0.121798).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.0620267391204834
Epoch: 2, Steps: 28 | Train Loss: 0.5424988 Vali Loss: 0.1124385 Test Loss: 0.1939513
Validation loss decreased (0.121798 --> 0.112438).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.0618593692779541
Epoch: 3, Steps: 28 | Train Loss: 0.5102291 Vali Loss: 0.1081433 Test Loss: 0.1904272
Validation loss decreased (0.112438 --> 0.108143).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.061791181564331055
Epoch: 4, Steps: 28 | Train Loss: 0.4941583 Vali Loss: 0.1055619 Test Loss: 0.1890704
Validation loss decreased (0.108143 --> 0.105562).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.061250925064086914
Epoch: 5, Steps: 28 | Train Loss: 0.4853996 Vali Loss: 0.1069958 Test Loss: 0.1884672
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.0639958381652832
Epoch: 6, Steps: 28 | Train Loss: 0.4835264 Vali Loss: 0.1054532 Test Loss: 0.1882147
Validation loss decreased (0.105562 --> 0.105453).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.061925411224365234
Epoch: 7, Steps: 28 | Train Loss: 0.4914349 Vali Loss: 0.1070661 Test Loss: 0.1880543
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.06348967552185059
Epoch: 8, Steps: 28 | Train Loss: 0.4827199 Vali Loss: 0.1061636 Test Loss: 0.1879644
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.06255865097045898
Epoch: 9, Steps: 28 | Train Loss: 0.4904290 Vali Loss: 0.1059069 Test Loss: 0.1879268
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.06485295295715332
Epoch: 10, Steps: 28 | Train Loss: 0.4855682 Vali Loss: 0.1070786 Test Loss: 0.1879066
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.06356358528137207
Epoch: 11, Steps: 28 | Train Loss: 0.4807118 Vali Loss: 0.1064157 Test Loss: 0.1878981
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.06343960762023926
Epoch: 12, Steps: 28 | Train Loss: 0.4874159 Vali Loss: 0.1036381 Test Loss: 0.1878930
Validation loss decreased (0.105453 --> 0.103638).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.061492919921875
Epoch: 13, Steps: 28 | Train Loss: 0.4808695 Vali Loss: 0.1033031 Test Loss: 0.1878892
Validation loss decreased (0.103638 --> 0.103303).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.06142449378967285
Epoch: 14, Steps: 28 | Train Loss: 0.4862322 Vali Loss: 0.1018495 Test Loss: 0.1878882
Validation loss decreased (0.103303 --> 0.101850).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.06272554397583008
Epoch: 15, Steps: 28 | Train Loss: 0.4757224 Vali Loss: 0.1078675 Test Loss: 0.1878878
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.06705498695373535
Epoch: 16, Steps: 28 | Train Loss: 0.4794111 Vali Loss: 0.1054217 Test Loss: 0.1878875
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.0675199031829834
Epoch: 17, Steps: 28 | Train Loss: 0.4921889 Vali Loss: 0.1056055 Test Loss: 0.1878874
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.06721687316894531
Epoch: 18, Steps: 28 | Train Loss: 0.4913294 Vali Loss: 0.1050659 Test Loss: 0.1878873
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.06667470932006836
Epoch: 19, Steps: 28 | Train Loss: 0.4820420 Vali Loss: 0.1063308 Test Loss: 0.1878873
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.06833052635192871
Epoch: 20, Steps: 28 | Train Loss: 0.4879446 Vali Loss: 0.1089957 Test Loss: 0.1878873
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.068023681640625
Epoch: 21, Steps: 28 | Train Loss: 0.4889255 Vali Loss: 0.1047571 Test Loss: 0.1878873
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.06830906867980957
Epoch: 22, Steps: 28 | Train Loss: 0.4840224 Vali Loss: 0.1067048 Test Loss: 0.1878873
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.07208013534545898
Epoch: 23, Steps: 28 | Train Loss: 0.4865636 Vali Loss: 0.1060361 Test Loss: 0.1878873
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.06476783752441406
Epoch: 24, Steps: 28 | Train Loss: 0.4922061 Vali Loss: 0.1066411 Test Loss: 0.1878873
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.0658566951751709
Epoch: 25, Steps: 28 | Train Loss: 0.4881549 Vali Loss: 0.1060310 Test Loss: 0.1878873
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.06499266624450684
Epoch: 26, Steps: 28 | Train Loss: 0.4865398 Vali Loss: 0.1049759 Test Loss: 0.1878873
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.06834292411804199
Epoch: 27, Steps: 28 | Train Loss: 0.4866794 Vali Loss: 0.1056980 Test Loss: 0.1878873
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.067230224609375
Epoch: 28, Steps: 28 | Train Loss: 0.4848089 Vali Loss: 0.1034041 Test Loss: 0.1878873
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.06709694862365723
Epoch: 29, Steps: 28 | Train Loss: 0.4908051 Vali Loss: 0.1045452 Test Loss: 0.1878873
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_iTransformer_pl5_iTransformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1881, mae:0.3295, msIC:0.0071, msIR:0.0145
Total Evaluation 

MSE:0.1860Â±0.0015
MAE:0.3264Â±0.0024
msIC:0.0355Â±0.0211
msIR:0.0711Â±0.0417
  Evaluating iTransformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: TimeMixer
  Training TimeMixer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_TimeMixer_pl5Model:              TimeMixer           

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          0                   
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            16                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       50                  Batch Size:         64                  
  Patience:           10                  Learning Rate:      0.01                
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.3835165500640869
Epoch: 1, Steps: 14 | Train Loss: 0.5791532 Vali Loss: 0.1117638 Test Loss: 0.1725747
Validation loss decreased (inf --> 0.111764).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.22039532661437988
Epoch: 2, Steps: 14 | Train Loss: 0.4656513 Vali Loss: 0.1102369 Test Loss: 0.1712908
Validation loss decreased (0.111764 --> 0.110237).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.23919939994812012
Epoch: 3, Steps: 14 | Train Loss: 0.4450445 Vali Loss: 0.1011178 Test Loss: 0.1715740
Validation loss decreased (0.110237 --> 0.101118).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.2290208339691162
Epoch: 4, Steps: 14 | Train Loss: 0.4345096 Vali Loss: 0.1122991 Test Loss: 0.1696973
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.1136012077331543
Epoch: 5, Steps: 14 | Train Loss: 0.4283750 Vali Loss: 0.1028371 Test Loss: 0.1694672
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.11378049850463867
Epoch: 6, Steps: 14 | Train Loss: 0.4283864 Vali Loss: 0.1032325 Test Loss: 0.1695946
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.11395478248596191
Epoch: 7, Steps: 14 | Train Loss: 0.4276036 Vali Loss: 0.1043924 Test Loss: 0.1695652
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.11455678939819336
Epoch: 8, Steps: 14 | Train Loss: 0.4275678 Vali Loss: 0.1047831 Test Loss: 0.1696017
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.11386656761169434
Epoch: 9, Steps: 14 | Train Loss: 0.4275080 Vali Loss: 0.0973706 Test Loss: 0.1695758
Validation loss decreased (0.101118 --> 0.097371).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.19379448890686035
Epoch: 10, Steps: 14 | Train Loss: 0.4269953 Vali Loss: 0.1011679 Test Loss: 0.1695676
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.13379979133605957
Epoch: 11, Steps: 14 | Train Loss: 0.4267265 Vali Loss: 0.1041166 Test Loss: 0.1695689
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.11432790756225586
Epoch: 12, Steps: 14 | Train Loss: 0.4270536 Vali Loss: 0.1091041 Test Loss: 0.1695697
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.11382722854614258
Epoch: 13, Steps: 14 | Train Loss: 0.4271316 Vali Loss: 0.1052276 Test Loss: 0.1695709
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.11496925354003906
Epoch: 14, Steps: 14 | Train Loss: 0.4265402 Vali Loss: 0.1117761 Test Loss: 0.1695719
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.1141815185546875
Epoch: 15, Steps: 14 | Train Loss: 0.4264636 Vali Loss: 0.0945694 Test Loss: 0.1695716
Validation loss decreased (0.097371 --> 0.094569).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.13298392295837402
Epoch: 16, Steps: 14 | Train Loss: 0.4264418 Vali Loss: 0.1101359 Test Loss: 0.1695718
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.1219170093536377
Epoch: 17, Steps: 14 | Train Loss: 0.4266915 Vali Loss: 0.1087960 Test Loss: 0.1695718
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.1286938190460205
Epoch: 18, Steps: 14 | Train Loss: 0.4271570 Vali Loss: 0.1109090 Test Loss: 0.1695718
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.11477017402648926
Epoch: 19, Steps: 14 | Train Loss: 0.4256014 Vali Loss: 0.0975202 Test Loss: 0.1695718
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.11504745483398438
Epoch: 20, Steps: 14 | Train Loss: 0.4289126 Vali Loss: 0.0998468 Test Loss: 0.1695718
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.1212162971496582
Epoch: 21, Steps: 14 | Train Loss: 0.4260822 Vali Loss: 0.0973813 Test Loss: 0.1695718
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.11486577987670898
Epoch: 22, Steps: 14 | Train Loss: 0.4264588 Vali Loss: 0.1062967 Test Loss: 0.1695718
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.11483240127563477
Epoch: 23, Steps: 14 | Train Loss: 0.4258739 Vali Loss: 0.1084181 Test Loss: 0.1695718
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.16435861587524414
Epoch: 24, Steps: 14 | Train Loss: 0.4267074 Vali Loss: 0.0991734 Test Loss: 0.1695718
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.26077914237976074
Epoch: 25, Steps: 14 | Train Loss: 0.4264901 Vali Loss: 0.1025179 Test Loss: 0.1695718
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1753, mae:0.3160, msIC:0.0197, msIR:0.0391
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.14119887351989746
Epoch: 1, Steps: 14 | Train Loss: 0.5681827 Vali Loss: 0.1011093 Test Loss: 0.1755953
Validation loss decreased (inf --> 0.101109).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.13842129707336426
Epoch: 2, Steps: 14 | Train Loss: 0.4753057 Vali Loss: 0.1100034 Test Loss: 0.1739840
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
Epoch: 3 cost time: 0.14361238479614258
Epoch: 3, Steps: 14 | Train Loss: 0.4445784 Vali Loss: 0.1069592 Test Loss: 0.1697003
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.11868572235107422
Epoch: 4, Steps: 14 | Train Loss: 0.4378795 Vali Loss: 0.1042140 Test Loss: 0.1687865
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.11599540710449219
Epoch: 5, Steps: 14 | Train Loss: 0.4290474 Vali Loss: 0.0949075 Test Loss: 0.1689712
Validation loss decreased (0.101109 --> 0.094907).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.1437215805053711
Epoch: 6, Steps: 14 | Train Loss: 0.4258111 Vali Loss: 0.1000600 Test Loss: 0.1688518
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.11561918258666992
Epoch: 7, Steps: 14 | Train Loss: 0.4237277 Vali Loss: 0.0984388 Test Loss: 0.1688707
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.11514568328857422
Epoch: 8, Steps: 14 | Train Loss: 0.4202477 Vali Loss: 0.1060336 Test Loss: 0.1688645
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.11539816856384277
Epoch: 9, Steps: 14 | Train Loss: 0.4220343 Vali Loss: 0.1067662 Test Loss: 0.1688623
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.19688105583190918
Epoch: 10, Steps: 14 | Train Loss: 0.4192982 Vali Loss: 0.1033173 Test Loss: 0.1688537
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.21671175956726074
Epoch: 11, Steps: 14 | Train Loss: 0.4200182 Vali Loss: 0.1017663 Test Loss: 0.1688589
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.15707111358642578
Epoch: 12, Steps: 14 | Train Loss: 0.4198511 Vali Loss: 0.1051522 Test Loss: 0.1688610
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.17352724075317383
Epoch: 13, Steps: 14 | Train Loss: 0.4196127 Vali Loss: 0.0989206 Test Loss: 0.1688599
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.21140098571777344
Epoch: 14, Steps: 14 | Train Loss: 0.4193199 Vali Loss: 0.1015206 Test Loss: 0.1688599
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.1862802505493164
Epoch: 15, Steps: 14 | Train Loss: 0.4193940 Vali Loss: 0.1057883 Test Loss: 0.1688603
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1749, mae:0.3157, msIC:0.0280, msIR:0.0591
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.13336944580078125
Epoch: 1, Steps: 14 | Train Loss: 0.5823330 Vali Loss: 0.1089263 Test Loss: 0.1732456
Validation loss decreased (inf --> 0.108926).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.135969877243042
Epoch: 2, Steps: 14 | Train Loss: 0.4613921 Vali Loss: 0.1067858 Test Loss: 0.1719669
Validation loss decreased (0.108926 --> 0.106786).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.13987326622009277
Epoch: 3, Steps: 14 | Train Loss: 0.4413315 Vali Loss: 0.1092328 Test Loss: 0.1701171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.1455988883972168
Epoch: 4, Steps: 14 | Train Loss: 0.4314286 Vali Loss: 0.1024963 Test Loss: 0.1694747
Validation loss decreased (0.106786 --> 0.102496).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.1328721046447754
Epoch: 5, Steps: 14 | Train Loss: 0.4278937 Vali Loss: 0.0983799 Test Loss: 0.1695927
Validation loss decreased (0.102496 --> 0.098380).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.1594839096069336
Epoch: 6, Steps: 14 | Train Loss: 0.4241280 Vali Loss: 0.1014845 Test Loss: 0.1695361
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.13495182991027832
Epoch: 7, Steps: 14 | Train Loss: 0.4216542 Vali Loss: 0.1074518 Test Loss: 0.1695762
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.11815714836120605
Epoch: 8, Steps: 14 | Train Loss: 0.4204183 Vali Loss: 0.1053993 Test Loss: 0.1695995
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.11435937881469727
Epoch: 9, Steps: 14 | Train Loss: 0.4198838 Vali Loss: 0.1138132 Test Loss: 0.1695955
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.11500358581542969
Epoch: 10, Steps: 14 | Train Loss: 0.4187725 Vali Loss: 0.1037079 Test Loss: 0.1695991
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.1144399642944336
Epoch: 11, Steps: 14 | Train Loss: 0.4179745 Vali Loss: 0.1018827 Test Loss: 0.1696060
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.11442303657531738
Epoch: 12, Steps: 14 | Train Loss: 0.4190703 Vali Loss: 0.1051045 Test Loss: 0.1696083
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.11482572555541992
Epoch: 13, Steps: 14 | Train Loss: 0.4191467 Vali Loss: 0.1064972 Test Loss: 0.1696089
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.11450648307800293
Epoch: 14, Steps: 14 | Train Loss: 0.4178395 Vali Loss: 0.1016451 Test Loss: 0.1696104
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.11471033096313477
Epoch: 15, Steps: 14 | Train Loss: 0.4196949 Vali Loss: 0.1091535 Test Loss: 0.1696105
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimeMixer_pl5_TimeMixer_custom_ftMS_sl128_ll0_pl5_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1753, mae:0.3156, msIC:0.0163, msIR:0.0339
Total Evaluation 

MSE:0.1752Â±0.0002
MAE:0.3158Â±0.0002
msIC:0.0213Â±0.0049
msIR:0.0440Â±0.0109
  Evaluating TimeMixer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: Transformer
  Training Transformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Transformer_pl5Model:              Transformer         

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.45082569122314453
Epoch: 1, Steps: 28 | Train Loss: 0.5912025 Vali Loss: 0.1203646 Test Loss: 0.2084651
Validation loss decreased (inf --> 0.120365).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.1602485179901123
Epoch: 2, Steps: 28 | Train Loss: 0.4912040 Vali Loss: 0.1088758 Test Loss: 0.1911333
Validation loss decreased (0.120365 --> 0.108876).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.16754603385925293
Epoch: 3, Steps: 28 | Train Loss: 0.4670249 Vali Loss: 0.1058707 Test Loss: 0.1911103
Validation loss decreased (0.108876 --> 0.105871).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.16591739654541016
Epoch: 4, Steps: 28 | Train Loss: 0.4669285 Vali Loss: 0.1056990 Test Loss: 0.1861898
Validation loss decreased (0.105871 --> 0.105699).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.16614747047424316
Epoch: 5, Steps: 28 | Train Loss: 0.4653928 Vali Loss: 0.1077585 Test Loss: 0.1853368
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.11106181144714355
Epoch: 6, Steps: 28 | Train Loss: 0.4644828 Vali Loss: 0.1094031 Test Loss: 0.1854332
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.11119294166564941
Epoch: 7, Steps: 28 | Train Loss: 0.4649428 Vali Loss: 0.1095727 Test Loss: 0.1853928
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.11106109619140625
Epoch: 8, Steps: 28 | Train Loss: 0.4589156 Vali Loss: 0.1067894 Test Loss: 0.1852013
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.11127257347106934
Epoch: 9, Steps: 28 | Train Loss: 0.4687080 Vali Loss: 0.1092223 Test Loss: 0.1851590
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.11153316497802734
Epoch: 10, Steps: 28 | Train Loss: 0.4695331 Vali Loss: 0.1003699 Test Loss: 0.1851195
Validation loss decreased (0.105699 --> 0.100370).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.12564945220947266
Epoch: 11, Steps: 28 | Train Loss: 0.4583748 Vali Loss: 0.1021421 Test Loss: 0.1851248
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.11260676383972168
Epoch: 12, Steps: 28 | Train Loss: 0.4615787 Vali Loss: 0.1060147 Test Loss: 0.1851158
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.1638622283935547
Epoch: 13, Steps: 28 | Train Loss: 0.4609215 Vali Loss: 0.1018349 Test Loss: 0.1851047
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.11126470565795898
Epoch: 14, Steps: 28 | Train Loss: 0.4631695 Vali Loss: 0.1050860 Test Loss: 0.1851039
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.1113276481628418
Epoch: 15, Steps: 28 | Train Loss: 0.4566593 Vali Loss: 0.1017868 Test Loss: 0.1851001
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.11127734184265137
Epoch: 16, Steps: 28 | Train Loss: 0.4637359 Vali Loss: 0.1072273 Test Loss: 0.1850992
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.11138224601745605
Epoch: 17, Steps: 28 | Train Loss: 0.4600432 Vali Loss: 0.1087189 Test Loss: 0.1850992
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.1114356517791748
Epoch: 18, Steps: 28 | Train Loss: 0.4622998 Vali Loss: 0.1064739 Test Loss: 0.1850992
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.11139178276062012
Epoch: 19, Steps: 28 | Train Loss: 0.4662718 Vali Loss: 0.1063492 Test Loss: 0.1850992
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.11162662506103516
Epoch: 20, Steps: 28 | Train Loss: 0.4599392 Vali Loss: 0.1066097 Test Loss: 0.1850992
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.11157631874084473
Epoch: 21, Steps: 28 | Train Loss: 0.4659292 Vali Loss: 0.1044037 Test Loss: 0.1850992
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.11131167411804199
Epoch: 22, Steps: 28 | Train Loss: 0.4620580 Vali Loss: 0.1075283 Test Loss: 0.1850992
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.11130714416503906
Epoch: 23, Steps: 28 | Train Loss: 0.4635815 Vali Loss: 0.1028869 Test Loss: 0.1850992
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.1734762191772461
Epoch: 24, Steps: 28 | Train Loss: 0.4611468 Vali Loss: 0.1041551 Test Loss: 0.1850992
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.1309366226196289
Epoch: 25, Steps: 28 | Train Loss: 0.4593427 Vali Loss: 0.1068101 Test Loss: 0.1850992
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1852, mae:0.3214, msIC:0.0103, msIR:0.0217
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.2159285545349121
Epoch: 1, Steps: 28 | Train Loss: 0.5344375 Vali Loss: 0.1074541 Test Loss: 0.1981763
Validation loss decreased (inf --> 0.107454).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.21670770645141602
Epoch: 2, Steps: 28 | Train Loss: 0.4781473 Vali Loss: 0.1059727 Test Loss: 0.1827173
Validation loss decreased (0.107454 --> 0.105973).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.24431061744689941
Epoch: 3, Steps: 28 | Train Loss: 0.4633054 Vali Loss: 0.1036100 Test Loss: 0.1826104
Validation loss decreased (0.105973 --> 0.103610).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.1506333351135254
Epoch: 4, Steps: 28 | Train Loss: 0.4640157 Vali Loss: 0.1019690 Test Loss: 0.1825125
Validation loss decreased (0.103610 --> 0.101969).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.16609454154968262
Epoch: 5, Steps: 28 | Train Loss: 0.4591371 Vali Loss: 0.1035879 Test Loss: 0.1822969
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.17557477951049805
Epoch: 6, Steps: 28 | Train Loss: 0.4582598 Vali Loss: 0.1043759 Test Loss: 0.1821915
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.19507741928100586
Epoch: 7, Steps: 28 | Train Loss: 0.4558436 Vali Loss: 0.1019813 Test Loss: 0.1821036
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.23208403587341309
Epoch: 8, Steps: 28 | Train Loss: 0.4602636 Vali Loss: 0.1056469 Test Loss: 0.1819585
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.1813652515411377
Epoch: 9, Steps: 28 | Train Loss: 0.4547692 Vali Loss: 0.1012119 Test Loss: 0.1819386
Validation loss decreased (0.101969 --> 0.101212).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.20725464820861816
Epoch: 10, Steps: 28 | Train Loss: 0.4559851 Vali Loss: 0.1052415 Test Loss: 0.1819886
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.1678314208984375
Epoch: 11, Steps: 28 | Train Loss: 0.4551355 Vali Loss: 0.1043645 Test Loss: 0.1819796
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.1648104190826416
Epoch: 12, Steps: 28 | Train Loss: 0.4589321 Vali Loss: 0.1069894 Test Loss: 0.1819627
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.1920459270477295
Epoch: 13, Steps: 28 | Train Loss: 0.4566155 Vali Loss: 0.1011676 Test Loss: 0.1819590
Validation loss decreased (0.101212 --> 0.101168).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.19962120056152344
Epoch: 14, Steps: 28 | Train Loss: 0.4526093 Vali Loss: 0.1052807 Test Loss: 0.1819600
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.12678813934326172
Epoch: 15, Steps: 28 | Train Loss: 0.4571718 Vali Loss: 0.1086334 Test Loss: 0.1819586
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.15375232696533203
Epoch: 16, Steps: 28 | Train Loss: 0.4619708 Vali Loss: 0.1000647 Test Loss: 0.1819578
Validation loss decreased (0.101168 --> 0.100065).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.20591235160827637
Epoch: 17, Steps: 28 | Train Loss: 0.4508845 Vali Loss: 0.1035487 Test Loss: 0.1819574
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13043999671936035
Epoch: 18, Steps: 28 | Train Loss: 0.4615052 Vali Loss: 0.1045486 Test Loss: 0.1819575
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.12730765342712402
Epoch: 19, Steps: 28 | Train Loss: 0.4634903 Vali Loss: 0.1036375 Test Loss: 0.1819574
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.1564006805419922
Epoch: 20, Steps: 28 | Train Loss: 0.4601904 Vali Loss: 0.1007071 Test Loss: 0.1819574
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.15822219848632812
Epoch: 21, Steps: 28 | Train Loss: 0.4649475 Vali Loss: 0.1027263 Test Loss: 0.1819574
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.14371037483215332
Epoch: 22, Steps: 28 | Train Loss: 0.4578005 Vali Loss: 0.1053244 Test Loss: 0.1819574
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.15271592140197754
Epoch: 23, Steps: 28 | Train Loss: 0.4581464 Vali Loss: 0.1112473 Test Loss: 0.1819574
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.2091810703277588
Epoch: 24, Steps: 28 | Train Loss: 0.4572206 Vali Loss: 0.1018172 Test Loss: 0.1819574
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.11138415336608887
Epoch: 25, Steps: 28 | Train Loss: 0.4572920 Vali Loss: 0.1017534 Test Loss: 0.1819574
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.1133735179901123
Epoch: 26, Steps: 28 | Train Loss: 0.4606349 Vali Loss: 0.1060949 Test Loss: 0.1819574
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.11181330680847168
Epoch: 27, Steps: 28 | Train Loss: 0.4564254 Vali Loss: 0.1033122 Test Loss: 0.1819574
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.11136841773986816
Epoch: 28, Steps: 28 | Train Loss: 0.4569036 Vali Loss: 0.1082272 Test Loss: 0.1819574
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.12596797943115234
Epoch: 29, Steps: 28 | Train Loss: 0.4581672 Vali Loss: 0.1042927 Test Loss: 0.1819574
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.12335777282714844
Epoch: 30, Steps: 28 | Train Loss: 0.4583864 Vali Loss: 0.1010875 Test Loss: 0.1819574
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.11147093772888184
Epoch: 31, Steps: 28 | Train Loss: 0.4589837 Vali Loss: 0.1048369 Test Loss: 0.1819574
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1821, mae:0.3205, msIC:-0.0186, msIR:-0.0405
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.19045042991638184
Epoch: 1, Steps: 28 | Train Loss: 0.5557336 Vali Loss: 0.1139642 Test Loss: 0.1867819
Validation loss decreased (inf --> 0.113964).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.23091411590576172
Epoch: 2, Steps: 28 | Train Loss: 0.4990664 Vali Loss: 0.1051977 Test Loss: 0.1906424
Validation loss decreased (0.113964 --> 0.105198).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2025601863861084
Epoch: 3, Steps: 28 | Train Loss: 0.4668516 Vali Loss: 0.1052715 Test Loss: 0.1805451
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.1285722255706787
Epoch: 4, Steps: 28 | Train Loss: 0.4688752 Vali Loss: 0.1056931 Test Loss: 0.1771555
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.14857721328735352
Epoch: 5, Steps: 28 | Train Loss: 0.4622914 Vali Loss: 0.1010235 Test Loss: 0.1774827
Validation loss decreased (0.105198 --> 0.101023).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2223823070526123
Epoch: 6, Steps: 28 | Train Loss: 0.4621489 Vali Loss: 0.1039245 Test Loss: 0.1775214
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.14094114303588867
Epoch: 7, Steps: 28 | Train Loss: 0.4550302 Vali Loss: 0.1037365 Test Loss: 0.1776266
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.15009403228759766
Epoch: 8, Steps: 28 | Train Loss: 0.4660705 Vali Loss: 0.1003860 Test Loss: 0.1778807
Validation loss decreased (0.101023 --> 0.100386).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.15538382530212402
Epoch: 9, Steps: 28 | Train Loss: 0.4636076 Vali Loss: 0.0993773 Test Loss: 0.1778372
Validation loss decreased (0.100386 --> 0.099377).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.1999976634979248
Epoch: 10, Steps: 28 | Train Loss: 0.4611412 Vali Loss: 0.1038529 Test Loss: 0.1777281
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.15397214889526367
Epoch: 11, Steps: 28 | Train Loss: 0.4622566 Vali Loss: 0.1044439 Test Loss: 0.1777328
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.12079977989196777
Epoch: 12, Steps: 28 | Train Loss: 0.4634311 Vali Loss: 0.1012002 Test Loss: 0.1777482
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.11162662506103516
Epoch: 13, Steps: 28 | Train Loss: 0.4626707 Vali Loss: 0.1042102 Test Loss: 0.1777467
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.1116633415222168
Epoch: 14, Steps: 28 | Train Loss: 0.4580464 Vali Loss: 0.1024539 Test Loss: 0.1777444
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.11175298690795898
Epoch: 15, Steps: 28 | Train Loss: 0.4604094 Vali Loss: 0.1042863 Test Loss: 0.1777451
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.11181378364562988
Epoch: 16, Steps: 28 | Train Loss: 0.4658166 Vali Loss: 0.1035837 Test Loss: 0.1777446
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.210066556930542
Epoch: 17, Steps: 28 | Train Loss: 0.4565243 Vali Loss: 0.1017842 Test Loss: 0.1777446
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.20189929008483887
Epoch: 18, Steps: 28 | Train Loss: 0.4622326 Vali Loss: 0.1032346 Test Loss: 0.1777445
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.11178088188171387
Epoch: 19, Steps: 28 | Train Loss: 0.4611471 Vali Loss: 0.1000443 Test Loss: 0.1777445
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.12062716484069824
Epoch: 20, Steps: 28 | Train Loss: 0.4654305 Vali Loss: 0.1059270 Test Loss: 0.1777445
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.12973403930664062
Epoch: 21, Steps: 28 | Train Loss: 0.4624811 Vali Loss: 0.1011001 Test Loss: 0.1777445
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.12818408012390137
Epoch: 22, Steps: 28 | Train Loss: 0.4562802 Vali Loss: 0.1013328 Test Loss: 0.1777445
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13109230995178223
Epoch: 23, Steps: 28 | Train Loss: 0.4570744 Vali Loss: 0.1004217 Test Loss: 0.1777445
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.12831592559814453
Epoch: 24, Steps: 28 | Train Loss: 0.4637228 Vali Loss: 0.1065783 Test Loss: 0.1777445
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Transformer_pl5_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1780, mae:0.3163, msIC:0.0138, msIR:0.0262
Total Evaluation 

MSE:0.1818Â±0.0029
MAE:0.3194Â±0.0022
msIC:0.0018Â±0.0145
msIR:0.0025Â±0.0304
  Evaluating Transformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: Autoformer
  Training Autoformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Autoformer_pl5Model:              Autoformer          

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.6981048583984375
Epoch: 1, Steps: 28 | Train Loss: 0.6627422 Vali Loss: 0.1817813 Test Loss: 0.2648962
Validation loss decreased (inf --> 0.181781).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.28932738304138184
Epoch: 2, Steps: 28 | Train Loss: 0.5372705 Vali Loss: 0.1286085 Test Loss: 0.2018915
Validation loss decreased (0.181781 --> 0.128609).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2942357063293457
Epoch: 3, Steps: 28 | Train Loss: 0.5077313 Vali Loss: 0.1153061 Test Loss: 0.1929826
Validation loss decreased (0.128609 --> 0.115306).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.28822922706604004
Epoch: 4, Steps: 28 | Train Loss: 0.4974012 Vali Loss: 0.1099856 Test Loss: 0.1909852
Validation loss decreased (0.115306 --> 0.109986).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2863330841064453
Epoch: 5, Steps: 28 | Train Loss: 0.4895704 Vali Loss: 0.1128787 Test Loss: 0.1904028
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.29020047187805176
Epoch: 6, Steps: 28 | Train Loss: 0.4843156 Vali Loss: 0.1148998 Test Loss: 0.1899970
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2832612991333008
Epoch: 7, Steps: 28 | Train Loss: 0.4912026 Vali Loss: 0.1118328 Test Loss: 0.1890263
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.2845456600189209
Epoch: 8, Steps: 28 | Train Loss: 0.4926358 Vali Loss: 0.1136171 Test Loss: 0.1891433
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.28835439682006836
Epoch: 9, Steps: 28 | Train Loss: 0.4887193 Vali Loss: 0.1138196 Test Loss: 0.1890840
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.2842879295349121
Epoch: 10, Steps: 28 | Train Loss: 0.4871805 Vali Loss: 0.1105477 Test Loss: 0.1890073
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.2831904888153076
Epoch: 11, Steps: 28 | Train Loss: 0.4909828 Vali Loss: 0.1113907 Test Loss: 0.1890106
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.2877066135406494
Epoch: 12, Steps: 28 | Train Loss: 0.4882179 Vali Loss: 0.1123998 Test Loss: 0.1890063
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2835698127746582
Epoch: 13, Steps: 28 | Train Loss: 0.4920344 Vali Loss: 0.1103289 Test Loss: 0.1890031
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.28265380859375
Epoch: 14, Steps: 28 | Train Loss: 0.4855089 Vali Loss: 0.1148006 Test Loss: 0.1890676
EarlyStopping counter: 10 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.29390716552734375
Epoch: 15, Steps: 28 | Train Loss: 0.4768441 Vali Loss: 0.1117733 Test Loss: 0.1890676
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.2943379878997803
Epoch: 16, Steps: 28 | Train Loss: 0.4848944 Vali Loss: 0.1130928 Test Loss: 0.1890672
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.28305983543395996
Epoch: 17, Steps: 28 | Train Loss: 0.4872067 Vali Loss: 0.1116960 Test Loss: 0.1890664
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.2914144992828369
Epoch: 18, Steps: 28 | Train Loss: 0.4804332 Vali Loss: 0.1130666 Test Loss: 0.1890665
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.2871711254119873
Epoch: 19, Steps: 28 | Train Loss: 0.4836406 Vali Loss: 0.1119720 Test Loss: 0.1890663
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1912, mae:0.3352, msIC:0.0433, msIR:0.0864
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.29038286209106445
Epoch: 1, Steps: 28 | Train Loss: 0.7126514 Vali Loss: 0.1394828 Test Loss: 0.2152423
Validation loss decreased (inf --> 0.139483).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.2924830913543701
Epoch: 2, Steps: 28 | Train Loss: 0.5589507 Vali Loss: 0.1354342 Test Loss: 0.2072591
Validation loss decreased (0.139483 --> 0.135434).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2935473918914795
Epoch: 3, Steps: 28 | Train Loss: 0.5165772 Vali Loss: 0.1290134 Test Loss: 0.2024649
Validation loss decreased (0.135434 --> 0.129013).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.30388903617858887
Epoch: 4, Steps: 28 | Train Loss: 0.5075964 Vali Loss: 0.1247867 Test Loss: 0.1971793
Validation loss decreased (0.129013 --> 0.124787).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2991602420806885
Epoch: 5, Steps: 28 | Train Loss: 0.5032678 Vali Loss: 0.1217826 Test Loss: 0.1955426
Validation loss decreased (0.124787 --> 0.121783).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2943735122680664
Epoch: 6, Steps: 28 | Train Loss: 0.4980973 Vali Loss: 0.1208529 Test Loss: 0.1949197
Validation loss decreased (0.121783 --> 0.120853).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2956233024597168
Epoch: 7, Steps: 28 | Train Loss: 0.4898301 Vali Loss: 0.1199032 Test Loss: 0.1954041
Validation loss decreased (0.120853 --> 0.119903).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.29061031341552734
Epoch: 8, Steps: 28 | Train Loss: 0.4988950 Vali Loss: 0.1190591 Test Loss: 0.1952257
Validation loss decreased (0.119903 --> 0.119059).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.2951948642730713
Epoch: 9, Steps: 28 | Train Loss: 0.5023684 Vali Loss: 0.1197643 Test Loss: 0.1953515
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.29108667373657227
Epoch: 10, Steps: 28 | Train Loss: 0.4974438 Vali Loss: 0.1213630 Test Loss: 0.1953965
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.29212427139282227
Epoch: 11, Steps: 28 | Train Loss: 0.4974499 Vali Loss: 0.1226887 Test Loss: 0.1953771
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.29482030868530273
Epoch: 12, Steps: 28 | Train Loss: 0.4914727 Vali Loss: 0.1228673 Test Loss: 0.1953554
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2869131565093994
Epoch: 13, Steps: 28 | Train Loss: 0.4919056 Vali Loss: 0.1221592 Test Loss: 0.1953504
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2859044075012207
Epoch: 14, Steps: 28 | Train Loss: 0.4961163 Vali Loss: 0.1231428 Test Loss: 0.1953505
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.29213428497314453
Epoch: 15, Steps: 28 | Train Loss: 0.4938929 Vali Loss: 0.1162867 Test Loss: 0.1953494
Validation loss decreased (0.119059 --> 0.116287).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.29056406021118164
Epoch: 16, Steps: 28 | Train Loss: 0.4910576 Vali Loss: 0.1161954 Test Loss: 0.1953507
Validation loss decreased (0.116287 --> 0.116195).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.3015620708465576
Epoch: 17, Steps: 28 | Train Loss: 0.4928090 Vali Loss: 0.1179995 Test Loss: 0.1953506
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.29520583152770996
Epoch: 18, Steps: 28 | Train Loss: 0.4992635 Vali Loss: 0.1190052 Test Loss: 0.1953503
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.29316210746765137
Epoch: 19, Steps: 28 | Train Loss: 0.4920736 Vali Loss: 0.1197027 Test Loss: 0.1953503
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.2919454574584961
Epoch: 20, Steps: 28 | Train Loss: 0.4861557 Vali Loss: 0.1189359 Test Loss: 0.1953504
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.29086875915527344
Epoch: 21, Steps: 28 | Train Loss: 0.4910147 Vali Loss: 0.1182639 Test Loss: 0.1953504
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.28989601135253906
Epoch: 22, Steps: 28 | Train Loss: 0.5005970 Vali Loss: 0.1223807 Test Loss: 0.1953503
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.29365992546081543
Epoch: 23, Steps: 28 | Train Loss: 0.4942585 Vali Loss: 0.1186947 Test Loss: 0.1953504
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.29808616638183594
Epoch: 24, Steps: 28 | Train Loss: 0.4918036 Vali Loss: 0.1171721 Test Loss: 0.1953505
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.3003115653991699
Epoch: 25, Steps: 28 | Train Loss: 0.4830554 Vali Loss: 0.1218105 Test Loss: 0.1953505
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.2945127487182617
Epoch: 26, Steps: 28 | Train Loss: 0.4894028 Vali Loss: 0.1164529 Test Loss: 0.1953505
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.300950288772583
Epoch: 27, Steps: 28 | Train Loss: 0.4981963 Vali Loss: 0.1212022 Test Loss: 0.1953505
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.2955806255340576
Epoch: 28, Steps: 28 | Train Loss: 0.5008597 Vali Loss: 0.1179433 Test Loss: 0.1953505
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.2974390983581543
Epoch: 29, Steps: 28 | Train Loss: 0.4905321 Vali Loss: 0.1216493 Test Loss: 0.1953505
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.2968015670776367
Epoch: 30, Steps: 28 | Train Loss: 0.5000155 Vali Loss: 0.1190683 Test Loss: 0.1953505
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.2941153049468994
Epoch: 31, Steps: 28 | Train Loss: 0.4910303 Vali Loss: 0.1212237 Test Loss: 0.1953505
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1955, mae:0.3365, msIC:-0.0455, msIR:-0.0960
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.2927210330963135
Epoch: 1, Steps: 28 | Train Loss: 0.5658404 Vali Loss: 0.1459704 Test Loss: 0.2111806
Validation loss decreased (inf --> 0.145970).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.29213929176330566
Epoch: 2, Steps: 28 | Train Loss: 0.5021550 Vali Loss: 0.1268382 Test Loss: 0.1908610
Validation loss decreased (0.145970 --> 0.126838).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.30009961128234863
Epoch: 3, Steps: 28 | Train Loss: 0.5098265 Vali Loss: 0.1211778 Test Loss: 0.1882933
Validation loss decreased (0.126838 --> 0.121178).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.3038008213043213
Epoch: 4, Steps: 28 | Train Loss: 0.4775433 Vali Loss: 0.1239076 Test Loss: 0.1881352
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.298626184463501
Epoch: 5, Steps: 28 | Train Loss: 0.4786363 Vali Loss: 0.1226897 Test Loss: 0.1883233
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2962837219238281
Epoch: 6, Steps: 28 | Train Loss: 0.4746546 Vali Loss: 0.1217060 Test Loss: 0.1889595
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.3023090362548828
Epoch: 7, Steps: 28 | Train Loss: 0.4742351 Vali Loss: 0.1224293 Test Loss: 0.1889995
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.29402828216552734
Epoch: 8, Steps: 28 | Train Loss: 0.4680385 Vali Loss: 0.1207061 Test Loss: 0.1890499
Validation loss decreased (0.121178 --> 0.120706).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.29152512550354004
Epoch: 9, Steps: 28 | Train Loss: 0.4809927 Vali Loss: 0.1188459 Test Loss: 0.1889839
Validation loss decreased (0.120706 --> 0.118846).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.2909815311431885
Epoch: 10, Steps: 28 | Train Loss: 0.4755448 Vali Loss: 0.1234954 Test Loss: 0.1889714
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.29682326316833496
Epoch: 11, Steps: 28 | Train Loss: 0.4793242 Vali Loss: 0.1256137 Test Loss: 0.1889844
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.28972411155700684
Epoch: 12, Steps: 28 | Train Loss: 0.4778481 Vali Loss: 0.1243104 Test Loss: 0.1889935
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2978980541229248
Epoch: 13, Steps: 28 | Train Loss: 0.4738036 Vali Loss: 0.1197890 Test Loss: 0.1890283
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.29039478302001953
Epoch: 14, Steps: 28 | Train Loss: 0.4715150 Vali Loss: 0.1269849 Test Loss: 0.1890286
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.2957477569580078
Epoch: 15, Steps: 28 | Train Loss: 0.4696962 Vali Loss: 0.1253464 Test Loss: 0.1890291
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.301633358001709
Epoch: 16, Steps: 28 | Train Loss: 0.4754288 Vali Loss: 0.1215276 Test Loss: 0.1890293
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.28310728073120117
Epoch: 17, Steps: 28 | Train Loss: 0.4793010 Vali Loss: 0.1197206 Test Loss: 0.1890292
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.28286004066467285
Epoch: 18, Steps: 28 | Train Loss: 0.4839133 Vali Loss: 0.1211834 Test Loss: 0.1890292
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.30019330978393555
Epoch: 19, Steps: 28 | Train Loss: 0.4778412 Vali Loss: 0.1223098 Test Loss: 0.1890291
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.2833418846130371
Epoch: 20, Steps: 28 | Train Loss: 0.4825427 Vali Loss: 0.1211024 Test Loss: 0.1890291
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.283724308013916
Epoch: 21, Steps: 28 | Train Loss: 0.4737918 Vali Loss: 0.1239598 Test Loss: 0.1890291
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.2897524833679199
Epoch: 22, Steps: 28 | Train Loss: 0.4754361 Vali Loss: 0.1248685 Test Loss: 0.1890291
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.2841224670410156
Epoch: 23, Steps: 28 | Train Loss: 0.4806824 Vali Loss: 0.1264542 Test Loss: 0.1890292
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.2826194763183594
Epoch: 24, Steps: 28 | Train Loss: 0.4847084 Vali Loss: 0.1240352 Test Loss: 0.1890292
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Autoformer_pl5_Autoformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1892, mae:0.3300, msIC:0.0218, msIR:0.0452
Total Evaluation 

MSE:0.1920Â±0.0026
MAE:0.3339Â±0.0028
msIC:0.0065Â±0.0378
msIR:0.0119Â±0.0781
  Evaluating Autoformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: FEDformer
  Training FEDformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_FEDformer_pl5Model:              FEDformer           

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[3, 4, 8, 9, 10, 11, 13, 15, 17, 18, 19, 20, 23, 25, 28, 31, 32, 34, 36, 39, 40, 41, 42, 43, 47, 48, 50, 51, 55, 58, 60, 61]
fourier enhanced block used!
modes=32, index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
modes_kv=32, index_kv=[0, 1, 8, 11, 13, 15, 16, 17, 18, 19, 21, 22, 24, 26, 28, 29, 33, 37, 39, 41, 44, 47, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62]
>>>>>>>start training : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.9126112461090088
Epoch: 1, Steps: 28 | Train Loss: 1.0616794 Vali Loss: 0.1887592 Test Loss: 0.2576706
Validation loss decreased (inf --> 0.188759).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6832842826843262
Epoch: 2, Steps: 28 | Train Loss: 0.6658838 Vali Loss: 0.1215544 Test Loss: 0.1988295
Validation loss decreased (0.188759 --> 0.121554).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.6781384944915771
Epoch: 3, Steps: 28 | Train Loss: 0.5882650 Vali Loss: 0.1263036 Test Loss: 0.2014175
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.6560487747192383
Epoch: 4, Steps: 28 | Train Loss: 0.5707598 Vali Loss: 0.1218516 Test Loss: 0.1981799
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.678333044052124
Epoch: 5, Steps: 28 | Train Loss: 0.5651763 Vali Loss: 0.1200277 Test Loss: 0.1957532
Validation loss decreased (0.121554 --> 0.120028).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.6644749641418457
Epoch: 6, Steps: 28 | Train Loss: 0.5671534 Vali Loss: 0.1208913 Test Loss: 0.1953819
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.660339593887329
Epoch: 7, Steps: 28 | Train Loss: 0.5626418 Vali Loss: 0.1197722 Test Loss: 0.1950832
Validation loss decreased (0.120028 --> 0.119772).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.6790034770965576
Epoch: 8, Steps: 28 | Train Loss: 0.5496959 Vali Loss: 0.1194426 Test Loss: 0.1949038
Validation loss decreased (0.119772 --> 0.119443).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.6776123046875
Epoch: 9, Steps: 28 | Train Loss: 0.5553129 Vali Loss: 0.1226116 Test Loss: 0.1949886
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.658050298690796
Epoch: 10, Steps: 28 | Train Loss: 0.5571815 Vali Loss: 0.1187790 Test Loss: 0.1949689
Validation loss decreased (0.119443 --> 0.118779).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.7029883861541748
Epoch: 11, Steps: 28 | Train Loss: 0.5428762 Vali Loss: 0.1235131 Test Loss: 0.1949633
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.6595313549041748
Epoch: 12, Steps: 28 | Train Loss: 0.5417605 Vali Loss: 0.1193017 Test Loss: 0.1949439
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.6819255352020264
Epoch: 13, Steps: 28 | Train Loss: 0.5480263 Vali Loss: 0.1206879 Test Loss: 0.1949499
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.6802284717559814
Epoch: 14, Steps: 28 | Train Loss: 0.5550348 Vali Loss: 0.1220223 Test Loss: 0.1949518
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.65970778465271
Epoch: 15, Steps: 28 | Train Loss: 0.5514372 Vali Loss: 0.1207938 Test Loss: 0.1949500
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.6937403678894043
Epoch: 16, Steps: 28 | Train Loss: 0.5422763 Vali Loss: 0.1202530 Test Loss: 0.1949511
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.6608555316925049
Epoch: 17, Steps: 28 | Train Loss: 0.5592797 Vali Loss: 0.1227782 Test Loss: 0.1949512
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 1.6590518951416016
Epoch: 18, Steps: 28 | Train Loss: 0.5612479 Vali Loss: 0.1206138 Test Loss: 0.1949514
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 1.6795830726623535
Epoch: 19, Steps: 28 | Train Loss: 0.5483847 Vali Loss: 0.1182543 Test Loss: 0.1949514
Validation loss decreased (0.118779 --> 0.118254).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 1.6819181442260742
Epoch: 20, Steps: 28 | Train Loss: 0.5404897 Vali Loss: 0.1200215 Test Loss: 0.1949514
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 1.6661314964294434
Epoch: 21, Steps: 28 | Train Loss: 0.5519444 Vali Loss: 0.1235729 Test Loss: 0.1949513
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 1.665400743484497
Epoch: 22, Steps: 28 | Train Loss: 0.5542457 Vali Loss: 0.1232053 Test Loss: 0.1949514
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 1.6577861309051514
Epoch: 23, Steps: 28 | Train Loss: 0.5456115 Vali Loss: 0.1232334 Test Loss: 0.1949514
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 1.67476487159729
Epoch: 24, Steps: 28 | Train Loss: 0.5510829 Vali Loss: 0.1191060 Test Loss: 0.1949514
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 1.6774790287017822
Epoch: 25, Steps: 28 | Train Loss: 0.5507253 Vali Loss: 0.1219470 Test Loss: 0.1949514
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 1.6699254512786865
Epoch: 26, Steps: 28 | Train Loss: 0.5508849 Vali Loss: 0.1182662 Test Loss: 0.1949514
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 1.6846916675567627
Epoch: 27, Steps: 28 | Train Loss: 0.5502112 Vali Loss: 0.1186683 Test Loss: 0.1949514
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 1.6564831733703613
Epoch: 28, Steps: 28 | Train Loss: 0.5470425 Vali Loss: 0.1213470 Test Loss: 0.1949514
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 1.6648027896881104
Epoch: 29, Steps: 28 | Train Loss: 0.5462772 Vali Loss: 0.1173934 Test Loss: 0.1949514
Validation loss decreased (0.118254 --> 0.117393).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 1.6707971096038818
Epoch: 30, Steps: 28 | Train Loss: 0.5619713 Vali Loss: 0.1240719 Test Loss: 0.1949514
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 1.668989658355713
Epoch: 31, Steps: 28 | Train Loss: 0.5388783 Vali Loss: 0.1215709 Test Loss: 0.1949514
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 1.6762328147888184
Epoch: 32, Steps: 28 | Train Loss: 0.5444653 Vali Loss: 0.1213444 Test Loss: 0.1949514
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 1.6533358097076416
Epoch: 33, Steps: 28 | Train Loss: 0.5538707 Vali Loss: 0.1243158 Test Loss: 0.1949514
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 1.6585900783538818
Epoch: 34, Steps: 28 | Train Loss: 0.5478549 Vali Loss: 0.1207163 Test Loss: 0.1949514
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 1.6709914207458496
Epoch: 35, Steps: 28 | Train Loss: 0.5483555 Vali Loss: 0.1189845 Test Loss: 0.1949514
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 1.6689832210540771
Epoch: 36, Steps: 28 | Train Loss: 0.5466445 Vali Loss: 0.1183254 Test Loss: 0.1949514
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 1.6580395698547363
Epoch: 37, Steps: 28 | Train Loss: 0.5553567 Vali Loss: 0.1237139 Test Loss: 0.1949514
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 1.6659629344940186
Epoch: 38, Steps: 28 | Train Loss: 0.5545864 Vali Loss: 0.1251089 Test Loss: 0.1949514
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 1.652761697769165
Epoch: 39, Steps: 28 | Train Loss: 0.5523485 Vali Loss: 0.1158087 Test Loss: 0.1949514
Validation loss decreased (0.117393 --> 0.115809).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 1.66044282913208
Epoch: 40, Steps: 28 | Train Loss: 0.5437108 Vali Loss: 0.1222209 Test Loss: 0.1949514
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 1.667970895767212
Epoch: 41, Steps: 28 | Train Loss: 0.5589381 Vali Loss: 0.1218162 Test Loss: 0.1949514
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 1.6725797653198242
Epoch: 42, Steps: 28 | Train Loss: 0.5430764 Vali Loss: 0.1225679 Test Loss: 0.1949514
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 1.6726171970367432
Epoch: 43, Steps: 28 | Train Loss: 0.5592834 Vali Loss: 0.1203180 Test Loss: 0.1949514
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 1.6554315090179443
Epoch: 44, Steps: 28 | Train Loss: 0.5441328 Vali Loss: 0.1219610 Test Loss: 0.1949514
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 1.662818431854248
Epoch: 45, Steps: 28 | Train Loss: 0.5414413 Vali Loss: 0.1190225 Test Loss: 0.1949514
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 1.6665315628051758
Epoch: 46, Steps: 28 | Train Loss: 0.5521921 Vali Loss: 0.1181501 Test Loss: 0.1949514
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 47 cost time: 1.672834873199463
Epoch: 47, Steps: 28 | Train Loss: 0.5593050 Vali Loss: 0.1226621 Test Loss: 0.1949514
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 48 cost time: 1.6679089069366455
Epoch: 48, Steps: 28 | Train Loss: 0.5385356 Vali Loss: 0.1210317 Test Loss: 0.1949514
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 49 cost time: 1.6687705516815186
Epoch: 49, Steps: 28 | Train Loss: 0.5591803 Vali Loss: 0.1196891 Test Loss: 0.1949514
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 50 cost time: 1.6586856842041016
Epoch: 50, Steps: 28 | Train Loss: 0.5480954 Vali Loss: 0.1162298 Test Loss: 0.1949514
EarlyStopping counter: 11 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 51 cost time: 1.6599693298339844
Epoch: 51, Steps: 28 | Train Loss: 0.5513670 Vali Loss: 0.1271422 Test Loss: 0.1949514
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 52 cost time: 1.6800568103790283
Epoch: 52, Steps: 28 | Train Loss: 0.5511323 Vali Loss: 0.1197780 Test Loss: 0.1949514
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.220446049250313e-19
Epoch: 53 cost time: 1.6789939403533936
Epoch: 53, Steps: 28 | Train Loss: 0.5618303 Vali Loss: 0.1185500 Test Loss: 0.1949514
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1102230246251566e-19
Epoch: 54 cost time: 1.654754400253296
Epoch: 54, Steps: 28 | Train Loss: 0.5547223 Vali Loss: 0.1229296 Test Loss: 0.1949514
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1952, mae:0.3331, msIC:0.0105, msIR:0.0206
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 19, 20, 22, 25, 28, 29, 30, 31, 36, 37, 38, 39, 46, 47, 51, 53, 54, 56, 57, 61]
fourier enhanced block used!
modes=32, index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
modes_kv=32, index_kv=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 18, 19, 22, 24, 37, 39, 40, 43, 44, 45, 52, 53, 55, 57, 58, 59, 60, 61, 62]
>>>>>>>start training : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.691399097442627
Epoch: 1, Steps: 28 | Train Loss: 0.6395321 Vali Loss: 0.1440659 Test Loss: 0.2178982
Validation loss decreased (inf --> 0.144066).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6716282367706299
Epoch: 2, Steps: 28 | Train Loss: 0.5423900 Vali Loss: 0.1295377 Test Loss: 0.2019266
Validation loss decreased (0.144066 --> 0.129538).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.7083854675292969
Epoch: 3, Steps: 28 | Train Loss: 0.5119420 Vali Loss: 0.1277616 Test Loss: 0.1986510
Validation loss decreased (0.129538 --> 0.127762).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.7204489707946777
Epoch: 4, Steps: 28 | Train Loss: 0.4985883 Vali Loss: 0.1295410 Test Loss: 0.1975683
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.6642608642578125
Epoch: 5, Steps: 28 | Train Loss: 0.4876416 Vali Loss: 0.1303225 Test Loss: 0.1994039
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.6814637184143066
Epoch: 6, Steps: 28 | Train Loss: 0.4974705 Vali Loss: 0.1333053 Test Loss: 0.1986667
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.674593448638916
Epoch: 7, Steps: 28 | Train Loss: 0.4919011 Vali Loss: 0.1318627 Test Loss: 0.1982511
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.6836609840393066
Epoch: 8, Steps: 28 | Train Loss: 0.4913356 Vali Loss: 0.1231517 Test Loss: 0.1983424
Validation loss decreased (0.127762 --> 0.123152).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.7142376899719238
Epoch: 9, Steps: 28 | Train Loss: 0.4825947 Vali Loss: 0.1276221 Test Loss: 0.1983748
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.6653964519500732
Epoch: 10, Steps: 28 | Train Loss: 0.4953999 Vali Loss: 0.1268445 Test Loss: 0.1983028
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.6984598636627197
Epoch: 11, Steps: 28 | Train Loss: 0.4937177 Vali Loss: 0.1308962 Test Loss: 0.1983107
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.668790340423584
Epoch: 12, Steps: 28 | Train Loss: 0.4983423 Vali Loss: 0.1302075 Test Loss: 0.1983116
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.6614770889282227
Epoch: 13, Steps: 28 | Train Loss: 0.4864918 Vali Loss: 0.1298592 Test Loss: 0.1983017
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.6892919540405273
Epoch: 14, Steps: 28 | Train Loss: 0.5002505 Vali Loss: 0.1251056 Test Loss: 0.1982979
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.6894500255584717
Epoch: 15, Steps: 28 | Train Loss: 0.4923628 Vali Loss: 0.1317747 Test Loss: 0.1982965
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.6684634685516357
Epoch: 16, Steps: 28 | Train Loss: 0.4968311 Vali Loss: 0.1296708 Test Loss: 0.1982961
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.6822383403778076
Epoch: 17, Steps: 28 | Train Loss: 0.4847998 Vali Loss: 0.1287270 Test Loss: 0.1982958
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 1.657052993774414
Epoch: 18, Steps: 28 | Train Loss: 0.4956954 Vali Loss: 0.1299285 Test Loss: 0.1982957
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 1.6703054904937744
Epoch: 19, Steps: 28 | Train Loss: 0.4898963 Vali Loss: 0.1336221 Test Loss: 0.1982958
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 1.6858303546905518
Epoch: 20, Steps: 28 | Train Loss: 0.4949633 Vali Loss: 0.1301109 Test Loss: 0.1982958
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 1.6650655269622803
Epoch: 21, Steps: 28 | Train Loss: 0.4934740 Vali Loss: 0.1315261 Test Loss: 0.1982958
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 1.6923902034759521
Epoch: 22, Steps: 28 | Train Loss: 0.4904835 Vali Loss: 0.1265778 Test Loss: 0.1982958
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 1.6660678386688232
Epoch: 23, Steps: 28 | Train Loss: 0.5014264 Vali Loss: 0.1267390 Test Loss: 0.1982958
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1986, mae:0.3406, msIC:0.0148, msIR:0.0301
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[0, 1, 2, 4, 7, 9, 12, 13, 14, 15, 17, 18, 21, 24, 26, 27, 31, 33, 34, 35, 37, 38, 40, 44, 45, 46, 50, 52, 54, 55, 56, 60]
fourier enhanced block used!
modes=32, index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33]
modes_kv=32, index_kv=[2, 3, 5, 6, 9, 10, 15, 16, 18, 20, 22, 26, 27, 28, 31, 32, 33, 37, 38, 39, 43, 44, 46, 47, 48, 51, 52, 55, 57, 59, 61, 63]
>>>>>>>start training : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.6724302768707275
Epoch: 1, Steps: 28 | Train Loss: 0.7286549 Vali Loss: 0.1693967 Test Loss: 0.2447274
Validation loss decreased (inf --> 0.169397).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 1.6847655773162842
Epoch: 2, Steps: 28 | Train Loss: 0.5800272 Vali Loss: 0.1360654 Test Loss: 0.2084665
Validation loss decreased (0.169397 --> 0.136065).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 1.6719114780426025
Epoch: 3, Steps: 28 | Train Loss: 0.5353458 Vali Loss: 0.1183290 Test Loss: 0.1954371
Validation loss decreased (0.136065 --> 0.118329).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 1.6683378219604492
Epoch: 4, Steps: 28 | Train Loss: 0.5228686 Vali Loss: 0.1223994 Test Loss: 0.1942219
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 1.6614630222320557
Epoch: 5, Steps: 28 | Train Loss: 0.5138722 Vali Loss: 0.1155985 Test Loss: 0.1943240
Validation loss decreased (0.118329 --> 0.115598).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 1.6582281589508057
Epoch: 6, Steps: 28 | Train Loss: 0.5080234 Vali Loss: 0.1112029 Test Loss: 0.1915464
Validation loss decreased (0.115598 --> 0.111203).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 1.6848888397216797
Epoch: 7, Steps: 28 | Train Loss: 0.5099812 Vali Loss: 0.1152970 Test Loss: 0.1906563
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 1.6653552055358887
Epoch: 8, Steps: 28 | Train Loss: 0.5173041 Vali Loss: 0.1155877 Test Loss: 0.1902755
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 1.6529886722564697
Epoch: 9, Steps: 28 | Train Loss: 0.5067464 Vali Loss: 0.1168202 Test Loss: 0.1901610
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 1.6665573120117188
Epoch: 10, Steps: 28 | Train Loss: 0.5179914 Vali Loss: 0.1135655 Test Loss: 0.1901695
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 1.6575517654418945
Epoch: 11, Steps: 28 | Train Loss: 0.5122306 Vali Loss: 0.1189446 Test Loss: 0.1902149
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 1.659193754196167
Epoch: 12, Steps: 28 | Train Loss: 0.5172068 Vali Loss: 0.1154302 Test Loss: 0.1902037
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 1.6615679264068604
Epoch: 13, Steps: 28 | Train Loss: 0.5080998 Vali Loss: 0.1163429 Test Loss: 0.1901952
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 1.667184829711914
Epoch: 14, Steps: 28 | Train Loss: 0.4921248 Vali Loss: 0.1165149 Test Loss: 0.1901954
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 1.674516201019287
Epoch: 15, Steps: 28 | Train Loss: 0.5066824 Vali Loss: 0.1189038 Test Loss: 0.1901940
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 1.659008264541626
Epoch: 16, Steps: 28 | Train Loss: 0.5102690 Vali Loss: 0.1197331 Test Loss: 0.1901924
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 1.660517930984497
Epoch: 17, Steps: 28 | Train Loss: 0.5059180 Vali Loss: 0.1155318 Test Loss: 0.1901921
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 1.675440788269043
Epoch: 18, Steps: 28 | Train Loss: 0.5099492 Vali Loss: 0.1146736 Test Loss: 0.1901920
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 1.687821626663208
Epoch: 19, Steps: 28 | Train Loss: 0.5014277 Vali Loss: 0.1211369 Test Loss: 0.1901922
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 1.6572558879852295
Epoch: 20, Steps: 28 | Train Loss: 0.5146499 Vali Loss: 0.1177957 Test Loss: 0.1901921
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 1.6801238059997559
Epoch: 21, Steps: 28 | Train Loss: 0.5087257 Vali Loss: 0.1164501 Test Loss: 0.1901922
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_FEDformer_pl5_FEDformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1917, mae:0.3302, msIC:0.0081, msIR:0.0165
Total Evaluation 

MSE:0.1952Â±0.0028
MAE:0.3346Â±0.0044
msIC:0.0111Â±0.0028
msIR:0.0224Â±0.0057
  Evaluating FEDformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: TiDE
  Training TiDE...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_TiDE_pl5 Model:              TiDE                

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            256                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               256                 
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         512                 
  Patience:           15                  Learning Rate:      0.01                
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.12659192085266113
Epoch: 1, Steps: 2 | Train Loss: 0.6744112 Vali Loss: 0.1350814 Test Loss: 0.2151415
Validation loss decreased (inf --> 0.135081).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.041172027587890625
Epoch: 2, Steps: 2 | Train Loss: 0.5315080 Vali Loss: 0.1248732 Test Loss: 0.2007091
Validation loss decreased (0.135081 --> 0.124873).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.04738283157348633
Epoch: 3, Steps: 2 | Train Loss: 0.4648575 Vali Loss: 0.1213957 Test Loss: 0.1958739
Validation loss decreased (0.124873 --> 0.121396).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.058498382568359375
Epoch: 4, Steps: 2 | Train Loss: 0.4432945 Vali Loss: 0.1199927 Test Loss: 0.1940709
Validation loss decreased (0.121396 --> 0.119993).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.05156135559082031
Epoch: 5, Steps: 2 | Train Loss: 0.4310528 Vali Loss: 0.1193020 Test Loss: 0.1932752
Validation loss decreased (0.119993 --> 0.119302).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.048268795013427734
Epoch: 6, Steps: 2 | Train Loss: 0.4294960 Vali Loss: 0.1189699 Test Loss: 0.1929100
Validation loss decreased (0.119302 --> 0.118970).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.05309438705444336
Epoch: 7, Steps: 2 | Train Loss: 0.4254340 Vali Loss: 0.1188066 Test Loss: 0.1927401
Validation loss decreased (0.118970 --> 0.118807).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.06559157371520996
Epoch: 8, Steps: 2 | Train Loss: 0.4240247 Vali Loss: 0.1187218 Test Loss: 0.1926554
Validation loss decreased (0.118807 --> 0.118722).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.05361771583557129
Epoch: 9, Steps: 2 | Train Loss: 0.4234838 Vali Loss: 0.1186798 Test Loss: 0.1926147
Validation loss decreased (0.118722 --> 0.118680).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.04825568199157715
Epoch: 10, Steps: 2 | Train Loss: 0.4239180 Vali Loss: 0.1186584 Test Loss: 0.1925942
Validation loss decreased (0.118680 --> 0.118658).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.04440569877624512
Epoch: 11, Steps: 2 | Train Loss: 0.4213405 Vali Loss: 0.1186476 Test Loss: 0.1925840
Validation loss decreased (0.118658 --> 0.118648).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.06252598762512207
Epoch: 12, Steps: 2 | Train Loss: 0.4264914 Vali Loss: 0.1186420 Test Loss: 0.1925789
Validation loss decreased (0.118648 --> 0.118642).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.06587886810302734
Epoch: 13, Steps: 2 | Train Loss: 0.4244712 Vali Loss: 0.1186392 Test Loss: 0.1925763
Validation loss decreased (0.118642 --> 0.118639).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.0693826675415039
Epoch: 14, Steps: 2 | Train Loss: 0.4238872 Vali Loss: 0.1186378 Test Loss: 0.1925750
Validation loss decreased (0.118639 --> 0.118638).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.05039072036743164
Epoch: 15, Steps: 2 | Train Loss: 0.4277049 Vali Loss: 0.1186371 Test Loss: 0.1925744
Validation loss decreased (0.118638 --> 0.118637).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.04823732376098633
Epoch: 16, Steps: 2 | Train Loss: 0.4252306 Vali Loss: 0.1186367 Test Loss: 0.1925741
Validation loss decreased (0.118637 --> 0.118637).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.04464864730834961
Epoch: 17, Steps: 2 | Train Loss: 0.4236299 Vali Loss: 0.1186365 Test Loss: 0.1925739
Validation loss decreased (0.118637 --> 0.118637).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.059795379638671875
Epoch: 18, Steps: 2 | Train Loss: 0.4225540 Vali Loss: 0.1186364 Test Loss: 0.1925738
Validation loss decreased (0.118637 --> 0.118636).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.0701456069946289
Epoch: 19, Steps: 2 | Train Loss: 0.4263899 Vali Loss: 0.1186364 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.07358837127685547
Epoch: 20, Steps: 2 | Train Loss: 0.4269473 Vali Loss: 0.1186364 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.050362586975097656
Epoch: 21, Steps: 2 | Train Loss: 0.4216990 Vali Loss: 0.1186364 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.05213332176208496
Epoch: 22, Steps: 2 | Train Loss: 0.4241206 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.05037045478820801
Epoch: 23, Steps: 2 | Train Loss: 0.4256645 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.02971935272216797
Epoch: 24, Steps: 2 | Train Loss: 0.4246826 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.055234670639038086
Epoch: 25, Steps: 2 | Train Loss: 0.4255362 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.960464477539063e-10
Epoch: 26 cost time: 0.02884054183959961
Epoch: 26, Steps: 2 | Train Loss: 0.4278753 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.9802322387695313e-10
Epoch: 27 cost time: 0.027611970901489258
Epoch: 27, Steps: 2 | Train Loss: 0.4273747 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 28 cost time: 0.05852317810058594
Epoch: 28, Steps: 2 | Train Loss: 0.4290228 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.450580596923828e-11
Epoch: 29 cost time: 0.028842449188232422
Epoch: 29, Steps: 2 | Train Loss: 0.4228524 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.725290298461914e-11
Epoch: 30 cost time: 0.031055927276611328
Epoch: 30, Steps: 2 | Train Loss: 0.4228815 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.862645149230957e-11
Epoch: 31 cost time: 0.030509471893310547
Epoch: 31, Steps: 2 | Train Loss: 0.4286341 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.313225746154785e-12
Epoch: 32 cost time: 0.027860164642333984
Epoch: 32, Steps: 2 | Train Loss: 0.4263392 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.656612873077393e-12
Epoch: 33 cost time: 0.03192400932312012
Epoch: 33, Steps: 2 | Train Loss: 0.4246278 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.3283064365386963e-12
Epoch: 34 cost time: 0.027532577514648438
Epoch: 34, Steps: 2 | Train Loss: 0.4265657 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.1641532182693482e-12
Epoch: 35 cost time: 0.04048037528991699
Epoch: 35, Steps: 2 | Train Loss: 0.4184913 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 8 out of 15
Updating learning rate to 5.820766091346741e-13
Epoch: 36 cost time: 0.02779412269592285
Epoch: 36, Steps: 2 | Train Loss: 0.4258220 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.9103830456733704e-13
Epoch: 37 cost time: 0.031047582626342773
Epoch: 37, Steps: 2 | Train Loss: 0.4245363 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.4551915228366852e-13
Epoch: 38 cost time: 0.02877640724182129
Epoch: 38, Steps: 2 | Train Loss: 0.4295292 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.275957614183426e-14
Epoch: 39 cost time: 0.02829432487487793
Epoch: 39, Steps: 2 | Train Loss: 0.4356208 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 3.637978807091713e-14
Epoch: 40 cost time: 0.0465855598449707
Epoch: 40, Steps: 2 | Train Loss: 0.4227986 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.8189894035458565e-14
Epoch: 41 cost time: 0.047951698303222656
Epoch: 41, Steps: 2 | Train Loss: 0.4236825 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.094947017729283e-15
Epoch: 42 cost time: 0.02711033821105957
Epoch: 42, Steps: 2 | Train Loss: 0.4238442 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.547473508864641e-15
Epoch: 43 cost time: 0.026981830596923828
Epoch: 43, Steps: 2 | Train Loss: 0.4311462 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 2.2737367544323206e-15
Epoch: 44 cost time: 0.04393315315246582
Epoch: 44, Steps: 2 | Train Loss: 0.4267645 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1368683772161603e-15
Epoch: 45 cost time: 0.026964187622070312
Epoch: 45, Steps: 2 | Train Loss: 0.4268241 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 5.684341886080802e-16
Epoch: 46 cost time: 0.05073690414428711
Epoch: 46, Steps: 2 | Train Loss: 0.4291785 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 2.842170943040401e-16
Epoch: 47 cost time: 0.04860424995422363
Epoch: 47, Steps: 2 | Train Loss: 0.4243383 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.4210854715202004e-16
Epoch: 48 cost time: 0.058464765548706055
Epoch: 48, Steps: 2 | Train Loss: 0.4255509 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.105427357601002e-17
Epoch: 49 cost time: 0.027868270874023438
Epoch: 49, Steps: 2 | Train Loss: 0.4275846 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 3.552713678800501e-17
Epoch: 50 cost time: 0.056781768798828125
Epoch: 50, Steps: 2 | Train Loss: 0.4300807 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.7763568394002505e-17
Epoch: 51 cost time: 0.03307771682739258
Epoch: 51, Steps: 2 | Train Loss: 0.4276691 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 8.881784197001253e-18
Epoch: 52 cost time: 0.02964162826538086
Epoch: 52, Steps: 2 | Train Loss: 0.4308432 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.440892098500626e-18
Epoch: 53 cost time: 0.027666568756103516
Epoch: 53, Steps: 2 | Train Loss: 0.4212322 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.220446049250313e-18
Epoch: 54 cost time: 0.02866387367248535
Epoch: 54, Steps: 2 | Train Loss: 0.4239783 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1102230246251566e-18
Epoch: 55 cost time: 0.028882503509521484
Epoch: 55, Steps: 2 | Train Loss: 0.4279724 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.551115123125783e-19
Epoch: 56 cost time: 0.03295302391052246
Epoch: 56, Steps: 2 | Train Loss: 0.4224355 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 2.7755575615628914e-19
Epoch: 57 cost time: 0.06282234191894531
Epoch: 57, Steps: 2 | Train Loss: 0.4280207 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.3877787807814457e-19
Epoch: 58 cost time: 0.03787064552307129
Epoch: 58, Steps: 2 | Train Loss: 0.4296652 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.938893903907229e-20
Epoch: 59 cost time: 0.028547048568725586
Epoch: 59, Steps: 2 | Train Loss: 0.4241841 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.469446951953614e-20
Epoch: 60 cost time: 0.029883146286010742
Epoch: 60, Steps: 2 | Train Loss: 0.4272404 Vali Loss: 0.1186363 Test Loss: 0.1925738
Validation loss decreased (0.118636 --> 0.118636).  Saving model ...
Updating learning rate to 1.734723475976807e-20
Epoch: 61 cost time: 0.04716610908508301
Epoch: 61, Steps: 2 | Train Loss: 0.4259493 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 1 out of 15
Updating learning rate to 8.673617379884036e-21
Epoch: 62 cost time: 0.029843568801879883
Epoch: 62, Steps: 2 | Train Loss: 0.4218713 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.336808689942018e-21
Epoch: 63 cost time: 0.02851414680480957
Epoch: 63, Steps: 2 | Train Loss: 0.4326224 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.168404344971009e-21
Epoch: 64 cost time: 0.02822589874267578
Epoch: 64, Steps: 2 | Train Loss: 0.4206109 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.0842021724855045e-21
Epoch: 65 cost time: 0.028348922729492188
Epoch: 65, Steps: 2 | Train Loss: 0.4221024 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.421010862427522e-22
Epoch: 66 cost time: 0.028612852096557617
Epoch: 66, Steps: 2 | Train Loss: 0.4270668 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.710505431213761e-22
Epoch: 67 cost time: 0.03418445587158203
Epoch: 67, Steps: 2 | Train Loss: 0.4226414 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.3552527156068806e-22
Epoch: 68 cost time: 0.03131580352783203
Epoch: 68, Steps: 2 | Train Loss: 0.4284267 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.776263578034403e-23
Epoch: 69 cost time: 0.03534245491027832
Epoch: 69, Steps: 2 | Train Loss: 0.4260283 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.3881317890172014e-23
Epoch: 70 cost time: 0.028980731964111328
Epoch: 70, Steps: 2 | Train Loss: 0.4278279 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.6940658945086007e-23
Epoch: 71 cost time: 0.028083324432373047
Epoch: 71, Steps: 2 | Train Loss: 0.4229896 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 11 out of 15
Updating learning rate to 8.470329472543004e-24
Epoch: 72 cost time: 0.02716374397277832
Epoch: 72, Steps: 2 | Train Loss: 0.4224284 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.235164736271502e-24
Epoch: 73 cost time: 0.026922941207885742
Epoch: 73, Steps: 2 | Train Loss: 0.4240961 Vali Loss: 0.1186364 Test Loss: 0.1925738
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.117582368135751e-24
Epoch: 74 cost time: 0.027095794677734375
Epoch: 74, Steps: 2 | Train Loss: 0.4230122 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.0587911840678754e-24
Epoch: 75 cost time: 0.026931047439575195
Epoch: 75, Steps: 2 | Train Loss: 0.4263256 Vali Loss: 0.1186363 Test Loss: 0.1925738
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1926, mae:0.3355, msIC:-0.0085, msIR:-0.0172
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.03185248374938965
Epoch: 1, Steps: 2 | Train Loss: 0.7273803 Vali Loss: 0.1394479 Test Loss: 0.2207010
Validation loss decreased (inf --> 0.139448).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.05276155471801758
Epoch: 2, Steps: 2 | Train Loss: 0.5625613 Vali Loss: 0.1251386 Test Loss: 0.2061300
Validation loss decreased (0.139448 --> 0.125139).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.056061506271362305
Epoch: 3, Steps: 2 | Train Loss: 0.4806515 Vali Loss: 0.1201374 Test Loss: 0.2012062
Validation loss decreased (0.125139 --> 0.120137).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.06060051918029785
Epoch: 4, Steps: 2 | Train Loss: 0.4578123 Vali Loss: 0.1181636 Test Loss: 0.1991213
Validation loss decreased (0.120137 --> 0.118164).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.07716250419616699
Epoch: 5, Steps: 2 | Train Loss: 0.4402162 Vali Loss: 0.1172936 Test Loss: 0.1981780
Validation loss decreased (0.118164 --> 0.117294).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.0689692497253418
Epoch: 6, Steps: 2 | Train Loss: 0.4410588 Vali Loss: 0.1168831 Test Loss: 0.1977144
Validation loss decreased (0.117294 --> 0.116883).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.04906487464904785
Epoch: 7, Steps: 2 | Train Loss: 0.4346707 Vali Loss: 0.1166877 Test Loss: 0.1974842
Validation loss decreased (0.116883 --> 0.116688).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.05233502388000488
Epoch: 8, Steps: 2 | Train Loss: 0.4381131 Vali Loss: 0.1165912 Test Loss: 0.1973631
Validation loss decreased (0.116688 --> 0.116591).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.04979205131530762
Epoch: 9, Steps: 2 | Train Loss: 0.4344952 Vali Loss: 0.1165438 Test Loss: 0.1973035
Validation loss decreased (0.116591 --> 0.116544).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.04629707336425781
Epoch: 10, Steps: 2 | Train Loss: 0.4356184 Vali Loss: 0.1165202 Test Loss: 0.1972738
Validation loss decreased (0.116544 --> 0.116520).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.05502057075500488
Epoch: 11, Steps: 2 | Train Loss: 0.4336814 Vali Loss: 0.1165086 Test Loss: 0.1972586
Validation loss decreased (0.116520 --> 0.116509).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.052911996841430664
Epoch: 12, Steps: 2 | Train Loss: 0.4404234 Vali Loss: 0.1165029 Test Loss: 0.1972509
Validation loss decreased (0.116509 --> 0.116503).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.05970454216003418
Epoch: 13, Steps: 2 | Train Loss: 0.4378876 Vali Loss: 0.1165000 Test Loss: 0.1972472
Validation loss decreased (0.116503 --> 0.116500).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.050478219985961914
Epoch: 14, Steps: 2 | Train Loss: 0.4358068 Vali Loss: 0.1164986 Test Loss: 0.1972453
Validation loss decreased (0.116500 --> 0.116499).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.04168701171875
Epoch: 15, Steps: 2 | Train Loss: 0.4366222 Vali Loss: 0.1164979 Test Loss: 0.1972443
Validation loss decreased (0.116499 --> 0.116498).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.04266762733459473
Epoch: 16, Steps: 2 | Train Loss: 0.4339379 Vali Loss: 0.1164975 Test Loss: 0.1972438
Validation loss decreased (0.116498 --> 0.116498).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.054635047912597656
Epoch: 17, Steps: 2 | Train Loss: 0.4331612 Vali Loss: 0.1164974 Test Loss: 0.1972436
Validation loss decreased (0.116498 --> 0.116497).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.053374290466308594
Epoch: 18, Steps: 2 | Train Loss: 0.4379467 Vali Loss: 0.1164973 Test Loss: 0.1972434
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.04553961753845215
Epoch: 19, Steps: 2 | Train Loss: 0.4389240 Vali Loss: 0.1164972 Test Loss: 0.1972434
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.045241355895996094
Epoch: 20, Steps: 2 | Train Loss: 0.4339371 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.07291126251220703
Epoch: 21, Steps: 2 | Train Loss: 0.4390678 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.06217360496520996
Epoch: 22, Steps: 2 | Train Loss: 0.4338876 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.05284690856933594
Epoch: 23, Steps: 2 | Train Loss: 0.4332528 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.05524563789367676
Epoch: 24, Steps: 2 | Train Loss: 0.4359044 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.05138278007507324
Epoch: 25, Steps: 2 | Train Loss: 0.4351503 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.960464477539063e-10
Epoch: 26 cost time: 0.0368647575378418
Epoch: 26, Steps: 2 | Train Loss: 0.4299435 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
Epoch: 27 cost time: 0.05360722541809082
Epoch: 27, Steps: 2 | Train Loss: 0.4351130 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 28 cost time: 0.07021665573120117
Epoch: 28, Steps: 2 | Train Loss: 0.4329793 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 7.450580596923828e-11
Epoch: 29 cost time: 0.05931401252746582
Epoch: 29, Steps: 2 | Train Loss: 0.4411842 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.725290298461914e-11
Epoch: 30 cost time: 0.02894878387451172
Epoch: 30, Steps: 2 | Train Loss: 0.4367720 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.862645149230957e-11
Epoch: 31 cost time: 0.0281524658203125
Epoch: 31, Steps: 2 | Train Loss: 0.4384807 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.313225746154785e-12
Epoch: 32 cost time: 0.028551101684570312
Epoch: 32, Steps: 2 | Train Loss: 0.4408389 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.656612873077393e-12
Epoch: 33 cost time: 0.02891397476196289
Epoch: 33, Steps: 2 | Train Loss: 0.4354350 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.3283064365386963e-12
Epoch: 34 cost time: 0.03128504753112793
Epoch: 34, Steps: 2 | Train Loss: 0.4378222 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1641532182693482e-12
Epoch: 35 cost time: 0.028483152389526367
Epoch: 35, Steps: 2 | Train Loss: 0.4357566 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.820766091346741e-13
Epoch: 36 cost time: 0.03877758979797363
Epoch: 36, Steps: 2 | Train Loss: 0.4391157 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.9103830456733704e-13
Epoch: 37 cost time: 0.031908273696899414
Epoch: 37, Steps: 2 | Train Loss: 0.4355717 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.4551915228366852e-13
Epoch: 38 cost time: 0.02691197395324707
Epoch: 38, Steps: 2 | Train Loss: 0.4373144 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 7.275957614183426e-14
Epoch: 39 cost time: 0.04126429557800293
Epoch: 39, Steps: 2 | Train Loss: 0.4384429 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 3.637978807091713e-14
Epoch: 40 cost time: 0.049109697341918945
Epoch: 40, Steps: 2 | Train Loss: 0.4415609 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.8189894035458565e-14
Epoch: 41 cost time: 0.026720523834228516
Epoch: 41, Steps: 2 | Train Loss: 0.4324737 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.094947017729283e-15
Epoch: 42 cost time: 0.02673792839050293
Epoch: 42, Steps: 2 | Train Loss: 0.4392787 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.547473508864641e-15
Epoch: 43 cost time: 0.02675008773803711
Epoch: 43, Steps: 2 | Train Loss: 0.4335709 Vali Loss: 0.1164972 Test Loss: 0.1972433
Validation loss decreased (0.116497 --> 0.116497).  Saving model ...
Updating learning rate to 2.2737367544323206e-15
Epoch: 44 cost time: 0.042530059814453125
Epoch: 44, Steps: 2 | Train Loss: 0.4355292 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1368683772161603e-15
Epoch: 45 cost time: 0.026706695556640625
Epoch: 45, Steps: 2 | Train Loss: 0.4342267 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.684341886080802e-16
Epoch: 46 cost time: 0.026770591735839844
Epoch: 46, Steps: 2 | Train Loss: 0.4331234 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.842170943040401e-16
Epoch: 47 cost time: 0.02673196792602539
Epoch: 47, Steps: 2 | Train Loss: 0.4386686 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.4210854715202004e-16
Epoch: 48 cost time: 0.02679133415222168
Epoch: 48, Steps: 2 | Train Loss: 0.4353760 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.105427357601002e-17
Epoch: 49 cost time: 0.02675652503967285
Epoch: 49, Steps: 2 | Train Loss: 0.4343901 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.552713678800501e-17
Epoch: 50 cost time: 0.026791810989379883
Epoch: 50, Steps: 2 | Train Loss: 0.4388173 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.7763568394002505e-17
Epoch: 51 cost time: 0.026749610900878906
Epoch: 51, Steps: 2 | Train Loss: 0.4395903 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 8 out of 15
Updating learning rate to 8.881784197001253e-18
Epoch: 52 cost time: 0.026654481887817383
Epoch: 52, Steps: 2 | Train Loss: 0.4393342 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.440892098500626e-18
Epoch: 53 cost time: 0.03564453125
Epoch: 53, Steps: 2 | Train Loss: 0.4386215 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.220446049250313e-18
Epoch: 54 cost time: 0.027611255645751953
Epoch: 54, Steps: 2 | Train Loss: 0.4349109 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.1102230246251566e-18
Epoch: 55 cost time: 0.02674102783203125
Epoch: 55, Steps: 2 | Train Loss: 0.4332364 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 12 out of 15
Updating learning rate to 5.551115123125783e-19
Epoch: 56 cost time: 0.026768922805786133
Epoch: 56, Steps: 2 | Train Loss: 0.4373816 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.7755575615628914e-19
Epoch: 57 cost time: 0.026731252670288086
Epoch: 57, Steps: 2 | Train Loss: 0.4345716 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.3877787807814457e-19
Epoch: 58 cost time: 0.02677178382873535
Epoch: 58, Steps: 2 | Train Loss: 0.4361363 Vali Loss: 0.1164972 Test Loss: 0.1972433
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1972, mae:0.3402, msIC:-0.0230, msIR:-0.0459
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.028133153915405273
Epoch: 1, Steps: 2 | Train Loss: 0.6709950 Vali Loss: 0.1288214 Test Loss: 0.2128130
Validation loss decreased (inf --> 0.128821).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 0.050516605377197266
Epoch: 2, Steps: 2 | Train Loss: 0.5308782 Vali Loss: 0.1189269 Test Loss: 0.1994292
Validation loss decreased (0.128821 --> 0.118927).  Saving model ...
Updating learning rate to 0.005
Epoch: 3 cost time: 0.05065274238586426
Epoch: 3, Steps: 2 | Train Loss: 0.4640028 Vali Loss: 0.1160681 Test Loss: 0.1952979
Validation loss decreased (0.118927 --> 0.116068).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 0.058236122131347656
Epoch: 4, Steps: 2 | Train Loss: 0.4380776 Vali Loss: 0.1149674 Test Loss: 0.1937364
Validation loss decreased (0.116068 --> 0.114967).  Saving model ...
Updating learning rate to 0.00125
Epoch: 5 cost time: 0.0510251522064209
Epoch: 5, Steps: 2 | Train Loss: 0.4325373 Vali Loss: 0.1144755 Test Loss: 0.1930517
Validation loss decreased (0.114967 --> 0.114475).  Saving model ...
Updating learning rate to 0.000625
Epoch: 6 cost time: 0.04651904106140137
Epoch: 6, Steps: 2 | Train Loss: 0.4291934 Vali Loss: 0.1142329 Test Loss: 0.1927272
Validation loss decreased (0.114475 --> 0.114233).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 7 cost time: 0.048560142517089844
Epoch: 7, Steps: 2 | Train Loss: 0.4276263 Vali Loss: 0.1141143 Test Loss: 0.1925689
Validation loss decreased (0.114233 --> 0.114114).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 8 cost time: 0.04590272903442383
Epoch: 8, Steps: 2 | Train Loss: 0.4217358 Vali Loss: 0.1140528 Test Loss: 0.1924919
Validation loss decreased (0.114114 --> 0.114053).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 9 cost time: 0.06268739700317383
Epoch: 9, Steps: 2 | Train Loss: 0.4228901 Vali Loss: 0.1140238 Test Loss: 0.1924532
Validation loss decreased (0.114053 --> 0.114024).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 10 cost time: 0.07445073127746582
Epoch: 10, Steps: 2 | Train Loss: 0.4278303 Vali Loss: 0.1140090 Test Loss: 0.1924341
Validation loss decreased (0.114024 --> 0.114009).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 11 cost time: 0.05700278282165527
Epoch: 11, Steps: 2 | Train Loss: 0.4204223 Vali Loss: 0.1140014 Test Loss: 0.1924250
Validation loss decreased (0.114009 --> 0.114001).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 12 cost time: 0.04334902763366699
Epoch: 12, Steps: 2 | Train Loss: 0.4211036 Vali Loss: 0.1139975 Test Loss: 0.1924203
Validation loss decreased (0.114001 --> 0.113998).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 13 cost time: 0.055199623107910156
Epoch: 13, Steps: 2 | Train Loss: 0.4203633 Vali Loss: 0.1139955 Test Loss: 0.1924181
Validation loss decreased (0.113998 --> 0.113996).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 14 cost time: 0.04526114463806152
Epoch: 14, Steps: 2 | Train Loss: 0.4232459 Vali Loss: 0.1139945 Test Loss: 0.1924169
Validation loss decreased (0.113996 --> 0.113994).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 15 cost time: 0.0471348762512207
Epoch: 15, Steps: 2 | Train Loss: 0.4229283 Vali Loss: 0.1139940 Test Loss: 0.1924163
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 16 cost time: 0.053453683853149414
Epoch: 16, Steps: 2 | Train Loss: 0.4288048 Vali Loss: 0.1139937 Test Loss: 0.1924160
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 17 cost time: 0.05161452293395996
Epoch: 17, Steps: 2 | Train Loss: 0.4245121 Vali Loss: 0.1139936 Test Loss: 0.1924159
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 18 cost time: 0.052460670471191406
Epoch: 18, Steps: 2 | Train Loss: 0.4226758 Vali Loss: 0.1139936 Test Loss: 0.1924158
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 19 cost time: 0.05651068687438965
Epoch: 19, Steps: 2 | Train Loss: 0.4258793 Vali Loss: 0.1139935 Test Loss: 0.1924158
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 20 cost time: 0.057079315185546875
Epoch: 20, Steps: 2 | Train Loss: 0.4237843 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 21 cost time: 0.05630135536193848
Epoch: 21, Steps: 2 | Train Loss: 0.4222713 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 22 cost time: 0.05550980567932129
Epoch: 22, Steps: 2 | Train Loss: 0.4216200 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113994 --> 0.113994).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 23 cost time: 0.05601763725280762
Epoch: 23, Steps: 2 | Train Loss: 0.4235722 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113994 --> 0.113993).  Saving model ...
Updating learning rate to 2.384185791015625e-09
Epoch: 24 cost time: 0.055011749267578125
Epoch: 24, Steps: 2 | Train Loss: 0.4237016 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
Epoch: 25 cost time: 0.050275564193725586
Epoch: 25, Steps: 2 | Train Loss: 0.4268362 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 5.960464477539063e-10
Epoch: 26 cost time: 0.05987095832824707
Epoch: 26, Steps: 2 | Train Loss: 0.4245315 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
Epoch: 27 cost time: 0.04871964454650879
Epoch: 27, Steps: 2 | Train Loss: 0.4219607 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 28 cost time: 0.05944681167602539
Epoch: 28, Steps: 2 | Train Loss: 0.4179678 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 7.450580596923828e-11
Epoch: 29 cost time: 0.0503542423248291
Epoch: 29, Steps: 2 | Train Loss: 0.4197085 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 3.725290298461914e-11
Epoch: 30 cost time: 0.046239614486694336
Epoch: 30, Steps: 2 | Train Loss: 0.4258199 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.862645149230957e-11
Epoch: 31 cost time: 0.05792403221130371
Epoch: 31, Steps: 2 | Train Loss: 0.4204345 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 9.313225746154785e-12
Epoch: 32 cost time: 0.0467681884765625
Epoch: 32, Steps: 2 | Train Loss: 0.4257139 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 4.656612873077393e-12
Epoch: 33 cost time: 0.053374528884887695
Epoch: 33, Steps: 2 | Train Loss: 0.4263476 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.3283064365386963e-12
Epoch: 34 cost time: 0.028268098831176758
Epoch: 34, Steps: 2 | Train Loss: 0.4233228 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.1641532182693482e-12
Epoch: 35 cost time: 0.06291818618774414
Epoch: 35, Steps: 2 | Train Loss: 0.4257000 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 5.820766091346741e-13
Epoch: 36 cost time: 0.06053900718688965
Epoch: 36, Steps: 2 | Train Loss: 0.4213800 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 2.9103830456733704e-13
Epoch: 37 cost time: 0.05693173408508301
Epoch: 37, Steps: 2 | Train Loss: 0.4237460 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.4551915228366852e-13
Epoch: 38 cost time: 0.05917167663574219
Epoch: 38, Steps: 2 | Train Loss: 0.4201160 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 7.275957614183426e-14
Epoch: 39 cost time: 0.06874871253967285
Epoch: 39, Steps: 2 | Train Loss: 0.4252654 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.637978807091713e-14
Epoch: 40 cost time: 0.03224968910217285
Epoch: 40, Steps: 2 | Train Loss: 0.4227104 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.8189894035458565e-14
Epoch: 41 cost time: 0.027815818786621094
Epoch: 41, Steps: 2 | Train Loss: 0.4255641 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.094947017729283e-15
Epoch: 42 cost time: 0.027918577194213867
Epoch: 42, Steps: 2 | Train Loss: 0.4311999 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.547473508864641e-15
Epoch: 43 cost time: 0.02830648422241211
Epoch: 43, Steps: 2 | Train Loss: 0.4259774 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 2.2737367544323206e-15
Epoch: 44 cost time: 0.06465864181518555
Epoch: 44, Steps: 2 | Train Loss: 0.4208219 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1368683772161603e-15
Epoch: 45 cost time: 0.04461240768432617
Epoch: 45, Steps: 2 | Train Loss: 0.4210256 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.684341886080802e-16
Epoch: 46 cost time: 0.03372693061828613
Epoch: 46, Steps: 2 | Train Loss: 0.4243657 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.842170943040401e-16
Epoch: 47 cost time: 0.028348684310913086
Epoch: 47, Steps: 2 | Train Loss: 0.4218506 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.4210854715202004e-16
Epoch: 48 cost time: 0.0353093147277832
Epoch: 48, Steps: 2 | Train Loss: 0.4274832 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.105427357601002e-17
Epoch: 49 cost time: 0.02967381477355957
Epoch: 49, Steps: 2 | Train Loss: 0.4262366 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 3.552713678800501e-17
Epoch: 50 cost time: 0.041153907775878906
Epoch: 50, Steps: 2 | Train Loss: 0.4242570 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.7763568394002505e-17
Epoch: 51 cost time: 0.03378653526306152
Epoch: 51, Steps: 2 | Train Loss: 0.4251157 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 8.881784197001253e-18
Epoch: 52 cost time: 0.02803659439086914
Epoch: 52, Steps: 2 | Train Loss: 0.4237884 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.440892098500626e-18
Epoch: 53 cost time: 0.02673172950744629
Epoch: 53, Steps: 2 | Train Loss: 0.4237286 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.220446049250313e-18
Epoch: 54 cost time: 0.02667522430419922
Epoch: 54, Steps: 2 | Train Loss: 0.4213724 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1102230246251566e-18
Epoch: 55 cost time: 0.026642799377441406
Epoch: 55, Steps: 2 | Train Loss: 0.4255797 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.551115123125783e-19
Epoch: 56 cost time: 0.026726484298706055
Epoch: 56, Steps: 2 | Train Loss: 0.4215211 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.7755575615628914e-19
Epoch: 57 cost time: 0.026683330535888672
Epoch: 57, Steps: 2 | Train Loss: 0.4244575 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.3877787807814457e-19
Epoch: 58 cost time: 0.02668476104736328
Epoch: 58, Steps: 2 | Train Loss: 0.4234502 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.938893903907229e-20
Epoch: 59 cost time: 0.02670454978942871
Epoch: 59, Steps: 2 | Train Loss: 0.4249506 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 3.469446951953614e-20
Epoch: 60 cost time: 0.04268455505371094
Epoch: 60, Steps: 2 | Train Loss: 0.4207761 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.734723475976807e-20
Epoch: 61 cost time: 0.04160451889038086
Epoch: 61, Steps: 2 | Train Loss: 0.4269335 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 8.673617379884036e-21
Epoch: 62 cost time: 0.026732921600341797
Epoch: 62, Steps: 2 | Train Loss: 0.4266499 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.336808689942018e-21
Epoch: 63 cost time: 0.026718854904174805
Epoch: 63, Steps: 2 | Train Loss: 0.4219207 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.168404344971009e-21
Epoch: 64 cost time: 0.02674722671508789
Epoch: 64, Steps: 2 | Train Loss: 0.4268423 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.0842021724855045e-21
Epoch: 65 cost time: 0.026688575744628906
Epoch: 65, Steps: 2 | Train Loss: 0.4283218 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.421010862427522e-22
Epoch: 66 cost time: 0.02668452262878418
Epoch: 66, Steps: 2 | Train Loss: 0.4291583 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.710505431213761e-22
Epoch: 67 cost time: 0.02670001983642578
Epoch: 67, Steps: 2 | Train Loss: 0.4232635 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.3552527156068806e-22
Epoch: 68 cost time: 0.043288230895996094
Epoch: 68, Steps: 2 | Train Loss: 0.4250248 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.776263578034403e-23
Epoch: 69 cost time: 0.02680230140686035
Epoch: 69, Steps: 2 | Train Loss: 0.4261893 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.3881317890172014e-23
Epoch: 70 cost time: 0.02681565284729004
Epoch: 70, Steps: 2 | Train Loss: 0.4237470 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.6940658945086007e-23
Epoch: 71 cost time: 0.046975135803222656
Epoch: 71, Steps: 2 | Train Loss: 0.4245465 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 8.470329472543004e-24
Epoch: 72 cost time: 0.026674747467041016
Epoch: 72, Steps: 2 | Train Loss: 0.4279873 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.235164736271502e-24
Epoch: 73 cost time: 0.026728391647338867
Epoch: 73, Steps: 2 | Train Loss: 0.4245383 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.117582368135751e-24
Epoch: 74 cost time: 0.026708602905273438
Epoch: 74, Steps: 2 | Train Loss: 0.4277706 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.0587911840678754e-24
Epoch: 75 cost time: 0.026758909225463867
Epoch: 75, Steps: 2 | Train Loss: 0.4221705 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.293955920339377e-25
Epoch: 76 cost time: 0.026766061782836914
Epoch: 76, Steps: 2 | Train Loss: 0.4213411 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.6469779601696886e-25
Epoch: 77 cost time: 0.028453350067138672
Epoch: 77, Steps: 2 | Train Loss: 0.4246631 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.3234889800848443e-25
Epoch: 78 cost time: 0.027564287185668945
Epoch: 78, Steps: 2 | Train Loss: 0.4213711 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.617444900424222e-26
Epoch: 79 cost time: 0.0270540714263916
Epoch: 79, Steps: 2 | Train Loss: 0.4229328 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.308722450212111e-26
Epoch: 80 cost time: 0.02686905860900879
Epoch: 80, Steps: 2 | Train Loss: 0.4281704 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.6543612251060554e-26
Epoch: 81 cost time: 0.034110307693481445
Epoch: 81, Steps: 2 | Train Loss: 0.4277185 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 11 out of 15
Updating learning rate to 8.271806125530277e-27
Epoch: 82 cost time: 0.029255151748657227
Epoch: 82, Steps: 2 | Train Loss: 0.4207984 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 4.1359030627651385e-27
Epoch: 83 cost time: 0.05197858810424805
Epoch: 83, Steps: 2 | Train Loss: 0.4250387 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.0679515313825692e-27
Epoch: 84 cost time: 0.035387516021728516
Epoch: 84, Steps: 2 | Train Loss: 0.4251734 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.0339757656912846e-27
Epoch: 85 cost time: 0.03594017028808594
Epoch: 85, Steps: 2 | Train Loss: 0.4254999 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 5.169878828456423e-28
Epoch: 86 cost time: 0.027918577194213867
Epoch: 86, Steps: 2 | Train Loss: 0.4235382 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 2.5849394142282115e-28
Epoch: 87 cost time: 0.05515313148498535
Epoch: 87, Steps: 2 | Train Loss: 0.4267434 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 1.2924697071141058e-28
Epoch: 88 cost time: 0.06734180450439453
Epoch: 88, Steps: 2 | Train Loss: 0.4270463 Vali Loss: 0.1139935 Test Loss: 0.1924157
Validation loss decreased (0.113993 --> 0.113993).  Saving model ...
Updating learning rate to 6.462348535570529e-29
Epoch: 89 cost time: 0.05809736251831055
Epoch: 89, Steps: 2 | Train Loss: 0.4259611 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.2311742677852644e-29
Epoch: 90 cost time: 0.027669429779052734
Epoch: 90, Steps: 2 | Train Loss: 0.4204552 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.6155871338926322e-29
Epoch: 91 cost time: 0.02701282501220703
Epoch: 91, Steps: 2 | Train Loss: 0.4301040 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 3 out of 15
Updating learning rate to 8.077935669463161e-30
Epoch: 92 cost time: 0.026940584182739258
Epoch: 92, Steps: 2 | Train Loss: 0.4251417 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.0389678347315805e-30
Epoch: 93 cost time: 0.027204275131225586
Epoch: 93, Steps: 2 | Train Loss: 0.4262426 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.0194839173657903e-30
Epoch: 94 cost time: 0.026983261108398438
Epoch: 94, Steps: 2 | Train Loss: 0.4225831 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.0097419586828951e-30
Epoch: 95 cost time: 0.027771472930908203
Epoch: 95, Steps: 2 | Train Loss: 0.4175209 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.048709793414476e-31
Epoch: 96 cost time: 0.028173446655273438
Epoch: 96, Steps: 2 | Train Loss: 0.4267508 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.524354896707238e-31
Epoch: 97 cost time: 0.035544633865356445
Epoch: 97, Steps: 2 | Train Loss: 0.4293915 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.262177448353619e-31
Epoch: 98 cost time: 0.03138375282287598
Epoch: 98, Steps: 2 | Train Loss: 0.4205911 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 10 out of 15
Updating learning rate to 6.310887241768095e-32
Epoch: 99 cost time: 0.03344225883483887
Epoch: 99, Steps: 2 | Train Loss: 0.4221416 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.1554436208840473e-32
Epoch: 100 cost time: 0.02768421173095703
Epoch: 100, Steps: 2 | Train Loss: 0.4215934 Vali Loss: 0.1139935 Test Loss: 0.1924157
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.5777218104420236e-32
>>>>>>>testing : long_term_forecast_POST_COVID_TiDE_pl5_TiDE_custom_ftMS_sl128_ll48_pl5_dm256_nh8_el2_dl2_df256_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1924, mae:0.3399, msIC:-0.0296, msIR:-0.0589
Total Evaluation 

MSE:0.1941Â±0.0022
MAE:0.3385Â±0.0022
msIC:-0.0204Â±0.0088
msIR:-0.0407Â±0.0174
  Evaluating TiDE results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: TimesNet
  Training TimesNet...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_TimesNet_pl5Model:              TimesNet            

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.1650712490081787
Epoch: 1, Steps: 28 | Train Loss: 0.5711900 Vali Loss: 0.1061854 Test Loss: 0.1880306
Validation loss decreased (inf --> 0.106185).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.5548624992370605
Epoch: 2, Steps: 28 | Train Loss: 0.4625840 Vali Loss: 0.1030935 Test Loss: 0.1809122
Validation loss decreased (0.106185 --> 0.103093).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.5287027359008789
Epoch: 3, Steps: 28 | Train Loss: 0.4429264 Vali Loss: 0.1062750 Test Loss: 0.1802935
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5324687957763672
Epoch: 4, Steps: 28 | Train Loss: 0.4317226 Vali Loss: 0.1073287 Test Loss: 0.1805227
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5184910297393799
Epoch: 5, Steps: 28 | Train Loss: 0.4231288 Vali Loss: 0.1082825 Test Loss: 0.1794623
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5371954441070557
Epoch: 6, Steps: 28 | Train Loss: 0.4226043 Vali Loss: 0.1070137 Test Loss: 0.1794297
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.5152394771575928
Epoch: 7, Steps: 28 | Train Loss: 0.4166584 Vali Loss: 0.1040062 Test Loss: 0.1793793
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.5175399780273438
Epoch: 8, Steps: 28 | Train Loss: 0.4201974 Vali Loss: 0.1083747 Test Loss: 0.1793831
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5204169750213623
Epoch: 9, Steps: 28 | Train Loss: 0.4222634 Vali Loss: 0.1014995 Test Loss: 0.1793310
Validation loss decreased (0.103093 --> 0.101499).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.5282447338104248
Epoch: 10, Steps: 28 | Train Loss: 0.4203855 Vali Loss: 0.1084470 Test Loss: 0.1793703
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5179953575134277
Epoch: 11, Steps: 28 | Train Loss: 0.4183619 Vali Loss: 0.1039559 Test Loss: 0.1793776
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.5171654224395752
Epoch: 12, Steps: 28 | Train Loss: 0.4182486 Vali Loss: 0.1042222 Test Loss: 0.1793885
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.5269999504089355
Epoch: 13, Steps: 28 | Train Loss: 0.4183432 Vali Loss: 0.1025021 Test Loss: 0.1793934
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.5194127559661865
Epoch: 14, Steps: 28 | Train Loss: 0.4185089 Vali Loss: 0.1006172 Test Loss: 0.1793946
Validation loss decreased (0.101499 --> 0.100617).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.5319638252258301
Epoch: 15, Steps: 28 | Train Loss: 0.4162708 Vali Loss: 0.1027436 Test Loss: 0.1793945
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.5220389366149902
Epoch: 16, Steps: 28 | Train Loss: 0.4187615 Vali Loss: 0.1036316 Test Loss: 0.1793947
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.55419921875
Epoch: 17, Steps: 28 | Train Loss: 0.4148624 Vali Loss: 0.1020978 Test Loss: 0.1793950
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.5473942756652832
Epoch: 18, Steps: 28 | Train Loss: 0.4173681 Vali Loss: 0.1033444 Test Loss: 0.1793949
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.5199189186096191
Epoch: 19, Steps: 28 | Train Loss: 0.4191832 Vali Loss: 0.1045197 Test Loss: 0.1793952
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.518038272857666
Epoch: 20, Steps: 28 | Train Loss: 0.4179267 Vali Loss: 0.1055520 Test Loss: 0.1793950
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.524263858795166
Epoch: 21, Steps: 28 | Train Loss: 0.4170818 Vali Loss: 0.1028409 Test Loss: 0.1793951
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.5343325138092041
Epoch: 22, Steps: 28 | Train Loss: 0.4203462 Vali Loss: 0.1040894 Test Loss: 0.1793951
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.5191013813018799
Epoch: 23, Steps: 28 | Train Loss: 0.4214076 Vali Loss: 0.1125912 Test Loss: 0.1793951
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.5194106101989746
Epoch: 24, Steps: 28 | Train Loss: 0.4177567 Vali Loss: 0.1043364 Test Loss: 0.1793951
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.5196306705474854
Epoch: 25, Steps: 28 | Train Loss: 0.4206555 Vali Loss: 0.1042502 Test Loss: 0.1793950
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.5193941593170166
Epoch: 26, Steps: 28 | Train Loss: 0.4187145 Vali Loss: 0.1074857 Test Loss: 0.1793950
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.5337462425231934
Epoch: 27, Steps: 28 | Train Loss: 0.4213417 Vali Loss: 0.1069080 Test Loss: 0.1793950
EarlyStopping counter: 13 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.5166745185852051
Epoch: 28, Steps: 28 | Train Loss: 0.4173080 Vali Loss: 0.1036538 Test Loss: 0.1793950
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.5169825553894043
Epoch: 29, Steps: 28 | Train Loss: 0.4181318 Vali Loss: 0.1074762 Test Loss: 0.1793950
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1796, mae:0.3182, msIC:0.0378, msIR:0.0755
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.5939359664916992
Epoch: 1, Steps: 28 | Train Loss: 0.5859800 Vali Loss: 0.1111247 Test Loss: 0.1779191
Validation loss decreased (inf --> 0.111125).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.5553555488586426
Epoch: 2, Steps: 28 | Train Loss: 0.4967102 Vali Loss: 0.1063150 Test Loss: 0.1765032
Validation loss decreased (0.111125 --> 0.106315).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.5564444065093994
Epoch: 3, Steps: 28 | Train Loss: 0.4545861 Vali Loss: 0.1017555 Test Loss: 0.1753479
Validation loss decreased (0.106315 --> 0.101755).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5463659763336182
Epoch: 4, Steps: 28 | Train Loss: 0.4424807 Vali Loss: 0.1041398 Test Loss: 0.1758023
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5428111553192139
Epoch: 5, Steps: 28 | Train Loss: 0.4402575 Vali Loss: 0.1076810 Test Loss: 0.1756798
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5390238761901855
Epoch: 6, Steps: 28 | Train Loss: 0.4376035 Vali Loss: 0.1024077 Test Loss: 0.1757542
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.5390949249267578
Epoch: 7, Steps: 28 | Train Loss: 0.4332850 Vali Loss: 0.1030207 Test Loss: 0.1758812
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.5431699752807617
Epoch: 8, Steps: 28 | Train Loss: 0.4336203 Vali Loss: 0.1006418 Test Loss: 0.1758961
Validation loss decreased (0.101755 --> 0.100642).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5527515411376953
Epoch: 9, Steps: 28 | Train Loss: 0.4300311 Vali Loss: 0.1023479 Test Loss: 0.1759334
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.5419914722442627
Epoch: 10, Steps: 28 | Train Loss: 0.4335956 Vali Loss: 0.1018362 Test Loss: 0.1759289
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5414257049560547
Epoch: 11, Steps: 28 | Train Loss: 0.4303601 Vali Loss: 0.1052613 Test Loss: 0.1759260
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.539832353591919
Epoch: 12, Steps: 28 | Train Loss: 0.4341654 Vali Loss: 0.1056805 Test Loss: 0.1759243
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.5411310195922852
Epoch: 13, Steps: 28 | Train Loss: 0.4323515 Vali Loss: 0.1057259 Test Loss: 0.1759246
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.5401709079742432
Epoch: 14, Steps: 28 | Train Loss: 0.4336906 Vali Loss: 0.1060153 Test Loss: 0.1759236
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.5551092624664307
Epoch: 15, Steps: 28 | Train Loss: 0.4285164 Vali Loss: 0.1056346 Test Loss: 0.1759243
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.5450975894927979
Epoch: 16, Steps: 28 | Train Loss: 0.4255838 Vali Loss: 0.1049748 Test Loss: 0.1759243
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.5444774627685547
Epoch: 17, Steps: 28 | Train Loss: 0.4314836 Vali Loss: 0.1019391 Test Loss: 0.1759244
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.5460355281829834
Epoch: 18, Steps: 28 | Train Loss: 0.4235618 Vali Loss: 0.1028300 Test Loss: 0.1759244
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.540550947189331
Epoch: 19, Steps: 28 | Train Loss: 0.4299362 Vali Loss: 0.1058954 Test Loss: 0.1759244
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.5439801216125488
Epoch: 20, Steps: 28 | Train Loss: 0.4304669 Vali Loss: 0.1010190 Test Loss: 0.1759243
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.5449526309967041
Epoch: 21, Steps: 28 | Train Loss: 0.4349438 Vali Loss: 0.1065206 Test Loss: 0.1759242
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.543203592300415
Epoch: 22, Steps: 28 | Train Loss: 0.4312632 Vali Loss: 0.1027067 Test Loss: 0.1759243
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.5439295768737793
Epoch: 23, Steps: 28 | Train Loss: 0.4263539 Vali Loss: 0.1035031 Test Loss: 0.1759243
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1761, mae:0.3151, msIC:0.0361, msIR:0.0743
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.5558459758758545
Epoch: 1, Steps: 28 | Train Loss: 0.6855669 Vali Loss: 0.1063044 Test Loss: 0.1899405
Validation loss decreased (inf --> 0.106304).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.5513744354248047
Epoch: 2, Steps: 28 | Train Loss: 0.5008140 Vali Loss: 0.1051186 Test Loss: 0.1802753
Validation loss decreased (0.106304 --> 0.105119).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.5357222557067871
Epoch: 3, Steps: 28 | Train Loss: 0.4477849 Vali Loss: 0.1015919 Test Loss: 0.1789033
Validation loss decreased (0.105119 --> 0.101592).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.5364775657653809
Epoch: 4, Steps: 28 | Train Loss: 0.4340091 Vali Loss: 0.1010011 Test Loss: 0.1807266
Validation loss decreased (0.101592 --> 0.101001).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.5320522785186768
Epoch: 5, Steps: 28 | Train Loss: 0.4217729 Vali Loss: 0.1014170 Test Loss: 0.1793302
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.5227422714233398
Epoch: 6, Steps: 28 | Train Loss: 0.4206147 Vali Loss: 0.1003919 Test Loss: 0.1798742
Validation loss decreased (0.101001 --> 0.100392).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.5336558818817139
Epoch: 7, Steps: 28 | Train Loss: 0.4196993 Vali Loss: 0.1046157 Test Loss: 0.1797919
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.5252606868743896
Epoch: 8, Steps: 28 | Train Loss: 0.4179249 Vali Loss: 0.1034000 Test Loss: 0.1796883
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.5287716388702393
Epoch: 9, Steps: 28 | Train Loss: 0.4133497 Vali Loss: 0.1056748 Test Loss: 0.1798444
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.5226707458496094
Epoch: 10, Steps: 28 | Train Loss: 0.4162085 Vali Loss: 0.1038692 Test Loss: 0.1799053
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.5258476734161377
Epoch: 11, Steps: 28 | Train Loss: 0.4141371 Vali Loss: 0.1026866 Test Loss: 0.1799014
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.5275304317474365
Epoch: 12, Steps: 28 | Train Loss: 0.4168053 Vali Loss: 0.1023993 Test Loss: 0.1799075
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.5270378589630127
Epoch: 13, Steps: 28 | Train Loss: 0.4104499 Vali Loss: 0.1022920 Test Loss: 0.1799088
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.5248446464538574
Epoch: 14, Steps: 28 | Train Loss: 0.4156635 Vali Loss: 0.1057228 Test Loss: 0.1799106
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.5262613296508789
Epoch: 15, Steps: 28 | Train Loss: 0.4141355 Vali Loss: 0.1022962 Test Loss: 0.1799104
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.5221848487854004
Epoch: 16, Steps: 28 | Train Loss: 0.4172073 Vali Loss: 0.1039102 Test Loss: 0.1799104
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.5235731601715088
Epoch: 17, Steps: 28 | Train Loss: 0.4172079 Vali Loss: 0.1048633 Test Loss: 0.1799106
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.5234289169311523
Epoch: 18, Steps: 28 | Train Loss: 0.4181494 Vali Loss: 0.1034269 Test Loss: 0.1799107
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.5240139961242676
Epoch: 19, Steps: 28 | Train Loss: 0.4186492 Vali Loss: 0.1068527 Test Loss: 0.1799107
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.524937629699707
Epoch: 20, Steps: 28 | Train Loss: 0.4182305 Vali Loss: 0.1011299 Test Loss: 0.1799106
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.524122953414917
Epoch: 21, Steps: 28 | Train Loss: 0.4165357 Vali Loss: 0.1021560 Test Loss: 0.1799106
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TimesNet_pl5_TimesNet_custom_ftMS_sl128_ll48_pl5_dm32_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1801, mae:0.3149, msIC:0.0462, msIR:0.0962
Total Evaluation 

MSE:0.1786Â±0.0018
MAE:0.3161Â±0.0015
msIC:0.0400Â±0.0044
msIR:0.0820Â±0.0101
  Evaluating TimesNet results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: Crossformer
  Training Crossformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Crossformer_pl5Model:              Crossformer         

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.3929152488708496
Epoch: 1, Steps: 28 | Train Loss: 0.6622298 Vali Loss: 0.1172229 Test Loss: 0.1857975
Validation loss decreased (inf --> 0.117223).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.2995340824127197
Epoch: 2, Steps: 28 | Train Loss: 0.5345964 Vali Loss: 0.1089012 Test Loss: 0.1820596
Validation loss decreased (0.117223 --> 0.108901).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.3053469657897949
Epoch: 3, Steps: 28 | Train Loss: 0.5003328 Vali Loss: 0.1078510 Test Loss: 0.1787897
Validation loss decreased (0.108901 --> 0.107851).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.30722928047180176
Epoch: 4, Steps: 28 | Train Loss: 0.4879596 Vali Loss: 0.1043699 Test Loss: 0.1780406
Validation loss decreased (0.107851 --> 0.104370).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.3055598735809326
Epoch: 5, Steps: 28 | Train Loss: 0.4825259 Vali Loss: 0.1016541 Test Loss: 0.1756471
Validation loss decreased (0.104370 --> 0.101654).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.3168833255767822
Epoch: 6, Steps: 28 | Train Loss: 0.4823601 Vali Loss: 0.1043883 Test Loss: 0.1752007
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2947425842285156
Epoch: 7, Steps: 28 | Train Loss: 0.4739984 Vali Loss: 0.1038701 Test Loss: 0.1757035
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.287900447845459
Epoch: 8, Steps: 28 | Train Loss: 0.4831841 Vali Loss: 0.1016856 Test Loss: 0.1755148
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.2925868034362793
Epoch: 9, Steps: 28 | Train Loss: 0.4862519 Vali Loss: 0.1046746 Test Loss: 0.1753984
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.2936577796936035
Epoch: 10, Steps: 28 | Train Loss: 0.4794669 Vali Loss: 0.1021975 Test Loss: 0.1753860
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.29462456703186035
Epoch: 11, Steps: 28 | Train Loss: 0.4771778 Vali Loss: 0.1028341 Test Loss: 0.1753935
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.296511173248291
Epoch: 12, Steps: 28 | Train Loss: 0.4739561 Vali Loss: 0.1058428 Test Loss: 0.1753969
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2987802028656006
Epoch: 13, Steps: 28 | Train Loss: 0.4778725 Vali Loss: 0.1000516 Test Loss: 0.1754006
Validation loss decreased (0.101654 --> 0.100052).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2982783317565918
Epoch: 14, Steps: 28 | Train Loss: 0.4781114 Vali Loss: 0.1038575 Test Loss: 0.1754016
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.2951085567474365
Epoch: 15, Steps: 28 | Train Loss: 0.4808501 Vali Loss: 0.1018711 Test Loss: 0.1754020
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.29157137870788574
Epoch: 16, Steps: 28 | Train Loss: 0.4818946 Vali Loss: 0.1043386 Test Loss: 0.1754013
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.2923245429992676
Epoch: 17, Steps: 28 | Train Loss: 0.4790579 Vali Loss: 0.1021157 Test Loss: 0.1754012
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.29131579399108887
Epoch: 18, Steps: 28 | Train Loss: 0.4819907 Vali Loss: 0.1008285 Test Loss: 0.1754013
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.2947707176208496
Epoch: 19, Steps: 28 | Train Loss: 0.4894135 Vali Loss: 0.1065908 Test Loss: 0.1754013
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.292712926864624
Epoch: 20, Steps: 28 | Train Loss: 0.4793826 Vali Loss: 0.1009525 Test Loss: 0.1754013
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.29242825508117676
Epoch: 21, Steps: 28 | Train Loss: 0.4815600 Vali Loss: 0.1010728 Test Loss: 0.1754013
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.29349303245544434
Epoch: 22, Steps: 28 | Train Loss: 0.4719938 Vali Loss: 0.1023276 Test Loss: 0.1754013
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.29224324226379395
Epoch: 23, Steps: 28 | Train Loss: 0.4768616 Vali Loss: 0.1000209 Test Loss: 0.1754013
Validation loss decreased (0.100052 --> 0.100021).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.3003678321838379
Epoch: 24, Steps: 28 | Train Loss: 0.4811684 Vali Loss: 0.1006910 Test Loss: 0.1754013
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.2870182991027832
Epoch: 25, Steps: 28 | Train Loss: 0.4862453 Vali Loss: 0.1043118 Test Loss: 0.1754013
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.2940852642059326
Epoch: 26, Steps: 28 | Train Loss: 0.4771821 Vali Loss: 0.1007072 Test Loss: 0.1754013
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.2970540523529053
Epoch: 27, Steps: 28 | Train Loss: 0.4803038 Vali Loss: 0.1027423 Test Loss: 0.1754013
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.2942652702331543
Epoch: 28, Steps: 28 | Train Loss: 0.4804627 Vali Loss: 0.0993770 Test Loss: 0.1754013
Validation loss decreased (0.100021 --> 0.099377).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.320758581161499
Epoch: 29, Steps: 28 | Train Loss: 0.4763088 Vali Loss: 0.1013418 Test Loss: 0.1754013
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.29602956771850586
Epoch: 30, Steps: 28 | Train Loss: 0.4789858 Vali Loss: 0.1056021 Test Loss: 0.1754013
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.2951200008392334
Epoch: 31, Steps: 28 | Train Loss: 0.4798835 Vali Loss: 0.1040782 Test Loss: 0.1754013
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.29232215881347656
Epoch: 32, Steps: 28 | Train Loss: 0.4768825 Vali Loss: 0.1046224 Test Loss: 0.1754013
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.29580259323120117
Epoch: 33, Steps: 28 | Train Loss: 0.4829802 Vali Loss: 0.1055139 Test Loss: 0.1754013
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.29817819595336914
Epoch: 34, Steps: 28 | Train Loss: 0.4835099 Vali Loss: 0.1025395 Test Loss: 0.1754013
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.30419158935546875
Epoch: 35, Steps: 28 | Train Loss: 0.4806072 Vali Loss: 0.1038676 Test Loss: 0.1754013
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.2895023822784424
Epoch: 36, Steps: 28 | Train Loss: 0.4820992 Vali Loss: 0.0994040 Test Loss: 0.1754013
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.28542542457580566
Epoch: 37, Steps: 28 | Train Loss: 0.4756869 Vali Loss: 0.1007417 Test Loss: 0.1754013
EarlyStopping counter: 9 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.28486132621765137
Epoch: 38, Steps: 28 | Train Loss: 0.4810507 Vali Loss: 0.1058862 Test Loss: 0.1754013
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.2892341613769531
Epoch: 39, Steps: 28 | Train Loss: 0.4888025 Vali Loss: 0.1015005 Test Loss: 0.1754013
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.285203218460083
Epoch: 40, Steps: 28 | Train Loss: 0.4759501 Vali Loss: 0.1046254 Test Loss: 0.1754013
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.2846708297729492
Epoch: 41, Steps: 28 | Train Loss: 0.4863198 Vali Loss: 0.1036421 Test Loss: 0.1754013
EarlyStopping counter: 13 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.29276108741760254
Epoch: 42, Steps: 28 | Train Loss: 0.4766267 Vali Loss: 0.1025027 Test Loss: 0.1754013
EarlyStopping counter: 14 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.28531646728515625
Epoch: 43, Steps: 28 | Train Loss: 0.4791673 Vali Loss: 0.1000833 Test Loss: 0.1754013
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1756, mae:0.3135, msIC:0.0331, msIR:0.0633
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.29602670669555664
Epoch: 1, Steps: 28 | Train Loss: 0.6443818 Vali Loss: 0.1142988 Test Loss: 0.1907787
Validation loss decreased (inf --> 0.114299).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.292280912399292
Epoch: 2, Steps: 28 | Train Loss: 0.5089994 Vali Loss: 0.1033117 Test Loss: 0.1755682
Validation loss decreased (0.114299 --> 0.103312).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.2971787452697754
Epoch: 3, Steps: 28 | Train Loss: 0.4906091 Vali Loss: 0.1090660 Test Loss: 0.1796528
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.29301881790161133
Epoch: 4, Steps: 28 | Train Loss: 0.4933781 Vali Loss: 0.1029242 Test Loss: 0.1751675
Validation loss decreased (0.103312 --> 0.102924).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2894933223724365
Epoch: 5, Steps: 28 | Train Loss: 0.4881491 Vali Loss: 0.1013427 Test Loss: 0.1759007
Validation loss decreased (0.102924 --> 0.101343).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.2953033447265625
Epoch: 6, Steps: 28 | Train Loss: 0.4700153 Vali Loss: 0.1012363 Test Loss: 0.1758472
Validation loss decreased (0.101343 --> 0.101236).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.29126834869384766
Epoch: 7, Steps: 28 | Train Loss: 0.4847719 Vali Loss: 0.1011376 Test Loss: 0.1753655
Validation loss decreased (0.101236 --> 0.101138).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.2953782081604004
Epoch: 8, Steps: 28 | Train Loss: 0.4729213 Vali Loss: 0.1023615 Test Loss: 0.1755627
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.297255277633667
Epoch: 9, Steps: 28 | Train Loss: 0.4741029 Vali Loss: 0.1035742 Test Loss: 0.1755812
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.29415178298950195
Epoch: 10, Steps: 28 | Train Loss: 0.4761934 Vali Loss: 0.1031088 Test Loss: 0.1755971
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.2944357395172119
Epoch: 11, Steps: 28 | Train Loss: 0.4797988 Vali Loss: 0.1039696 Test Loss: 0.1756346
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.29866838455200195
Epoch: 12, Steps: 28 | Train Loss: 0.4809775 Vali Loss: 0.1063832 Test Loss: 0.1756159
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.2891860008239746
Epoch: 13, Steps: 28 | Train Loss: 0.4780014 Vali Loss: 0.1000351 Test Loss: 0.1756091
Validation loss decreased (0.101138 --> 0.100035).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2904491424560547
Epoch: 14, Steps: 28 | Train Loss: 0.4733782 Vali Loss: 0.1007830 Test Loss: 0.1756123
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.2936248779296875
Epoch: 15, Steps: 28 | Train Loss: 0.4757033 Vali Loss: 0.0998850 Test Loss: 0.1756124
Validation loss decreased (0.100035 --> 0.099885).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.30161070823669434
Epoch: 16, Steps: 28 | Train Loss: 0.4770022 Vali Loss: 0.1035737 Test Loss: 0.1756124
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.2948005199432373
Epoch: 17, Steps: 28 | Train Loss: 0.4739897 Vali Loss: 0.1016183 Test Loss: 0.1756127
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.2956206798553467
Epoch: 18, Steps: 28 | Train Loss: 0.4767530 Vali Loss: 0.0989345 Test Loss: 0.1756126
Validation loss decreased (0.099885 --> 0.098935).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.2994394302368164
Epoch: 19, Steps: 28 | Train Loss: 0.4737325 Vali Loss: 0.0974940 Test Loss: 0.1756126
Validation loss decreased (0.098935 --> 0.097494).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.32039690017700195
Epoch: 20, Steps: 28 | Train Loss: 0.4825384 Vali Loss: 0.1043060 Test Loss: 0.1756126
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.30693602561950684
Epoch: 21, Steps: 28 | Train Loss: 0.4695447 Vali Loss: 0.1021375 Test Loss: 0.1756126
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.2883315086364746
Epoch: 22, Steps: 28 | Train Loss: 0.4730241 Vali Loss: 0.1009934 Test Loss: 0.1756126
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.2880995273590088
Epoch: 23, Steps: 28 | Train Loss: 0.4718163 Vali Loss: 0.1024613 Test Loss: 0.1756126
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.2980353832244873
Epoch: 24, Steps: 28 | Train Loss: 0.4763252 Vali Loss: 0.1015939 Test Loss: 0.1756126
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.29416346549987793
Epoch: 25, Steps: 28 | Train Loss: 0.4783096 Vali Loss: 0.1018945 Test Loss: 0.1756126
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.2981746196746826
Epoch: 26, Steps: 28 | Train Loss: 0.4681633 Vali Loss: 0.1018214 Test Loss: 0.1756126
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.29720520973205566
Epoch: 27, Steps: 28 | Train Loss: 0.4644068 Vali Loss: 0.1028736 Test Loss: 0.1756126
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.28859853744506836
Epoch: 28, Steps: 28 | Train Loss: 0.4747425 Vali Loss: 0.1020211 Test Loss: 0.1756126
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.2910120487213135
Epoch: 29, Steps: 28 | Train Loss: 0.4774776 Vali Loss: 0.1012918 Test Loss: 0.1756126
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.2966468334197998
Epoch: 30, Steps: 28 | Train Loss: 0.4810013 Vali Loss: 0.1000768 Test Loss: 0.1756126
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.29482340812683105
Epoch: 31, Steps: 28 | Train Loss: 0.4737296 Vali Loss: 0.1067358 Test Loss: 0.1756126
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.2946469783782959
Epoch: 32, Steps: 28 | Train Loss: 0.4754033 Vali Loss: 0.0991120 Test Loss: 0.1756126
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.29562830924987793
Epoch: 33, Steps: 28 | Train Loss: 0.4812842 Vali Loss: 0.0997180 Test Loss: 0.1756126
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.28828930854797363
Epoch: 34, Steps: 28 | Train Loss: 0.4832296 Vali Loss: 0.1068244 Test Loss: 0.1756126
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1758, mae:0.3132, msIC:0.0162, msIR:0.0311
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.2974979877471924
Epoch: 1, Steps: 28 | Train Loss: 0.6230461 Vali Loss: 0.1320612 Test Loss: 0.2038468
Validation loss decreased (inf --> 0.132061).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.2965688705444336
Epoch: 2, Steps: 28 | Train Loss: 0.5088304 Vali Loss: 0.1064974 Test Loss: 0.1813029
Validation loss decreased (0.132061 --> 0.106497).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.3118295669555664
Epoch: 3, Steps: 28 | Train Loss: 0.4889073 Vali Loss: 0.1057148 Test Loss: 0.1779011
Validation loss decreased (0.106497 --> 0.105715).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.3004152774810791
Epoch: 4, Steps: 28 | Train Loss: 0.4777818 Vali Loss: 0.1048283 Test Loss: 0.1786449
Validation loss decreased (0.105715 --> 0.104828).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.2994828224182129
Epoch: 5, Steps: 28 | Train Loss: 0.4729723 Vali Loss: 0.1019305 Test Loss: 0.1767542
Validation loss decreased (0.104828 --> 0.101930).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.3324120044708252
Epoch: 6, Steps: 28 | Train Loss: 0.4759608 Vali Loss: 0.1043826 Test Loss: 0.1772858
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.2968251705169678
Epoch: 7, Steps: 28 | Train Loss: 0.4764448 Vali Loss: 0.1075548 Test Loss: 0.1771680
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.29500818252563477
Epoch: 8, Steps: 28 | Train Loss: 0.4647837 Vali Loss: 0.1057819 Test Loss: 0.1768813
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.300046443939209
Epoch: 9, Steps: 28 | Train Loss: 0.4733349 Vali Loss: 0.1046815 Test Loss: 0.1769097
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.29714107513427734
Epoch: 10, Steps: 28 | Train Loss: 0.4680748 Vali Loss: 0.1086521 Test Loss: 0.1769444
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.2942204475402832
Epoch: 11, Steps: 28 | Train Loss: 0.4735171 Vali Loss: 0.1051132 Test Loss: 0.1769210
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.29605817794799805
Epoch: 12, Steps: 28 | Train Loss: 0.4631072 Vali Loss: 0.1032010 Test Loss: 0.1769367
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.29643797874450684
Epoch: 13, Steps: 28 | Train Loss: 0.4690063 Vali Loss: 0.1055128 Test Loss: 0.1769364
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.2940409183502197
Epoch: 14, Steps: 28 | Train Loss: 0.4728463 Vali Loss: 0.1010974 Test Loss: 0.1769333
Validation loss decreased (0.101930 --> 0.101097).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.2989847660064697
Epoch: 15, Steps: 28 | Train Loss: 0.4735842 Vali Loss: 0.1044340 Test Loss: 0.1769354
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.2955482006072998
Epoch: 16, Steps: 28 | Train Loss: 0.4777757 Vali Loss: 0.1023246 Test Loss: 0.1769349
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.29767274856567383
Epoch: 17, Steps: 28 | Train Loss: 0.4710825 Vali Loss: 0.1014333 Test Loss: 0.1769351
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.3002166748046875
Epoch: 18, Steps: 28 | Train Loss: 0.4681256 Vali Loss: 0.1007016 Test Loss: 0.1769352
Validation loss decreased (0.101097 --> 0.100702).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.30623888969421387
Epoch: 19, Steps: 28 | Train Loss: 0.4731172 Vali Loss: 0.1050022 Test Loss: 0.1769352
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.2944059371948242
Epoch: 20, Steps: 28 | Train Loss: 0.4718554 Vali Loss: 0.1020487 Test Loss: 0.1769352
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.2967958450317383
Epoch: 21, Steps: 28 | Train Loss: 0.4697901 Vali Loss: 0.1050034 Test Loss: 0.1769351
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.2941265106201172
Epoch: 22, Steps: 28 | Train Loss: 0.4703565 Vali Loss: 0.1015227 Test Loss: 0.1769352
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.2945692539215088
Epoch: 23, Steps: 28 | Train Loss: 0.4700280 Vali Loss: 0.1021035 Test Loss: 0.1769352
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.2987070083618164
Epoch: 24, Steps: 28 | Train Loss: 0.4697750 Vali Loss: 0.1023519 Test Loss: 0.1769352
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.29439258575439453
Epoch: 25, Steps: 28 | Train Loss: 0.4654701 Vali Loss: 0.1004398 Test Loss: 0.1769352
Validation loss decreased (0.100702 --> 0.100440).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.29726529121398926
Epoch: 26, Steps: 28 | Train Loss: 0.4695513 Vali Loss: 0.1030749 Test Loss: 0.1769352
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.29689645767211914
Epoch: 27, Steps: 28 | Train Loss: 0.4661774 Vali Loss: 0.1025774 Test Loss: 0.1769352
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.2940056324005127
Epoch: 28, Steps: 28 | Train Loss: 0.4727129 Vali Loss: 0.1018694 Test Loss: 0.1769352
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.2956809997558594
Epoch: 29, Steps: 28 | Train Loss: 0.4607534 Vali Loss: 0.1039113 Test Loss: 0.1769352
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.2980365753173828
Epoch: 30, Steps: 28 | Train Loss: 0.4738177 Vali Loss: 0.1015473 Test Loss: 0.1769352
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.3012681007385254
Epoch: 31, Steps: 28 | Train Loss: 0.4693118 Vali Loss: 0.1012805 Test Loss: 0.1769352
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.2959706783294678
Epoch: 32, Steps: 28 | Train Loss: 0.4709603 Vali Loss: 0.1011351 Test Loss: 0.1769352
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.29793620109558105
Epoch: 33, Steps: 28 | Train Loss: 0.4715009 Vali Loss: 0.0994138 Test Loss: 0.1769352
Validation loss decreased (0.100440 --> 0.099414).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.3016831874847412
Epoch: 34, Steps: 28 | Train Loss: 0.4699989 Vali Loss: 0.1016324 Test Loss: 0.1769352
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.29344701766967773
Epoch: 35, Steps: 28 | Train Loss: 0.4762900 Vali Loss: 0.1017238 Test Loss: 0.1769352
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.2968180179595947
Epoch: 36, Steps: 28 | Train Loss: 0.4697935 Vali Loss: 0.1032002 Test Loss: 0.1769352
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.2937278747558594
Epoch: 37, Steps: 28 | Train Loss: 0.4649249 Vali Loss: 0.1037171 Test Loss: 0.1769352
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.2976400852203369
Epoch: 38, Steps: 28 | Train Loss: 0.4679213 Vali Loss: 0.1035989 Test Loss: 0.1769352
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.2965729236602783
Epoch: 39, Steps: 28 | Train Loss: 0.4681047 Vali Loss: 0.0993339 Test Loss: 0.1769352
Validation loss decreased (0.099414 --> 0.099334).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.2960681915283203
Epoch: 40, Steps: 28 | Train Loss: 0.4718073 Vali Loss: 0.1012043 Test Loss: 0.1769352
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.29605770111083984
Epoch: 41, Steps: 28 | Train Loss: 0.4705221 Vali Loss: 0.1030329 Test Loss: 0.1769352
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.29636263847351074
Epoch: 42, Steps: 28 | Train Loss: 0.4632912 Vali Loss: 0.0993778 Test Loss: 0.1769352
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.2946305274963379
Epoch: 43, Steps: 28 | Train Loss: 0.4701693 Vali Loss: 0.1018299 Test Loss: 0.1769352
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.29696178436279297
Epoch: 44, Steps: 28 | Train Loss: 0.4750958 Vali Loss: 0.1088842 Test Loss: 0.1769352
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.2958376407623291
Epoch: 45, Steps: 28 | Train Loss: 0.4655784 Vali Loss: 0.1022872 Test Loss: 0.1769352
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 0.2947204113006592
Epoch: 46, Steps: 28 | Train Loss: 0.4642481 Vali Loss: 0.1041386 Test Loss: 0.1769352
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 47 cost time: 0.2961714267730713
Epoch: 47, Steps: 28 | Train Loss: 0.4692096 Vali Loss: 0.1045488 Test Loss: 0.1769352
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 48 cost time: 0.3074178695678711
Epoch: 48, Steps: 28 | Train Loss: 0.4691290 Vali Loss: 0.1037797 Test Loss: 0.1769352
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 49 cost time: 0.28702449798583984
Epoch: 49, Steps: 28 | Train Loss: 0.4696456 Vali Loss: 0.1034000 Test Loss: 0.1769352
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 50 cost time: 0.291994571685791
Epoch: 50, Steps: 28 | Train Loss: 0.4718267 Vali Loss: 0.0999517 Test Loss: 0.1769352
EarlyStopping counter: 11 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 51 cost time: 0.2918436527252197
Epoch: 51, Steps: 28 | Train Loss: 0.4702189 Vali Loss: 0.1066740 Test Loss: 0.1769352
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 52 cost time: 0.28690528869628906
Epoch: 52, Steps: 28 | Train Loss: 0.4627016 Vali Loss: 0.0990309 Test Loss: 0.1769352
Validation loss decreased (0.099334 --> 0.099031).  Saving model ...
Updating learning rate to 2.220446049250313e-19
Epoch: 53 cost time: 0.2929966449737549
Epoch: 53, Steps: 28 | Train Loss: 0.4633924 Vali Loss: 0.1021863 Test Loss: 0.1769352
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1102230246251566e-19
Epoch: 54 cost time: 0.2914571762084961
Epoch: 54, Steps: 28 | Train Loss: 0.4699604 Vali Loss: 0.1028550 Test Loss: 0.1769352
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.551115123125783e-20
Epoch: 55 cost time: 0.2868833541870117
Epoch: 55, Steps: 28 | Train Loss: 0.4711272 Vali Loss: 0.1020890 Test Loss: 0.1769352
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.7755575615628914e-20
Epoch: 56 cost time: 0.2879953384399414
Epoch: 56, Steps: 28 | Train Loss: 0.4719506 Vali Loss: 0.1004073 Test Loss: 0.1769352
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.3877787807814457e-20
Epoch: 57 cost time: 0.2905263900756836
Epoch: 57, Steps: 28 | Train Loss: 0.4647814 Vali Loss: 0.0997996 Test Loss: 0.1769352
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.938893903907229e-21
Epoch: 58 cost time: 0.28749632835388184
Epoch: 58, Steps: 28 | Train Loss: 0.4630947 Vali Loss: 0.1038382 Test Loss: 0.1769352
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.469446951953614e-21
Epoch: 59 cost time: 0.28759074211120605
Epoch: 59, Steps: 28 | Train Loss: 0.4672864 Vali Loss: 0.1040203 Test Loss: 0.1769352
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.734723475976807e-21
Epoch: 60 cost time: 0.2921919822692871
Epoch: 60, Steps: 28 | Train Loss: 0.4656060 Vali Loss: 0.1058160 Test Loss: 0.1769352
EarlyStopping counter: 8 out of 15
Updating learning rate to 8.673617379884036e-22
Epoch: 61 cost time: 0.28820228576660156
Epoch: 61, Steps: 28 | Train Loss: 0.4633023 Vali Loss: 0.1019832 Test Loss: 0.1769352
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.336808689942018e-22
Epoch: 62 cost time: 0.28699493408203125
Epoch: 62, Steps: 28 | Train Loss: 0.4691087 Vali Loss: 0.1001002 Test Loss: 0.1769352
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.168404344971009e-22
Epoch: 63 cost time: 0.2952876091003418
Epoch: 63, Steps: 28 | Train Loss: 0.4760844 Vali Loss: 0.1059494 Test Loss: 0.1769352
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.0842021724855045e-22
Epoch: 64 cost time: 0.2960383892059326
Epoch: 64, Steps: 28 | Train Loss: 0.4715408 Vali Loss: 0.1032487 Test Loss: 0.1769352
EarlyStopping counter: 12 out of 15
Updating learning rate to 5.421010862427522e-23
Epoch: 65 cost time: 0.2994856834411621
Epoch: 65, Steps: 28 | Train Loss: 0.4716054 Vali Loss: 0.1023393 Test Loss: 0.1769352
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.710505431213761e-23
Epoch: 66 cost time: 0.2934117317199707
Epoch: 66, Steps: 28 | Train Loss: 0.4687654 Vali Loss: 0.1050858 Test Loss: 0.1769352
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.3552527156068806e-23
Epoch: 67 cost time: 0.28709840774536133
Epoch: 67, Steps: 28 | Train Loss: 0.4704302 Vali Loss: 0.1025110 Test Loss: 0.1769352
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Crossformer_pl5_Crossformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1771, mae:0.3145, msIC:0.0108, msIR:0.0204
Total Evaluation 

MSE:0.1762Â±0.0007
MAE:0.3138Â±0.0005
msIC:0.0200Â±0.0095
msIR:0.0383Â±0.0182
  Evaluating Crossformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: TSMixer
  Training TSMixer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_TSMixer_pl5Model:              TSMixer             

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               64                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.10975027084350586
Epoch: 1, Steps: 28 | Train Loss: 0.6819669 Vali Loss: 0.1397874 Test Loss: 0.2127911
Validation loss decreased (inf --> 0.139787).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.03561973571777344
Epoch: 2, Steps: 28 | Train Loss: 0.5793399 Vali Loss: 0.1223344 Test Loss: 0.2025488
Validation loss decreased (0.139787 --> 0.122334).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.03510141372680664
Epoch: 3, Steps: 28 | Train Loss: 0.5302375 Vali Loss: 0.1213609 Test Loss: 0.1989928
Validation loss decreased (0.122334 --> 0.121361).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.048433542251586914
Epoch: 4, Steps: 28 | Train Loss: 0.5084607 Vali Loss: 0.1234881 Test Loss: 0.1974702
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.03395819664001465
Epoch: 5, Steps: 28 | Train Loss: 0.5078332 Vali Loss: 0.1184106 Test Loss: 0.1967441
Validation loss decreased (0.121361 --> 0.118411).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.03515172004699707
Epoch: 6, Steps: 28 | Train Loss: 0.5030370 Vali Loss: 0.1257725 Test Loss: 0.1964893
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.033808231353759766
Epoch: 7, Steps: 28 | Train Loss: 0.4936612 Vali Loss: 0.1225428 Test Loss: 0.1963280
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.036064863204956055
Epoch: 8, Steps: 28 | Train Loss: 0.4985180 Vali Loss: 0.1199460 Test Loss: 0.1962543
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.03504753112792969
Epoch: 9, Steps: 28 | Train Loss: 0.4922889 Vali Loss: 0.1177085 Test Loss: 0.1962090
Validation loss decreased (0.118411 --> 0.117708).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.03577613830566406
Epoch: 10, Steps: 28 | Train Loss: 0.4887738 Vali Loss: 0.1229918 Test Loss: 0.1961887
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.035582780838012695
Epoch: 11, Steps: 28 | Train Loss: 0.4998598 Vali Loss: 0.1221676 Test Loss: 0.1961777
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.03527116775512695
Epoch: 12, Steps: 28 | Train Loss: 0.4930884 Vali Loss: 0.1191237 Test Loss: 0.1961730
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.03423595428466797
Epoch: 13, Steps: 28 | Train Loss: 0.4992813 Vali Loss: 0.1228105 Test Loss: 0.1961699
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.03450274467468262
Epoch: 14, Steps: 28 | Train Loss: 0.4946886 Vali Loss: 0.1178228 Test Loss: 0.1961685
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.035707712173461914
Epoch: 15, Steps: 28 | Train Loss: 0.4953976 Vali Loss: 0.1199051 Test Loss: 0.1961679
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.03393244743347168
Epoch: 16, Steps: 28 | Train Loss: 0.4963517 Vali Loss: 0.1206902 Test Loss: 0.1961675
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.03481864929199219
Epoch: 17, Steps: 28 | Train Loss: 0.4929586 Vali Loss: 0.1172777 Test Loss: 0.1961673
Validation loss decreased (0.117708 --> 0.117278).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.03517556190490723
Epoch: 18, Steps: 28 | Train Loss: 0.4954966 Vali Loss: 0.1220527 Test Loss: 0.1961673
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.0343623161315918
Epoch: 19, Steps: 28 | Train Loss: 0.4984022 Vali Loss: 0.1218551 Test Loss: 0.1961673
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.03558015823364258
Epoch: 20, Steps: 28 | Train Loss: 0.4908048 Vali Loss: 0.1255920 Test Loss: 0.1961673
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.034787654876708984
Epoch: 21, Steps: 28 | Train Loss: 0.4864869 Vali Loss: 0.1205126 Test Loss: 0.1961673
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.03476977348327637
Epoch: 22, Steps: 28 | Train Loss: 0.4944863 Vali Loss: 0.1208411 Test Loss: 0.1961673
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.03418445587158203
Epoch: 23, Steps: 28 | Train Loss: 0.4918477 Vali Loss: 0.1183322 Test Loss: 0.1961673
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.03386664390563965
Epoch: 24, Steps: 28 | Train Loss: 0.4935523 Vali Loss: 0.1188495 Test Loss: 0.1961673
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.034302473068237305
Epoch: 25, Steps: 28 | Train Loss: 0.4964461 Vali Loss: 0.1165328 Test Loss: 0.1961673
Validation loss decreased (0.117278 --> 0.116533).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.03545784950256348
Epoch: 26, Steps: 28 | Train Loss: 0.4957238 Vali Loss: 0.1177088 Test Loss: 0.1961673
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.034737586975097656
Epoch: 27, Steps: 28 | Train Loss: 0.4856166 Vali Loss: 0.1168555 Test Loss: 0.1961673
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.03538179397583008
Epoch: 28, Steps: 28 | Train Loss: 0.4939240 Vali Loss: 0.1225431 Test Loss: 0.1961673
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.03534245491027832
Epoch: 29, Steps: 28 | Train Loss: 0.4944796 Vali Loss: 0.1180032 Test Loss: 0.1961673
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.034798383712768555
Epoch: 30, Steps: 28 | Train Loss: 0.4973733 Vali Loss: 0.1178334 Test Loss: 0.1961673
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.0347287654876709
Epoch: 31, Steps: 28 | Train Loss: 0.4947640 Vali Loss: 0.1230825 Test Loss: 0.1961673
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.035120248794555664
Epoch: 32, Steps: 28 | Train Loss: 0.4875277 Vali Loss: 0.1225066 Test Loss: 0.1961673
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.03512740135192871
Epoch: 33, Steps: 28 | Train Loss: 0.4977563 Vali Loss: 0.1223487 Test Loss: 0.1961673
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.03383278846740723
Epoch: 34, Steps: 28 | Train Loss: 0.4946421 Vali Loss: 0.1191667 Test Loss: 0.1961673
EarlyStopping counter: 9 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.03399300575256348
Epoch: 35, Steps: 28 | Train Loss: 0.4910848 Vali Loss: 0.1220442 Test Loss: 0.1961673
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.03414011001586914
Epoch: 36, Steps: 28 | Train Loss: 0.4895673 Vali Loss: 0.1199811 Test Loss: 0.1961673
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.033905029296875
Epoch: 37, Steps: 28 | Train Loss: 0.4896886 Vali Loss: 0.1165317 Test Loss: 0.1961673
Validation loss decreased (0.116533 --> 0.116532).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.03521728515625
Epoch: 38, Steps: 28 | Train Loss: 0.4996680 Vali Loss: 0.1232837 Test Loss: 0.1961673
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.03386044502258301
Epoch: 39, Steps: 28 | Train Loss: 0.4964815 Vali Loss: 0.1209231 Test Loss: 0.1961673
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.03550839424133301
Epoch: 40, Steps: 28 | Train Loss: 0.4930140 Vali Loss: 0.1206933 Test Loss: 0.1961673
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.03672456741333008
Epoch: 41, Steps: 28 | Train Loss: 0.4979674 Vali Loss: 0.1223875 Test Loss: 0.1961673
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.037809133529663086
Epoch: 42, Steps: 28 | Train Loss: 0.4946452 Vali Loss: 0.1206975 Test Loss: 0.1961673
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.2737367544323206e-16
Epoch: 43 cost time: 0.03535175323486328
Epoch: 43, Steps: 28 | Train Loss: 0.4928125 Vali Loss: 0.1175352 Test Loss: 0.1961673
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1368683772161603e-16
Epoch: 44 cost time: 0.03520703315734863
Epoch: 44, Steps: 28 | Train Loss: 0.4993102 Vali Loss: 0.1153836 Test Loss: 0.1961673
Validation loss decreased (0.116532 --> 0.115384).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 45 cost time: 0.03533124923706055
Epoch: 45, Steps: 28 | Train Loss: 0.4945833 Vali Loss: 0.1196498 Test Loss: 0.1961673
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.842170943040401e-17
Epoch: 46 cost time: 0.03511619567871094
Epoch: 46, Steps: 28 | Train Loss: 0.4940129 Vali Loss: 0.1204028 Test Loss: 0.1961673
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.4210854715202004e-17
Epoch: 47 cost time: 0.035927534103393555
Epoch: 47, Steps: 28 | Train Loss: 0.4985773 Vali Loss: 0.1223674 Test Loss: 0.1961673
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.105427357601002e-18
Epoch: 48 cost time: 0.03539633750915527
Epoch: 48, Steps: 28 | Train Loss: 0.4947557 Vali Loss: 0.1257051 Test Loss: 0.1961673
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.552713678800501e-18
Epoch: 49 cost time: 0.03290724754333496
Epoch: 49, Steps: 28 | Train Loss: 0.4930622 Vali Loss: 0.1206796 Test Loss: 0.1961673
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.7763568394002505e-18
Epoch: 50 cost time: 0.03302812576293945
Epoch: 50, Steps: 28 | Train Loss: 0.4978410 Vali Loss: 0.1198380 Test Loss: 0.1961673
EarlyStopping counter: 6 out of 15
Updating learning rate to 8.881784197001253e-19
Epoch: 51 cost time: 0.033003807067871094
Epoch: 51, Steps: 28 | Train Loss: 0.4974313 Vali Loss: 0.1173715 Test Loss: 0.1961673
EarlyStopping counter: 7 out of 15
Updating learning rate to 4.440892098500626e-19
Epoch: 52 cost time: 0.03356432914733887
Epoch: 52, Steps: 28 | Train Loss: 0.4942095 Vali Loss: 0.1227306 Test Loss: 0.1961673
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.220446049250313e-19
Epoch: 53 cost time: 0.03457069396972656
Epoch: 53, Steps: 28 | Train Loss: 0.4952721 Vali Loss: 0.1230537 Test Loss: 0.1961673
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.1102230246251566e-19
Epoch: 54 cost time: 0.0326688289642334
Epoch: 54, Steps: 28 | Train Loss: 0.4950579 Vali Loss: 0.1191792 Test Loss: 0.1961673
EarlyStopping counter: 10 out of 15
Updating learning rate to 5.551115123125783e-20
Epoch: 55 cost time: 0.031334638595581055
Epoch: 55, Steps: 28 | Train Loss: 0.4890460 Vali Loss: 0.1226979 Test Loss: 0.1961673
EarlyStopping counter: 11 out of 15
Updating learning rate to 2.7755575615628914e-20
Epoch: 56 cost time: 0.0313868522644043
Epoch: 56, Steps: 28 | Train Loss: 0.4974796 Vali Loss: 0.1182992 Test Loss: 0.1961673
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.3877787807814457e-20
Epoch: 57 cost time: 0.03289937973022461
Epoch: 57, Steps: 28 | Train Loss: 0.4878721 Vali Loss: 0.1199234 Test Loss: 0.1961673
EarlyStopping counter: 13 out of 15
Updating learning rate to 6.938893903907229e-21
Epoch: 58 cost time: 0.03245902061462402
Epoch: 58, Steps: 28 | Train Loss: 0.4961132 Vali Loss: 0.1176250 Test Loss: 0.1961673
EarlyStopping counter: 14 out of 15
Updating learning rate to 3.469446951953614e-21
Epoch: 59 cost time: 0.0312349796295166
Epoch: 59, Steps: 28 | Train Loss: 0.4981704 Vali Loss: 0.1224460 Test Loss: 0.1961673
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1964, mae:0.3368, msIC:-0.0072, msIR:-0.0145
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.03872179985046387
Epoch: 1, Steps: 28 | Train Loss: 0.8185002 Vali Loss: 0.1461523 Test Loss: 0.2241308
Validation loss decreased (inf --> 0.146152).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.03470468521118164
Epoch: 2, Steps: 28 | Train Loss: 0.6460996 Vali Loss: 0.1292259 Test Loss: 0.2067918
Validation loss decreased (0.146152 --> 0.129226).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.035928964614868164
Epoch: 3, Steps: 28 | Train Loss: 0.5787179 Vali Loss: 0.1201958 Test Loss: 0.2018345
Validation loss decreased (0.129226 --> 0.120196).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.036679983139038086
Epoch: 4, Steps: 28 | Train Loss: 0.5539458 Vali Loss: 0.1190007 Test Loss: 0.1996002
Validation loss decreased (0.120196 --> 0.119001).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.06588411331176758
Epoch: 5, Steps: 28 | Train Loss: 0.5419576 Vali Loss: 0.1198022 Test Loss: 0.1985721
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.03515195846557617
Epoch: 6, Steps: 28 | Train Loss: 0.5387801 Vali Loss: 0.1169484 Test Loss: 0.1980980
Validation loss decreased (0.119001 --> 0.116948).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.03696465492248535
Epoch: 7, Steps: 28 | Train Loss: 0.5348877 Vali Loss: 0.1192693 Test Loss: 0.1978550
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.03577780723571777
Epoch: 8, Steps: 28 | Train Loss: 0.5331552 Vali Loss: 0.1202838 Test Loss: 0.1977295
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.03487348556518555
Epoch: 9, Steps: 28 | Train Loss: 0.5348112 Vali Loss: 0.1205412 Test Loss: 0.1976689
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.03448033332824707
Epoch: 10, Steps: 28 | Train Loss: 0.5267755 Vali Loss: 0.1191819 Test Loss: 0.1976342
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.03400850296020508
Epoch: 11, Steps: 28 | Train Loss: 0.5307560 Vali Loss: 0.1197763 Test Loss: 0.1976176
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.035039424896240234
Epoch: 12, Steps: 28 | Train Loss: 0.5312590 Vali Loss: 0.1222821 Test Loss: 0.1976088
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.037564754486083984
Epoch: 13, Steps: 28 | Train Loss: 0.5294278 Vali Loss: 0.1169034 Test Loss: 0.1976044
Validation loss decreased (0.116948 --> 0.116903).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.033376216888427734
Epoch: 14, Steps: 28 | Train Loss: 0.5261117 Vali Loss: 0.1190552 Test Loss: 0.1976021
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.03330516815185547
Epoch: 15, Steps: 28 | Train Loss: 0.5302592 Vali Loss: 0.1225065 Test Loss: 0.1976010
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.03267788887023926
Epoch: 16, Steps: 28 | Train Loss: 0.5336971 Vali Loss: 0.1158819 Test Loss: 0.1976004
Validation loss decreased (0.116903 --> 0.115882).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.03333854675292969
Epoch: 17, Steps: 28 | Train Loss: 0.5320038 Vali Loss: 0.1188890 Test Loss: 0.1976002
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.03344917297363281
Epoch: 18, Steps: 28 | Train Loss: 0.5262444 Vali Loss: 0.1174680 Test Loss: 0.1976001
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.03326606750488281
Epoch: 19, Steps: 28 | Train Loss: 0.5300542 Vali Loss: 0.1193947 Test Loss: 0.1976000
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.032732248306274414
Epoch: 20, Steps: 28 | Train Loss: 0.5313289 Vali Loss: 0.1189965 Test Loss: 0.1976000
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.03151416778564453
Epoch: 21, Steps: 28 | Train Loss: 0.5269865 Vali Loss: 0.1212252 Test Loss: 0.1976001
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.03294062614440918
Epoch: 22, Steps: 28 | Train Loss: 0.5346574 Vali Loss: 0.1150669 Test Loss: 0.1976000
Validation loss decreased (0.115882 --> 0.115067).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.03341960906982422
Epoch: 23, Steps: 28 | Train Loss: 0.5288998 Vali Loss: 0.1176133 Test Loss: 0.1976000
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.03390836715698242
Epoch: 24, Steps: 28 | Train Loss: 0.5267607 Vali Loss: 0.1219364 Test Loss: 0.1976000
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.0333864688873291
Epoch: 25, Steps: 28 | Train Loss: 0.5329163 Vali Loss: 0.1175389 Test Loss: 0.1976000
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.033278465270996094
Epoch: 26, Steps: 28 | Train Loss: 0.5317256 Vali Loss: 0.1184691 Test Loss: 0.1976001
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.03332686424255371
Epoch: 27, Steps: 28 | Train Loss: 0.5328440 Vali Loss: 0.1172677 Test Loss: 0.1976001
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.03349041938781738
Epoch: 28, Steps: 28 | Train Loss: 0.5324887 Vali Loss: 0.1181716 Test Loss: 0.1976001
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.03350257873535156
Epoch: 29, Steps: 28 | Train Loss: 0.5305469 Vali Loss: 0.1182377 Test Loss: 0.1976001
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.0329434871673584
Epoch: 30, Steps: 28 | Train Loss: 0.5317885 Vali Loss: 0.1207031 Test Loss: 0.1976001
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.03311753273010254
Epoch: 31, Steps: 28 | Train Loss: 0.5333029 Vali Loss: 0.1195102 Test Loss: 0.1976001
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.03299236297607422
Epoch: 32, Steps: 28 | Train Loss: 0.5276227 Vali Loss: 0.1172865 Test Loss: 0.1976001
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.032662391662597656
Epoch: 33, Steps: 28 | Train Loss: 0.5305206 Vali Loss: 0.1258425 Test Loss: 0.1976001
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.03117060661315918
Epoch: 34, Steps: 28 | Train Loss: 0.5308182 Vali Loss: 0.1175502 Test Loss: 0.1976001
EarlyStopping counter: 12 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.031409502029418945
Epoch: 35, Steps: 28 | Train Loss: 0.5323505 Vali Loss: 0.1162710 Test Loss: 0.1976001
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.03275156021118164
Epoch: 36, Steps: 28 | Train Loss: 0.5351386 Vali Loss: 0.1204835 Test Loss: 0.1976001
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.0319058895111084
Epoch: 37, Steps: 28 | Train Loss: 0.5381620 Vali Loss: 0.1167526 Test Loss: 0.1976001
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1978, mae:0.3361, msIC:0.0028, msIR:0.0055
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.04240298271179199
Epoch: 1, Steps: 28 | Train Loss: 0.6437855 Vali Loss: 0.1351774 Test Loss: 0.2088957
Validation loss decreased (inf --> 0.135177).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.03280234336853027
Epoch: 2, Steps: 28 | Train Loss: 0.5326543 Vali Loss: 0.1238771 Test Loss: 0.1969579
Validation loss decreased (0.135177 --> 0.123877).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.03553152084350586
Epoch: 3, Steps: 28 | Train Loss: 0.4962424 Vali Loss: 0.1198319 Test Loss: 0.1943550
Validation loss decreased (0.123877 --> 0.119832).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.03618192672729492
Epoch: 4, Steps: 28 | Train Loss: 0.4850759 Vali Loss: 0.1175241 Test Loss: 0.1931662
Validation loss decreased (0.119832 --> 0.117524).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.03648567199707031
Epoch: 5, Steps: 28 | Train Loss: 0.4844039 Vali Loss: 0.1158338 Test Loss: 0.1927507
Validation loss decreased (0.117524 --> 0.115834).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.03612852096557617
Epoch: 6, Steps: 28 | Train Loss: 0.4768868 Vali Loss: 0.1172538 Test Loss: 0.1924486
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.03395485877990723
Epoch: 7, Steps: 28 | Train Loss: 0.4771175 Vali Loss: 0.1197792 Test Loss: 0.1923462
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.03406047821044922
Epoch: 8, Steps: 28 | Train Loss: 0.4766529 Vali Loss: 0.1203322 Test Loss: 0.1922698
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.03438115119934082
Epoch: 9, Steps: 28 | Train Loss: 0.4718087 Vali Loss: 0.1164704 Test Loss: 0.1922328
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.034230709075927734
Epoch: 10, Steps: 28 | Train Loss: 0.4781164 Vali Loss: 0.1209671 Test Loss: 0.1922171
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.034342050552368164
Epoch: 11, Steps: 28 | Train Loss: 0.4731862 Vali Loss: 0.1207323 Test Loss: 0.1922086
EarlyStopping counter: 6 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.03402090072631836
Epoch: 12, Steps: 28 | Train Loss: 0.4746145 Vali Loss: 0.1169943 Test Loss: 0.1922040
EarlyStopping counter: 7 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.03429865837097168
Epoch: 13, Steps: 28 | Train Loss: 0.4808062 Vali Loss: 0.1165101 Test Loss: 0.1922015
EarlyStopping counter: 8 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.03490447998046875
Epoch: 14, Steps: 28 | Train Loss: 0.4720196 Vali Loss: 0.1230175 Test Loss: 0.1922005
EarlyStopping counter: 9 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.0354769229888916
Epoch: 15, Steps: 28 | Train Loss: 0.4773632 Vali Loss: 0.1202695 Test Loss: 0.1921999
EarlyStopping counter: 10 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.03260302543640137
Epoch: 16, Steps: 28 | Train Loss: 0.4755799 Vali Loss: 0.1163085 Test Loss: 0.1921996
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.03304147720336914
Epoch: 17, Steps: 28 | Train Loss: 0.4837068 Vali Loss: 0.1198923 Test Loss: 0.1921995
EarlyStopping counter: 12 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.03292393684387207
Epoch: 18, Steps: 28 | Train Loss: 0.4767406 Vali Loss: 0.1201904 Test Loss: 0.1921995
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.03186750411987305
Epoch: 19, Steps: 28 | Train Loss: 0.4754539 Vali Loss: 0.1173919 Test Loss: 0.1921995
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.03301858901977539
Epoch: 20, Steps: 28 | Train Loss: 0.4800632 Vali Loss: 0.1218625 Test Loss: 0.1921995
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_TSMixer_pl5_TSMixer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df64_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1929, mae:0.3326, msIC:-0.0437, msIR:-0.0864
Total Evaluation 

MSE:0.1957Â±0.0020
MAE:0.3352Â±0.0018
msIC:-0.0160Â±0.0200
msIR:-0.0318Â±0.0395
  Evaluating TSMixer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: Koopa
  Training Koopa...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Koopa_pl5Model:              Koopa               

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.001               
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 888
>>>>>>>start training : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 2.0471301078796387
Epoch: 1, Steps: 28 | Train Loss: 0.4944000 Vali Loss: 0.1065382 Test Loss: 0.1965638
Validation loss decreased (inf --> 0.106538).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.8619036674499512
Epoch: 2, Steps: 28 | Train Loss: 0.4429059 Vali Loss: 0.1053829 Test Loss: 0.1899197
Validation loss decreased (0.106538 --> 0.105383).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.8589317798614502
Epoch: 3, Steps: 28 | Train Loss: 0.4207308 Vali Loss: 0.1009688 Test Loss: 0.1868484
Validation loss decreased (0.105383 --> 0.100969).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.8539533615112305
Epoch: 4, Steps: 28 | Train Loss: 0.4061142 Vali Loss: 0.1041540 Test Loss: 0.1872901
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.8551115989685059
Epoch: 5, Steps: 28 | Train Loss: 0.3992817 Vali Loss: 0.1062818 Test Loss: 0.1874120
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.8654210567474365
Epoch: 6, Steps: 28 | Train Loss: 0.3936954 Vali Loss: 0.1070556 Test Loss: 0.1878862
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.8591673374176025
Epoch: 7, Steps: 28 | Train Loss: 0.3956267 Vali Loss: 0.1037664 Test Loss: 0.1881642
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.8636763095855713
Epoch: 8, Steps: 28 | Train Loss: 0.3944620 Vali Loss: 0.1053764 Test Loss: 0.1881655
EarlyStopping counter: 5 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.8652005195617676
Epoch: 9, Steps: 28 | Train Loss: 0.3960073 Vali Loss: 0.1045971 Test Loss: 0.1882022
EarlyStopping counter: 6 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.8596513271331787
Epoch: 10, Steps: 28 | Train Loss: 0.3950428 Vali Loss: 0.1034792 Test Loss: 0.1882413
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.8625097274780273
Epoch: 11, Steps: 28 | Train Loss: 0.3948150 Vali Loss: 0.1053623 Test Loss: 0.1882676
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.8603134155273438
Epoch: 12, Steps: 28 | Train Loss: 0.3921119 Vali Loss: 0.1009785 Test Loss: 0.1882780
EarlyStopping counter: 9 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.8612778186798096
Epoch: 13, Steps: 28 | Train Loss: 0.3942291 Vali Loss: 0.1023268 Test Loss: 0.1882779
EarlyStopping counter: 10 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.8619499206542969
Epoch: 14, Steps: 28 | Train Loss: 0.3947308 Vali Loss: 0.1050811 Test Loss: 0.1882783
EarlyStopping counter: 11 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.8598864078521729
Epoch: 15, Steps: 28 | Train Loss: 0.3931144 Vali Loss: 0.1063306 Test Loss: 0.1882780
EarlyStopping counter: 12 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.8634819984436035
Epoch: 16, Steps: 28 | Train Loss: 0.3962735 Vali Loss: 0.1033963 Test Loss: 0.1882777
EarlyStopping counter: 13 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.8632564544677734
Epoch: 17, Steps: 28 | Train Loss: 0.3911688 Vali Loss: 0.1063397 Test Loss: 0.1882775
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.8604307174682617
Epoch: 18, Steps: 28 | Train Loss: 0.3942697 Vali Loss: 0.1046542 Test Loss: 0.1882775
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1871, mae:0.3282, msIC:0.0139, msIR:0.0272
Use GPU: cuda:0
train 888
>>>>>>>start training : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.864393949508667
Epoch: 1, Steps: 28 | Train Loss: 0.4774010 Vali Loss: 0.1052974 Test Loss: 0.1882805
Validation loss decreased (inf --> 0.105297).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.8591220378875732
Epoch: 2, Steps: 28 | Train Loss: 0.4430130 Vali Loss: 0.1077377 Test Loss: 0.1768907
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.862779140472412
Epoch: 3, Steps: 28 | Train Loss: 0.4200461 Vali Loss: 0.1018451 Test Loss: 0.1759770
Validation loss decreased (0.105297 --> 0.101845).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.8604800701141357
Epoch: 4, Steps: 28 | Train Loss: 0.4043669 Vali Loss: 0.1038983 Test Loss: 0.1761477
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.8614258766174316
Epoch: 5, Steps: 28 | Train Loss: 0.3968611 Vali Loss: 0.1059414 Test Loss: 0.1767505
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.859220266342163
Epoch: 6, Steps: 28 | Train Loss: 0.3954773 Vali Loss: 0.1050591 Test Loss: 0.1772089
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.8574306964874268
Epoch: 7, Steps: 28 | Train Loss: 0.3924296 Vali Loss: 0.1001332 Test Loss: 0.1771937
Validation loss decreased (0.101845 --> 0.100133).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.8594775199890137
Epoch: 8, Steps: 28 | Train Loss: 0.3920990 Vali Loss: 0.1052580 Test Loss: 0.1773021
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.853104829788208
Epoch: 9, Steps: 28 | Train Loss: 0.3946700 Vali Loss: 0.1028381 Test Loss: 0.1772933
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.8525140285491943
Epoch: 10, Steps: 28 | Train Loss: 0.3921821 Vali Loss: 0.1005200 Test Loss: 0.1772976
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.854912281036377
Epoch: 11, Steps: 28 | Train Loss: 0.3921266 Vali Loss: 0.1066460 Test Loss: 0.1772964
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.85378098487854
Epoch: 12, Steps: 28 | Train Loss: 0.3928211 Vali Loss: 0.1006562 Test Loss: 0.1773053
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.8620092868804932
Epoch: 13, Steps: 28 | Train Loss: 0.3890555 Vali Loss: 0.1056732 Test Loss: 0.1773059
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.8572170734405518
Epoch: 14, Steps: 28 | Train Loss: 0.3902335 Vali Loss: 0.1013369 Test Loss: 0.1773051
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.8569891452789307
Epoch: 15, Steps: 28 | Train Loss: 0.3928776 Vali Loss: 0.1034826 Test Loss: 0.1773044
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.8600943088531494
Epoch: 16, Steps: 28 | Train Loss: 0.3922592 Vali Loss: 0.1018362 Test Loss: 0.1773043
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.8600692749023438
Epoch: 17, Steps: 28 | Train Loss: 0.3919862 Vali Loss: 0.1037696 Test Loss: 0.1773046
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.861269235610962
Epoch: 18, Steps: 28 | Train Loss: 0.3912716 Vali Loss: 0.1028799 Test Loss: 0.1773047
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.8561112880706787
Epoch: 19, Steps: 28 | Train Loss: 0.3901905 Vali Loss: 0.1010249 Test Loss: 0.1773047
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.8594951629638672
Epoch: 20, Steps: 28 | Train Loss: 0.3879032 Vali Loss: 0.1054958 Test Loss: 0.1773047
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.8577642440795898
Epoch: 21, Steps: 28 | Train Loss: 0.3916586 Vali Loss: 0.1037309 Test Loss: 0.1773047
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.8578414916992188
Epoch: 22, Steps: 28 | Train Loss: 0.3916724 Vali Loss: 0.1042785 Test Loss: 0.1773047
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1774, mae:0.3181, msIC:0.0372, msIR:0.0758
Use GPU: cuda:0
train 888
>>>>>>>start training : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 1.8624284267425537
Epoch: 1, Steps: 28 | Train Loss: 0.4681553 Vali Loss: 0.1049424 Test Loss: 0.1852222
Validation loss decreased (inf --> 0.104942).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.8636085987091064
Epoch: 2, Steps: 28 | Train Loss: 0.4327935 Vali Loss: 0.1050502 Test Loss: 0.1799522
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.861595630645752
Epoch: 3, Steps: 28 | Train Loss: 0.4121076 Vali Loss: 0.1019652 Test Loss: 0.1803283
Validation loss decreased (0.104942 --> 0.101965).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.8634033203125
Epoch: 4, Steps: 28 | Train Loss: 0.3969787 Vali Loss: 0.1015705 Test Loss: 0.1806195
Validation loss decreased (0.101965 --> 0.101570).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.8603777885437012
Epoch: 5, Steps: 28 | Train Loss: 0.3963144 Vali Loss: 0.1036647 Test Loss: 0.1796792
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.8633902072906494
Epoch: 6, Steps: 28 | Train Loss: 0.3901199 Vali Loss: 0.1041257 Test Loss: 0.1798865
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.8619968891143799
Epoch: 7, Steps: 28 | Train Loss: 0.3877775 Vali Loss: 0.0991368 Test Loss: 0.1801668
Validation loss decreased (0.101570 --> 0.099137).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.8496952056884766
Epoch: 8, Steps: 28 | Train Loss: 0.3861575 Vali Loss: 0.1027791 Test Loss: 0.1802329
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.8635773658752441
Epoch: 9, Steps: 28 | Train Loss: 0.3868297 Vali Loss: 0.1027656 Test Loss: 0.1802464
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.8611690998077393
Epoch: 10, Steps: 28 | Train Loss: 0.3861220 Vali Loss: 0.1074903 Test Loss: 0.1802455
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.8616783618927002
Epoch: 11, Steps: 28 | Train Loss: 0.3870422 Vali Loss: 0.1045261 Test Loss: 0.1802337
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.8654732704162598
Epoch: 12, Steps: 28 | Train Loss: 0.3836383 Vali Loss: 0.1031712 Test Loss: 0.1802485
EarlyStopping counter: 5 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.860489845275879
Epoch: 13, Steps: 28 | Train Loss: 0.3854567 Vali Loss: 0.1004739 Test Loss: 0.1802472
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.8613877296447754
Epoch: 14, Steps: 28 | Train Loss: 0.3868774 Vali Loss: 0.1045775 Test Loss: 0.1802491
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.8592638969421387
Epoch: 15, Steps: 28 | Train Loss: 0.3877426 Vali Loss: 0.1025234 Test Loss: 0.1802499
EarlyStopping counter: 8 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.8579750061035156
Epoch: 16, Steps: 28 | Train Loss: 0.3870117 Vali Loss: 0.1034966 Test Loss: 0.1802497
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.862083911895752
Epoch: 17, Steps: 28 | Train Loss: 0.3856738 Vali Loss: 0.1030203 Test Loss: 0.1802497
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.8583896160125732
Epoch: 18, Steps: 28 | Train Loss: 0.3857987 Vali Loss: 0.1040077 Test Loss: 0.1802499
EarlyStopping counter: 11 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.8621938228607178
Epoch: 19, Steps: 28 | Train Loss: 0.3877214 Vali Loss: 0.1043159 Test Loss: 0.1802499
EarlyStopping counter: 12 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.8615796566009521
Epoch: 20, Steps: 28 | Train Loss: 0.3879552 Vali Loss: 0.1035923 Test Loss: 0.1802499
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.8529729843139648
Epoch: 21, Steps: 28 | Train Loss: 0.3865776 Vali Loss: 0.1065486 Test Loss: 0.1802499
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.860058307647705
Epoch: 22, Steps: 28 | Train Loss: 0.3878297 Vali Loss: 0.1056573 Test Loss: 0.1802498
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Koopa_pl5_Koopa_custom_ftMS_sl128_ll48_pl5_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1803, mae:0.3199, msIC:0.0097, msIR:0.0214
Total Evaluation 

MSE:0.1816Â±0.0041
MAE:0.3221Â±0.0044
msIC:0.0203Â±0.0121
msIR:0.0415Â±0.0244
  Evaluating Koopa results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

[POST_COVID] Model: Nonstationary_Transformer
  Training Nonstationary_Transformer...
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           POST_COVID_Nonstationary_Transformer_pl5Model:              Nonstationary_Transformer

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/FBD/      
  Data Path:          WTI-log-2020.csv    Features:           MS                  
  Target:             daily_return        Freq:               d                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            128                 Label Len:          48                  
  Pred Len:           5                   Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             6                   Dec In:             6                   
  C Out:              1                   d model:            32                  
  n heads:            4                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.3                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                3                   
  Train Epochs:       100                 Batch Size:         32                  
  Patience:           15                  Learning Rate:      0.0005              
  Des:                POST_COVID          Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      256, 256            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.4327428340911865
Epoch: 1, Steps: 28 | Train Loss: 0.5485721 Vali Loss: 0.1062340 Test Loss: 0.1814914
Validation loss decreased (inf --> 0.106234).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.18082857131958008
Epoch: 2, Steps: 28 | Train Loss: 0.4894111 Vali Loss: 0.1020658 Test Loss: 0.1758031
Validation loss decreased (0.106234 --> 0.102066).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.18551921844482422
Epoch: 3, Steps: 28 | Train Loss: 0.4726445 Vali Loss: 0.1027541 Test Loss: 0.1755593
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.13004851341247559
Epoch: 4, Steps: 28 | Train Loss: 0.4592177 Vali Loss: 0.1063995 Test Loss: 0.1753538
EarlyStopping counter: 2 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.13025426864624023
Epoch: 5, Steps: 28 | Train Loss: 0.4637846 Vali Loss: 0.1016734 Test Loss: 0.1754382
Validation loss decreased (0.102066 --> 0.101673).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.1588301658630371
Epoch: 6, Steps: 28 | Train Loss: 0.4658727 Vali Loss: 0.1034987 Test Loss: 0.1753058
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.13042116165161133
Epoch: 7, Steps: 28 | Train Loss: 0.4629438 Vali Loss: 0.1033427 Test Loss: 0.1753014
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.13230419158935547
Epoch: 8, Steps: 28 | Train Loss: 0.4647165 Vali Loss: 0.1033877 Test Loss: 0.1753069
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.13070297241210938
Epoch: 9, Steps: 28 | Train Loss: 0.4597863 Vali Loss: 0.1049312 Test Loss: 0.1752898
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.1307811737060547
Epoch: 10, Steps: 28 | Train Loss: 0.4635470 Vali Loss: 0.1016546 Test Loss: 0.1752833
Validation loss decreased (0.101673 --> 0.101655).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.15873456001281738
Epoch: 11, Steps: 28 | Train Loss: 0.4663850 Vali Loss: 0.1026091 Test Loss: 0.1752879
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.1306774616241455
Epoch: 12, Steps: 28 | Train Loss: 0.4599287 Vali Loss: 0.1031685 Test Loss: 0.1752878
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.13070392608642578
Epoch: 13, Steps: 28 | Train Loss: 0.4604398 Vali Loss: 0.1021307 Test Loss: 0.1752878
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.13081908226013184
Epoch: 14, Steps: 28 | Train Loss: 0.4627481 Vali Loss: 0.1082293 Test Loss: 0.1752878
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.13165903091430664
Epoch: 15, Steps: 28 | Train Loss: 0.4675924 Vali Loss: 0.1003347 Test Loss: 0.1752879
Validation loss decreased (0.101655 --> 0.100335).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.15821170806884766
Epoch: 16, Steps: 28 | Train Loss: 0.4628587 Vali Loss: 0.0997378 Test Loss: 0.1752877
Validation loss decreased (0.100335 --> 0.099738).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.18163824081420898
Epoch: 17, Steps: 28 | Train Loss: 0.4716817 Vali Loss: 0.0998421 Test Loss: 0.1752877
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.1305990219116211
Epoch: 18, Steps: 28 | Train Loss: 0.4598471 Vali Loss: 0.1006783 Test Loss: 0.1752878
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.13060379028320312
Epoch: 19, Steps: 28 | Train Loss: 0.4580992 Vali Loss: 0.1033041 Test Loss: 0.1752878
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.13240575790405273
Epoch: 20, Steps: 28 | Train Loss: 0.4608265 Vali Loss: 0.0988087 Test Loss: 0.1752878
Validation loss decreased (0.099738 --> 0.098809).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.15654897689819336
Epoch: 21, Steps: 28 | Train Loss: 0.4655254 Vali Loss: 0.1041253 Test Loss: 0.1752878
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.13059210777282715
Epoch: 22, Steps: 28 | Train Loss: 0.4671244 Vali Loss: 0.1049574 Test Loss: 0.1752878
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13081073760986328
Epoch: 23, Steps: 28 | Train Loss: 0.4602422 Vali Loss: 0.1047082 Test Loss: 0.1752878
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.1306757926940918
Epoch: 24, Steps: 28 | Train Loss: 0.4613242 Vali Loss: 0.1033810 Test Loss: 0.1752878
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.16754937171936035
Epoch: 25, Steps: 28 | Train Loss: 0.4674346 Vali Loss: 0.1011513 Test Loss: 0.1752878
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13759183883666992
Epoch: 26, Steps: 28 | Train Loss: 0.4650053 Vali Loss: 0.1056620 Test Loss: 0.1752878
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13096213340759277
Epoch: 27, Steps: 28 | Train Loss: 0.4597066 Vali Loss: 0.1009946 Test Loss: 0.1752878
EarlyStopping counter: 7 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.1306612491607666
Epoch: 28, Steps: 28 | Train Loss: 0.4576782 Vali Loss: 0.1014400 Test Loss: 0.1752878
EarlyStopping counter: 8 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.1304783821105957
Epoch: 29, Steps: 28 | Train Loss: 0.4587320 Vali Loss: 0.0997264 Test Loss: 0.1752878
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.13065600395202637
Epoch: 30, Steps: 28 | Train Loss: 0.4625965 Vali Loss: 0.1024978 Test Loss: 0.1752878
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.13287353515625
Epoch: 31, Steps: 28 | Train Loss: 0.4695530 Vali Loss: 0.1043787 Test Loss: 0.1752878
EarlyStopping counter: 11 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.16899800300598145
Epoch: 32, Steps: 28 | Train Loss: 0.4646455 Vali Loss: 0.1042957 Test Loss: 0.1752878
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.1340951919555664
Epoch: 33, Steps: 28 | Train Loss: 0.4643639 Vali Loss: 0.1007790 Test Loss: 0.1752878
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.2495896816253662
Epoch: 34, Steps: 28 | Train Loss: 0.4612881 Vali Loss: 0.0998525 Test Loss: 0.1752878
EarlyStopping counter: 14 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.2681276798248291
Epoch: 35, Steps: 28 | Train Loss: 0.4637464 Vali Loss: 0.1003468 Test Loss: 0.1752878
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1755, mae:0.3147, msIC:0.0296, msIR:0.0606
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.1561412811279297
Epoch: 1, Steps: 28 | Train Loss: 0.5407105 Vali Loss: 0.1048487 Test Loss: 0.1773215
Validation loss decreased (inf --> 0.104849).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.19358563423156738
Epoch: 2, Steps: 28 | Train Loss: 0.4861113 Vali Loss: 0.1020695 Test Loss: 0.1764115
Validation loss decreased (0.104849 --> 0.102069).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.1765763759613037
Epoch: 3, Steps: 28 | Train Loss: 0.4756550 Vali Loss: 0.1010725 Test Loss: 0.1751883
Validation loss decreased (0.102069 --> 0.101072).  Saving model ...
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.2600984573364258
Epoch: 4, Steps: 28 | Train Loss: 0.4611556 Vali Loss: 0.1045539 Test Loss: 0.1754691
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.18562626838684082
Epoch: 5, Steps: 28 | Train Loss: 0.4637958 Vali Loss: 0.1054674 Test Loss: 0.1754101
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.15470027923583984
Epoch: 6, Steps: 28 | Train Loss: 0.4567007 Vali Loss: 0.0993009 Test Loss: 0.1752445
Validation loss decreased (0.101072 --> 0.099301).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.19243955612182617
Epoch: 7, Steps: 28 | Train Loss: 0.4624074 Vali Loss: 0.1019200 Test Loss: 0.1752061
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.14561891555786133
Epoch: 8, Steps: 28 | Train Loss: 0.4657860 Vali Loss: 0.0984297 Test Loss: 0.1752636
Validation loss decreased (0.099301 --> 0.098430).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.153578519821167
Epoch: 9, Steps: 28 | Train Loss: 0.4630425 Vali Loss: 0.1016853 Test Loss: 0.1752726
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.1331031322479248
Epoch: 10, Steps: 28 | Train Loss: 0.4568947 Vali Loss: 0.0999846 Test Loss: 0.1752758
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.1310718059539795
Epoch: 11, Steps: 28 | Train Loss: 0.4604676 Vali Loss: 0.1005773 Test Loss: 0.1752772
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.13154149055480957
Epoch: 12, Steps: 28 | Train Loss: 0.4646911 Vali Loss: 0.1005425 Test Loss: 0.1752771
EarlyStopping counter: 4 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.1405644416809082
Epoch: 13, Steps: 28 | Train Loss: 0.4616963 Vali Loss: 0.0983637 Test Loss: 0.1752779
Validation loss decreased (0.098430 --> 0.098364).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.15967583656311035
Epoch: 14, Steps: 28 | Train Loss: 0.4583153 Vali Loss: 0.1068725 Test Loss: 0.1752785
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.13107967376708984
Epoch: 15, Steps: 28 | Train Loss: 0.4647111 Vali Loss: 0.1010094 Test Loss: 0.1752789
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.15035367012023926
Epoch: 16, Steps: 28 | Train Loss: 0.4566733 Vali Loss: 0.1022433 Test Loss: 0.1752790
EarlyStopping counter: 3 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.13108539581298828
Epoch: 17, Steps: 28 | Train Loss: 0.4618434 Vali Loss: 0.1033726 Test Loss: 0.1752790
EarlyStopping counter: 4 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13112950325012207
Epoch: 18, Steps: 28 | Train Loss: 0.4607765 Vali Loss: 0.1011963 Test Loss: 0.1752790
EarlyStopping counter: 5 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.1668710708618164
Epoch: 19, Steps: 28 | Train Loss: 0.4614395 Vali Loss: 0.1007196 Test Loss: 0.1752790
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.17095398902893066
Epoch: 20, Steps: 28 | Train Loss: 0.4630349 Vali Loss: 0.1003195 Test Loss: 0.1752790
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.13207292556762695
Epoch: 21, Steps: 28 | Train Loss: 0.4532681 Vali Loss: 0.1026181 Test Loss: 0.1752790
EarlyStopping counter: 8 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.1725766658782959
Epoch: 22, Steps: 28 | Train Loss: 0.4643786 Vali Loss: 0.0999142 Test Loss: 0.1752790
EarlyStopping counter: 9 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.13098573684692383
Epoch: 23, Steps: 28 | Train Loss: 0.4605573 Vali Loss: 0.1027371 Test Loss: 0.1752790
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.13100695610046387
Epoch: 24, Steps: 28 | Train Loss: 0.4625284 Vali Loss: 0.1028925 Test Loss: 0.1752790
EarlyStopping counter: 11 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.13192009925842285
Epoch: 25, Steps: 28 | Train Loss: 0.4599354 Vali Loss: 0.1006583 Test Loss: 0.1752790
EarlyStopping counter: 12 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13525104522705078
Epoch: 26, Steps: 28 | Train Loss: 0.4586029 Vali Loss: 0.1010955 Test Loss: 0.1752790
EarlyStopping counter: 13 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13138508796691895
Epoch: 27, Steps: 28 | Train Loss: 0.4599879 Vali Loss: 0.0982899 Test Loss: 0.1752790
Validation loss decreased (0.098364 --> 0.098290).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.20149803161621094
Epoch: 28, Steps: 28 | Train Loss: 0.4611738 Vali Loss: 0.1057178 Test Loss: 0.1752790
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.15433144569396973
Epoch: 29, Steps: 28 | Train Loss: 0.4605704 Vali Loss: 0.1046161 Test Loss: 0.1752790
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.16888093948364258
Epoch: 30, Steps: 28 | Train Loss: 0.4601470 Vali Loss: 0.1025011 Test Loss: 0.1752790
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.23116469383239746
Epoch: 31, Steps: 28 | Train Loss: 0.4606436 Vali Loss: 0.1032851 Test Loss: 0.1752790
EarlyStopping counter: 4 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.27252745628356934
Epoch: 32, Steps: 28 | Train Loss: 0.4547567 Vali Loss: 0.0997546 Test Loss: 0.1752790
EarlyStopping counter: 5 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.27684521675109863
Epoch: 33, Steps: 28 | Train Loss: 0.4663838 Vali Loss: 0.1015621 Test Loss: 0.1752790
EarlyStopping counter: 6 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.25264549255371094
Epoch: 34, Steps: 28 | Train Loss: 0.4616506 Vali Loss: 0.1012051 Test Loss: 0.1752790
EarlyStopping counter: 7 out of 15
Updating learning rate to 5.820766091346741e-14
Epoch: 35 cost time: 0.13851380348205566
Epoch: 35, Steps: 28 | Train Loss: 0.4612351 Vali Loss: 0.0987768 Test Loss: 0.1752790
EarlyStopping counter: 8 out of 15
Updating learning rate to 2.9103830456733704e-14
Epoch: 36 cost time: 0.16324472427368164
Epoch: 36, Steps: 28 | Train Loss: 0.4599446 Vali Loss: 0.0986130 Test Loss: 0.1752790
EarlyStopping counter: 9 out of 15
Updating learning rate to 1.4551915228366852e-14
Epoch: 37 cost time: 0.13546347618103027
Epoch: 37, Steps: 28 | Train Loss: 0.4580459 Vali Loss: 0.1021907 Test Loss: 0.1752790
EarlyStopping counter: 10 out of 15
Updating learning rate to 7.275957614183426e-15
Epoch: 38 cost time: 0.1346724033355713
Epoch: 38, Steps: 28 | Train Loss: 0.4591627 Vali Loss: 0.1002952 Test Loss: 0.1752790
EarlyStopping counter: 11 out of 15
Updating learning rate to 3.637978807091713e-15
Epoch: 39 cost time: 0.16721105575561523
Epoch: 39, Steps: 28 | Train Loss: 0.4624182 Vali Loss: 0.1012660 Test Loss: 0.1752790
EarlyStopping counter: 12 out of 15
Updating learning rate to 1.8189894035458565e-15
Epoch: 40 cost time: 0.1353764533996582
Epoch: 40, Steps: 28 | Train Loss: 0.4610362 Vali Loss: 0.1055976 Test Loss: 0.1752790
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.094947017729283e-16
Epoch: 41 cost time: 0.20229554176330566
Epoch: 41, Steps: 28 | Train Loss: 0.4665034 Vali Loss: 0.1006153 Test Loss: 0.1752790
EarlyStopping counter: 14 out of 15
Updating learning rate to 4.547473508864641e-16
Epoch: 42 cost time: 0.13209962844848633
Epoch: 42, Steps: 28 | Train Loss: 0.4623834 Vali Loss: 0.1026206 Test Loss: 0.1752790
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1755, mae:0.3136, msIC:0.0278, msIR:0.0583
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 888
val 143
test 287
Epoch: 1 cost time: 0.21659517288208008
Epoch: 1, Steps: 28 | Train Loss: 0.5489545 Vali Loss: 0.1110005 Test Loss: 0.1814594
Validation loss decreased (inf --> 0.111001).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.2160351276397705
Epoch: 2, Steps: 28 | Train Loss: 0.4772577 Vali Loss: 0.1059116 Test Loss: 0.1785512
Validation loss decreased (0.111001 --> 0.105912).  Saving model ...
Updating learning rate to 0.00025
Epoch: 3 cost time: 0.17427682876586914
Epoch: 3, Steps: 28 | Train Loss: 0.4588802 Vali Loss: 0.1071475 Test Loss: 0.1769928
EarlyStopping counter: 1 out of 15
Updating learning rate to 0.000125
Epoch: 4 cost time: 0.16738224029541016
Epoch: 4, Steps: 28 | Train Loss: 0.4622541 Vali Loss: 0.1047526 Test Loss: 0.1772902
Validation loss decreased (0.105912 --> 0.104753).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 5 cost time: 0.25402379035949707
Epoch: 5, Steps: 28 | Train Loss: 0.4539816 Vali Loss: 0.1067301 Test Loss: 0.1767655
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.125e-05
Epoch: 6 cost time: 0.27777552604675293
Epoch: 6, Steps: 28 | Train Loss: 0.4488557 Vali Loss: 0.1032716 Test Loss: 0.1767014
Validation loss decreased (0.104753 --> 0.103272).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 7 cost time: 0.19325971603393555
Epoch: 7, Steps: 28 | Train Loss: 0.4526046 Vali Loss: 0.1033734 Test Loss: 0.1768122
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.8125e-06
Epoch: 8 cost time: 0.13168716430664062
Epoch: 8, Steps: 28 | Train Loss: 0.4523507 Vali Loss: 0.1092070 Test Loss: 0.1767315
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.90625e-06
Epoch: 9 cost time: 0.15441155433654785
Epoch: 9, Steps: 28 | Train Loss: 0.4516773 Vali Loss: 0.1023860 Test Loss: 0.1767041
Validation loss decreased (0.103272 --> 0.102386).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 10 cost time: 0.20632123947143555
Epoch: 10, Steps: 28 | Train Loss: 0.4516957 Vali Loss: 0.1044345 Test Loss: 0.1766935
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.765625e-07
Epoch: 11 cost time: 0.13187766075134277
Epoch: 11, Steps: 28 | Train Loss: 0.4522098 Vali Loss: 0.1022364 Test Loss: 0.1766868
Validation loss decreased (0.102386 --> 0.102236).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 12 cost time: 0.18353939056396484
Epoch: 12, Steps: 28 | Train Loss: 0.4476565 Vali Loss: 0.1056705 Test Loss: 0.1766845
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.44140625e-07
Epoch: 13 cost time: 0.13175082206726074
Epoch: 13, Steps: 28 | Train Loss: 0.4522258 Vali Loss: 0.1066373 Test Loss: 0.1766831
EarlyStopping counter: 2 out of 15
Updating learning rate to 1.220703125e-07
Epoch: 14 cost time: 0.13930630683898926
Epoch: 14, Steps: 28 | Train Loss: 0.4524640 Vali Loss: 0.1038035 Test Loss: 0.1766831
EarlyStopping counter: 3 out of 15
Updating learning rate to 6.103515625e-08
Epoch: 15 cost time: 0.1312103271484375
Epoch: 15, Steps: 28 | Train Loss: 0.4567235 Vali Loss: 0.1054926 Test Loss: 0.1766828
EarlyStopping counter: 4 out of 15
Updating learning rate to 3.0517578125e-08
Epoch: 16 cost time: 0.13160085678100586
Epoch: 16, Steps: 28 | Train Loss: 0.4511612 Vali Loss: 0.1050726 Test Loss: 0.1766824
EarlyStopping counter: 5 out of 15
Updating learning rate to 1.52587890625e-08
Epoch: 17 cost time: 0.13156843185424805
Epoch: 17, Steps: 28 | Train Loss: 0.4552853 Vali Loss: 0.1043059 Test Loss: 0.1766825
EarlyStopping counter: 6 out of 15
Updating learning rate to 7.62939453125e-09
Epoch: 18 cost time: 0.13138937950134277
Epoch: 18, Steps: 28 | Train Loss: 0.4474772 Vali Loss: 0.1027432 Test Loss: 0.1766824
EarlyStopping counter: 7 out of 15
Updating learning rate to 3.814697265625e-09
Epoch: 19 cost time: 0.13153076171875
Epoch: 19, Steps: 28 | Train Loss: 0.4478478 Vali Loss: 0.1006570 Test Loss: 0.1766824
Validation loss decreased (0.102236 --> 0.100657).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 20 cost time: 0.21416759490966797
Epoch: 20, Steps: 28 | Train Loss: 0.4532185 Vali Loss: 0.1034153 Test Loss: 0.1766824
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.5367431640625e-10
Epoch: 21 cost time: 0.1320171356201172
Epoch: 21, Steps: 28 | Train Loss: 0.4542838 Vali Loss: 0.1022998 Test Loss: 0.1766824
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.76837158203125e-10
Epoch: 22 cost time: 0.1801128387451172
Epoch: 22, Steps: 28 | Train Loss: 0.4513017 Vali Loss: 0.1064948 Test Loss: 0.1766824
EarlyStopping counter: 3 out of 15
Updating learning rate to 2.384185791015625e-10
Epoch: 23 cost time: 0.24451065063476562
Epoch: 23, Steps: 28 | Train Loss: 0.4512762 Vali Loss: 0.1046015 Test Loss: 0.1766824
EarlyStopping counter: 4 out of 15
Updating learning rate to 1.1920928955078125e-10
Epoch: 24 cost time: 0.13192296028137207
Epoch: 24, Steps: 28 | Train Loss: 0.4543940 Vali Loss: 0.1063895 Test Loss: 0.1766824
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.960464477539063e-11
Epoch: 25 cost time: 0.20184683799743652
Epoch: 25, Steps: 28 | Train Loss: 0.4521674 Vali Loss: 0.1035654 Test Loss: 0.1766824
EarlyStopping counter: 6 out of 15
Updating learning rate to 2.980232238769531e-11
Epoch: 26 cost time: 0.13155245780944824
Epoch: 26, Steps: 28 | Train Loss: 0.4542922 Vali Loss: 0.1025726 Test Loss: 0.1766824
EarlyStopping counter: 7 out of 15
Updating learning rate to 1.4901161193847657e-11
Epoch: 27 cost time: 0.13146471977233887
Epoch: 27, Steps: 28 | Train Loss: 0.4525865 Vali Loss: 0.1028864 Test Loss: 0.1766824
EarlyStopping counter: 8 out of 15
Updating learning rate to 7.450580596923828e-12
Epoch: 28 cost time: 0.13141369819641113
Epoch: 28, Steps: 28 | Train Loss: 0.4540724 Vali Loss: 0.1048627 Test Loss: 0.1766824
EarlyStopping counter: 9 out of 15
Updating learning rate to 3.725290298461914e-12
Epoch: 29 cost time: 0.13149785995483398
Epoch: 29, Steps: 28 | Train Loss: 0.4521466 Vali Loss: 0.1043594 Test Loss: 0.1766824
EarlyStopping counter: 10 out of 15
Updating learning rate to 1.862645149230957e-12
Epoch: 30 cost time: 0.1313948631286621
Epoch: 30, Steps: 28 | Train Loss: 0.4503652 Vali Loss: 0.1025548 Test Loss: 0.1766824
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.313225746154785e-13
Epoch: 31 cost time: 0.1322484016418457
Epoch: 31, Steps: 28 | Train Loss: 0.4482884 Vali Loss: 0.1061787 Test Loss: 0.1766824
EarlyStopping counter: 12 out of 15
Updating learning rate to 4.656612873077393e-13
Epoch: 32 cost time: 0.13173508644104004
Epoch: 32, Steps: 28 | Train Loss: 0.4485119 Vali Loss: 0.1013343 Test Loss: 0.1766824
EarlyStopping counter: 13 out of 15
Updating learning rate to 2.3283064365386963e-13
Epoch: 33 cost time: 0.13163304328918457
Epoch: 33, Steps: 28 | Train Loss: 0.4571449 Vali Loss: 0.1056658 Test Loss: 0.1766824
EarlyStopping counter: 14 out of 15
Updating learning rate to 1.1641532182693482e-13
Epoch: 34 cost time: 0.13161754608154297
Epoch: 34, Steps: 28 | Train Loss: 0.4526191 Vali Loss: 0.1050941 Test Loss: 0.1766824
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : long_term_forecast_POST_COVID_Nonstationary_Transformer_pl5_Nonstationary_Transformer_custom_ftMS_sl128_ll48_pl5_dm32_nh4_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_POST_COVID_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 287
test shape: (287, 5, 1) (287, 5, 1)
test shape: (287, 5, 1) (287, 5, 1)
mse:0.1769, mae:0.3167, msIC:0.0209, msIR:0.0434
Total Evaluation 

MSE:0.1760Â±0.0007
MAE:0.3150Â±0.0013
msIC:0.0261Â±0.0037
msIR:0.0541Â±0.0076
  Evaluating Nonstationary_Transformer results...
    [Iter 0] Not found
    [Iter 1] Not found
    [Iter 2] Not found

==============================================================
FINAL ANALYSIS
==============================================================
